{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Open-source AI workflows","text":""},{"location":"#easily-build-repeatable-ai-workflows","title":"Easily build repeatable AI workflows","text":"<p>Pipelex is an open-source language specifically designed to build reliable, repeatable workflows. Stop wrestling with fragile workflows and start building AI systems you can trust.</p>"},{"location":"#ready-to-build-something-amazing","title":"Ready to build something amazing?","text":"<p>Just want to see it in action? Get up and running in minutes with our quick-start guide.</p> <p> Install &amp; Quick Start</p> <p>Want to understand the bigger picture? Discover why Pipelex changes everything about AI development.</p> <p> Read the Manifesto  Explore the Paradigm</p>"},{"location":"CODE_OF_CONDUCT/","title":"Code of Conduct","text":"<p>--8&lt;-- \"../CODE_OF_CONDUCT.md\" </p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v064-2025-07-19","title":"[v0.6.4] - 2025-07-19","text":"<ul> <li>Fixed the <code>README.md</code> link to the documentation</li> </ul>"},{"location":"changelog/#v063-2025-07-18","title":"[v0.6.3] - 2025-07-18","text":""},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>Enhanced <code>Stuff.content_as()</code> method with improved type validation logic - now attempts model validation when <code>isinstance</code> check fails</li> </ul>"},{"location":"changelog/#v062-2025-07-18","title":"[v0.6.2] - 2025-07-18","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>New <code>dry-run-pipe</code> cli command to dry run a single pipe by its code</li> <li>New <code>show-pipe</code> cli command to display pipe definitions from the pipe library</li> <li>New <code>dry_run_single_pipe()</code> function for running individual pipe dry runs</li> </ul>"},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>Updated <code>init-libraries</code> command to accept a directory argument and create <code>pipelex_libraries</code> folder in specified location</li> <li>Updated <code>validate</code> command to use <code>-c</code> flag for the config folder path</li> </ul>"},{"location":"changelog/#v061-2025-07-16","title":"[v0.6.1] - 2025-07-16","text":"<ul> <li>Can execute pipelines with <code>input_memory</code>: It is a <code>CompactMemory: Dict[str, Dict[str, Any]]</code></li> </ul>"},{"location":"changelog/#v060-2025-07-15","title":"[v0.6.0] - 2025-07-15","text":""},{"location":"changelog/#changed_2","title":"Changed","text":"<ul> <li>Enhanced <code>Pipelex.make()</code> method: Complete overhaul of the initialization method with new path configuration options and robust validation:</li> <li>Added <code>relative_config_folder_path</code> and <code>absolute_config_folder_path</code> parameters for flexible config folder specification</li> <li>The <code>from_file</code> parameter controls path resolution: if <code>True</code> (default), relative paths are resolved relative to the caller's file location; if <code>False</code>, relative to the current working directory (useful for CLI scenarios)</li> <li>Renamed Makefile targets like <code>make doc</code> to <code>make docs</code> for consistency</li> </ul>"},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>Added github action for inference tests</li> <li><code>load_json_list_from_path</code> function in <code>pipelex.tools.misc.file_utils</code>: Loads a JSON file and ensures it contains a list.</li> <li>Added issue templates</li> <li>Updated Azure/OpenAI integrations, using dated deployment names systematically</li> </ul>"},{"location":"changelog/#v052-2025-07-11","title":"[v0.5.2] - 2025-07-11","text":"<ul> <li>log a warning when dry running a <code>PipeFunc</code></li> <li>Update Readme.md</li> </ul>"},{"location":"changelog/#v051-2025-07-09","title":"[v0.5.1] - 2025-07-09","text":""},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>Fixed the <code>ConceptFactory.make_from_blueprint</code> method: Concepts defined in single-line format no longer automatically refine <code>TextContent</code> when a structure class with the same name exists</li> <li><code>ConceptFactory.make_concept_from_definition</code> is now <code>ConceptFactory.make_concept_from_definition_str</code></li> </ul>"},{"location":"changelog/#added_2","title":"Added","text":"<ul> <li>Bumped <code>kajson</code> to <code>v0.3.0</code>: Introducing <code>MetaSingleton</code> for better singleton management</li> <li>Unit tests for <code>ConceptLibrary.is_compatible_by_concept_code</code></li> </ul>"},{"location":"changelog/#v050-2025-07-01","title":"[v0.5.0] - 2025-07-01","text":""},{"location":"changelog/#highlight-vibe-coding-an-ai-workflow-becomes-a-reality","title":"Highlight: Vibe Coding an AI workflow becomes a reality","text":"<p>Create AI workflows from natural language without writing code - The combination of Pipelex's declarative language, comprehensive Cursor rules, and robust validation tools enables AI assistants to autonomously iterate on pipelines until all errors are resolved and workflows are ready to run.</p>"},{"location":"changelog/#added_3","title":"Added","text":"<ul> <li>Complete Dry Run &amp; Static Validation System - A comprehensive validation framework that catches configuration and pipeline errors before any expensive inference operations.</li> <li>WorkingMemoryFactory Enhancement: New <code>make_for_dry_run()</code> method creates working memory with realistic mock objects for zero-cost pipeline testing</li> <li>Enhanced Dry Run System: Complete dry run support for all pipe controllers (<code>PipeCondition</code>, <code>PipeParallel</code>, <code>PipeBatch</code>) with mock data generation using <code>polyfactory</code></li> <li>Comprehensive Static Validation: Enhanced static validation with configurable error handling for missing/extraneous input variables and domain validation</li> <li>TOML File Validation: Automatic detection and prevention of trailing whitespaces, formatting issues, and compilation blockers in pipeline files</li> <li>Pipeline Testing Framework: New <code>dry_run_all_pipes()</code> method enables comprehensive testing of entire pipeline libraries</li> <li>Enhanced Library Loading: Improved error handling and validation during TOML file loading with proper exception propagation</li> </ul>"},{"location":"changelog/#configuration","title":"Configuration","text":"<ul> <li>Dry Run Configuration: New <code>allowed_to_fail_pipes</code> setting allows specific pipes (like infinite loop examples that fail on purpose) to be excluded from dry run validation</li> <li>Static Validation Control: Configurable error reactions (<code>raise</code>, <code>log</code>, <code>ignore</code>) for different validation error types</li> </ul>"},{"location":"changelog/#documentation-development-experience","title":"Documentation &amp; Development Experience","text":"<ul> <li>Cursor Rules Enhancement: Comprehensive pipe controller documentation covering <code>PipeSequence</code>, <code>PipeCondition</code>, <code>PipeBatch</code>, and <code>PipeParallel</code>, improved PipeOperator documentation for <code>PipeLLM</code>, <code>PipeOCR</code></li> <li>Pipeline Validation CLI: Enhanced <code>pipelex validate</code> command with better error reporting and validation coverage</li> <li>Improved Error Messages: Better formatting and context for pipeline configuration errors</li> </ul>"},{"location":"changelog/#changed_3","title":"Changed","text":"<ul> <li>OCR Input Standardization: Changed OCR pipe input parameter naming to consistently use <code>ocr_input</code> for both image and PDF inputs, improving consistency across the API</li> <li>Error Message Improvements: Updated PipeCondition error messages to reference <code>expression_template</code> instead of deprecated <code>expression_jinja2</code></li> </ul>"},{"location":"changelog/#v0411-2025-06-30","title":"[v0.4.11] - 2025-06-30","text":"<ul> <li>LLM Settings Simplification: Streamlined LLM choice system by removing complex <code>for_object_direct</code>, <code>for_object_list</code>, and <code>for_object_list_direct</code> options. LLM selection now uses a simpler fallback pattern: specific choice \u2192 text choice \u2192 overrides \u2192 defaults.</li> <li>Image Model Updates: Renamed <code>image_bytes</code> field to <code>base_64</code> in <code>PromptImageTypedBytes</code> for better consistency. Updated to use <code>CustomBaseModel</code> base class to benefit from bytes truncation when printing.</li> </ul>"},{"location":"changelog/#v0410-2025-06-30","title":"[v0.4.10] - 2025-06-30","text":"<ul> <li>Fixed a bad import statement</li> </ul>"},{"location":"changelog/#v049-2025-06-30","title":"[v0.4.9] - 2025-06-30","text":""},{"location":"changelog/#highlights","title":"Highlights","text":"<p>Plugin System Refactoring - Complete overhaul of the plugin architecture to support external LLM providers.</p>"},{"location":"changelog/#added_4","title":"Added","text":"<ul> <li>External Plugin Support: New <code>LLMWorkerAbstract</code> base class for integrating custom LLM providers, and we don't mean only an OpenAI-SDK-based LLM with a custom endpoint, now the implementation can be anything, as long as it implements the <code>LLMWorkerAbstract</code> interface.</li> <li>Plugin SDK Registry: Better management of SDK instances with proper teardown handling</li> <li>Enhanced Error Formatting: Improved Pydantic validation error messages for enums</li> </ul>"},{"location":"changelog/#changed_4","title":"Changed","text":"<ul> <li>Plugin Architecture: Moved plugin system to dedicated <code>pipelex.plugins</code> package</li> <li>LLM Workers: Split into <code>LLMWorkerInternalAbstract</code> (for built-in providers) and <code>LLMWorkerAbstract</code> (for external plugins)</li> <li>Configuration: Plugin configs moved from main <code>pipelex.toml</code> to separate <code>pipelex_libraries/plugins/plugin_config.toml</code> (\u26a0\ufe0f breaking change)</li> <li>Error Handling: Standardized credential errors with new <code>CredentialsError</code> base class</li> </ul>"},{"location":"changelog/#v048-2025-06-26","title":"[v0.4.8] - 2025-06-26","text":"<ul> <li>Added <code>StorageProviderAbstract</code></li> <li>Updated the changelog of <code>v0.4.7</code>: Moved <code>Added StorageProviderAbstract</code> to <code>v0.4.8</code></li> </ul>"},{"location":"changelog/#v047-2025-06-26","title":"[v0.4.7] - 2025-06-26","text":"<ul> <li>Added an API serializer: introducing the <code>compact_memory</code>, a new way to encode/decode the working memory as json, for the API.</li> <li>When creating a Concept with no structure specified and no explicit <code>refines</code>, set it to refine <code>native.Text</code></li> <li><code>JobMetadata</code>: added <code>job_name</code>. Removed <code>top_job_id</code> and <code>wfid</code></li> <li><code>PipeOutput</code>: added <code>pipeline_run_id</code></li> </ul>"},{"location":"changelog/#v046-2025-06-24","title":"[v0.4.6] - 2025-06-24","text":"<ul> <li>Changed the link to the doc in the <code>README.md</code>: https://docs.pipelex.com</li> </ul>"},{"location":"changelog/#v045-2025-06-23","title":"[v0.4.5] - 2025-06-23","text":""},{"location":"changelog/#changed_5","title":"Changed","text":"<ul> <li>Test structure overhaul: Reorganized test directory structure for better organization:</li> <li>Tests now separated into <code>unit/</code>, <code>integration/</code>, and <code>e2e/</code> directories</li> <li>Created <code>tests/cases/</code> package for pure test data and constants</li> <li>Created <code>tests/helpers/</code> package for test utilities</li> <li>Cleaned up test imports and removed empty <code>__init__.py</code> files</li> <li>Class registry refactoring: Updated kajson from 0.1.6 to 0.2.0, adapted to changes in Kajson's class registry with new <code>ClassRegistryUtils</code> (better separation of concerns)</li> <li>Dependency updates:</li> <li>Added pytest-mock to dev dependencies for improved unit testing</li> </ul>"},{"location":"changelog/#added_5","title":"Added","text":"<ul> <li>Coverage commands: New Makefile targets for test coverage analysis:</li> <li><code>make cov</code>: Run tests with coverage report</li> <li><code>make cov-missing</code> (or <code>make cm</code>): Show coverage with missing lines</li> <li>Test configuration: Set <code>xfail_strict = true</code> in pytest config for stricter test failure handling</li> <li>Pydantic validation errors: Enhanced error formatting to properly handle model_type errors</li> </ul>"},{"location":"changelog/#fixed_1","title":"Fixed","text":"<ul> <li>External links: Removed broken Markdown target=\"_blank\" syntax from MANIFESTO.md links</li> <li>Variable naming consistency: Fixed redundant naming in OpenAI config (openai_openai_config \u2192 openai_config)</li> <li>Makefile optimization: Removed parallel test execution (<code>-n auto</code>) from codex-tests, works better now</li> </ul>"},{"location":"changelog/#tests","title":"Tests","text":"<ul> <li>Unit tests added: New comprehensive unit tests for:</li> <li><code>ClassRegistryUtils</code></li> <li><code>FuncRegistry</code> </li> <li><code>ModuleInspector</code></li> <li>File finding utilities</li> </ul>"},{"location":"changelog/#v044-2025-06-20","title":"[v0.4.4] - 2025-06-20","text":""},{"location":"changelog/#fixed_2","title":"Fixed","text":"<ul> <li>Changed the allowed base branch names in the GHA <code>guard-branches.yml</code>: <code>doc</code> -&gt; <code>docs</code></li> <li>Fixed <code>kajson</code> dependency (see kajson v0.1.6 changelog)</li> </ul>"},{"location":"changelog/#cursor-rules","title":"Cursor rules","text":"<ul> <li>Added Cursor rules for coding best practices and standards (including linting methods). Added TDD (Test Driven Development) rule on demand.</li> <li>Various changes</li> </ul>"},{"location":"changelog/#documentation","title":"Documentation","text":"<ul> <li>Added documentation for referencing images in PipeLLM.</li> <li>Fixed typos</li> </ul>"},{"location":"changelog/#refactor","title":"Refactor","text":"<ul> <li>Removed the <code>images</code> field from PipeLLM - images can now be referenced directly in the <code>inputs</code></li> <li>Moved the list-pipes CLI function to the <code>PipeLibrary</code> class.</li> </ul>"},{"location":"changelog/#v043-2025-06-19","title":"[v0.4.3] - 2025-06-19","text":""},{"location":"changelog/#fixed_3","title":"Fixed","text":"<ul> <li>Removed deprecated Gemini 1.5 models: Removed <code>gemini-1.5-flash</code> and <code>gemini-1.5-pro</code> from the VertexAI integration as they are no longer supported</li> <li>Fixed multiple import statements across the codebase</li> </ul>"},{"location":"changelog/#documentation_1","title":"Documentation","text":"<ul> <li>Enhanced MkDocs search: Added search functionality to the documentation site</li> <li>Proofreading improvements: Fixed various typos and improved clarity across documentation</li> </ul>"},{"location":"changelog/#refactor_1","title":"Refactor","text":"<ul> <li>Mini refactor: changed kajson dependency to <code>kajson==0.1.5</code> (instead of <code>&gt;=</code>) to tolerate temporary breaking changes from kajson</li> </ul>"},{"location":"changelog/#v042-2025-06-17","title":"[v0.4.2] - 2025-06-17","text":"<ul> <li>Fixed the inheritance config manager method (Undocumented feature, soon to be removed)</li> <li>Fixed the <code>deploy-doc.yml</code> GitHub Action</li> <li>Grouped the mkdocs dependencies in a single group <code>docs</code> in the <code>pyproject.toml</code> file</li> </ul>"},{"location":"changelog/#v041-2025-06-16","title":"[v0.4.1] - 2025-06-16","text":"<ul> <li>Changed discord link to the new one: https://go.pipelex.com/discord</li> <li>Added <code>hello-world</code> example in the <code>cookbook-examples</code> of the documentation.</li> </ul>"},{"location":"changelog/#v040-2025-06-16","title":"[v0.4.0] - 2025-06-16","text":""},{"location":"changelog/#highlight-complete-documentation-overhaul","title":"Highlight: Complete documentation overhaul","text":"<ul> <li>MkDocs setup for static web docs generation<ul> <li>Material for MkDocs theme, custom styling and navigation</li> <li>Other plugins: meta-manager, glightbox</li> <li>GitHub Pages deployment, mapped to docs.pipelex.com</li> <li>Added GHA workflows for documentation deployment and validation</li> </ul> </li> <li>Added to docs:<ul> <li>Manifesto explaining the Pipelex viewpoint</li> <li>The Pipelex Paradigm explaining the fundamentals of Pipelex's solution</li> <li>**Cookbook examples** presented and explained, commented code, some event with mermaid flow charts</li> <li>And plenty of details about using Pipelex and developing for Pipelex, from structured generation to PipeOperators (LLM, Image generation, OCR\u2026) to PipeControllers (Sequence, Parallel, Batch, Condition\u2026), workflow optimization, workflow static validation and dry run\u2026 there's still work to do, but we move fast!</li> </ul> </li> <li>Also a major update of Cursor rules</li> </ul>"},{"location":"changelog/#tooling-improvements","title":"Tooling Improvements","text":"<ul> <li>Pipeline tracking: restored visual flowchart generation using Mermaid</li> <li>Enhanced dry run configuration: added more granular control with <code>nb_list_items</code>, <code>nb_ocr_pages</code>, and <code>image_urls</code></li> <li>New feature flags: better control over pipeline tracking, activity tracking, and reporting</li> <li>Improved OCR configuration: handle image file type for Mistral-OCR, added <code>default_page_views_dpi</code> setting</li> <li>Enhanced LLM configuration: better prompting for structured generation with automatic schema insertion for two-step structuring: generate plain text and then structure via Json</li> <li>Better logging: Enhanced log truncation and display for large objects like image bytes (there are still cases to deal with)</li> </ul>"},{"location":"changelog/#refactor_2","title":"Refactor","text":"<p>Concept system refactoring</p> <ul> <li>Improved concept code factory with better domain handling, so you no longer need the <code>native</code> domain prefix for native domains, you can just call them by their names: <code>Text</code>, <code>Image</code>, <code>PDF</code>, <code>Page</code>, <code>Number</code>\u2026</li> <li>Concept <code>refines</code> attribute can now be a string for single refined concepts (the most common case)</li> </ul>"},{"location":"changelog/#breaking-changes","title":"Breaking Changes","text":"<ul> <li>File structure changes: documentation moved from <code>doc/</code> to <code>docs/</code></li> <li>Configuration changes: some configuration keys have been renamed or restructured</li> <li><code>StuffFactory.make_stuff()</code> argument <code>concept_code</code> renamed to <code>concept_str</code> to explicitly support concepts without fully qualified domains (e.g., <code>Text</code> or <code>PDF</code> implicitly <code>native</code> )</li> <li>Some method signatures have been updated</li> </ul>"},{"location":"changelog/#tests_1","title":"Tests","text":"<ul> <li>Added Concept refinement validation: <code>TestConceptRefinesValidationFunction</code> and <code>TestConceptPydanticFieldValidation</code> ensure proper concept inheritance and field validation</li> </ul>"},{"location":"changelog/#v032-2025-06-13","title":"[v0.3.2] - 2025-06-13","text":"<ul> <li>Improved automatic insertion of class structure from BaseModel into prompts, based on the PipeLLM's <code>output_concept</code>. New unit test included.</li> <li>The ReportingManager now reports costs for all pipeline IDs when no <code>pipeline_run_id</code> is specified.</li> <li>The <code>make_from_str</code> method from the <code>StuffFactory</code> class now uses <code>Text</code> context by default.</li> </ul>"},{"location":"changelog/#v031-2025-06-10","title":"[v0.3.1] - 2025-06-10","text":""},{"location":"changelog/#added_6","title":"Added","text":"<ul> <li>New pytest marker <code>dry_runnable</code> for tests that can run without inference.</li> <li>Enhanced <code>make</code> targets with dry-run capabilities for improved test coverage:</li> <li><code>make test-xdist</code> (or <code>make t</code>): Runs all non-inference tests plus inference tests that support dry-runs - fast and resource-efficient</li> <li><code>make test-inference</code> (or <code>make ti</code>): Runs tests requiring actual inference, with actual inference (slow and costly)</li> <li>Parallel test execution using <code>pytest-xdist</code> (<code>-n auto</code>) enabled for:</li> <li>GitHub Actions workflows</li> <li>Codex test targets</li> </ul>"},{"location":"changelog/#changed_6","title":"Changed","text":"<ul> <li>Domain validation is now less restrictive in pipeline TOML: the <code>definition</code> attribute is now <code>Optional</code></li> </ul>"},{"location":"changelog/#v030-2025-06-09","title":"[v0.3.0] - 2025-06-09","text":""},{"location":"changelog/#highlights_1","title":"Highlights","text":"<ul> <li>Structured Input Specifications: Pipe inputs are now defined as a dictionary mapping a required variable name to a concept code (<code>required_variable</code> -&gt; <code>concept_code</code>). This replaces the previous single <code>input</code> field and allows for multiple, named inputs, making pipes more powerful and explicit. This is a breaking change.</li> <li>Static Validation for Inference Pipes: You can now catch configuration and input mistakes in your pipelines before running any operations. This static validation checks <code>PipeLLM</code>, <code>PipeOcr</code>, and <code>PipeImgGen</code>. Static validation for controller pipes (PipeSequence, PipeParallel\u2026) will come in a future release.<ul> <li>Configure the behavior for different error types using the <code>static_validation_config</code> section in your settings. For each error type, choose to <code>raise</code>, <code>log</code>, or <code>ignore</code>.</li> </ul> </li> <li>Dry Run Mode for Zero-Cost Pipeline Validation: A powerful dry-run mode allows you to test entire pipelines without making any actual inference calls. It's fast, costs nothing, works offline, and is perfect for linting and validating pipeline logic.<ul> <li>The new <code>dry_run_config</code> lets you control settings, like disabling Jinja2 rendering during a dry run.</li> <li>This feature leverages <code>polyfactory</code> to generate mock Pydantic models for simulated outputs.</li> <li>Error handling for bad inputs during <code>run_pipe</code> has been improved and is fully effective in dry-run mode.</li> <li>One limitation: currently, dry running doesn't work when the pipeline uses a PipeCondition. This will be fixed in a future release.</li> </ul> </li> </ul>"},{"location":"changelog/#added_7","title":"Added","text":"<ul> <li><code>native.Anything</code> Concept: A new flexible native concept that is compatible with any other concept, simplifying pipe definitions where input types can vary.</li> <li>Added dependency on <code>polyfactory</code> for mock Pydantic model generation in dry-run mode.</li> </ul>"},{"location":"changelog/#changed_7","title":"Changed","text":"<ul> <li>Refactored Cognitive Workers: The abstraction for <code>LLM</code>, <code>Imgg</code>, and <code>Ocr</code> workers has been elegantly simplified. The old decorator-based approach (<code>..._job_func</code>) has been replaced with a more robust pattern: a public base method now handles pre- and post-execution logic while calling a private abstract method that each worker implements.</li> <li>The <code>b64_image_bytes</code> field in <code>PromptImageBytes</code> was renamed to <code>base_64</code> for better consistency.</li> </ul>"},{"location":"changelog/#fixed_4","title":"Fixed","text":"<ul> <li>Resolved a logged error related to the pipe stack when using <code>PipeParallel</code>.</li> <li>The pipe tracker functionality has been restored. It no longer crashes when using nested object attributes (e.g., <code>my_object.attribute</code>) as pipe inputs.</li> </ul>"},{"location":"changelog/#tests_2","title":"Tests","text":"<ul> <li>A new pytest command-line option <code>--pipe-run-mode</code> has been added to switch between <code>live</code> and <code>dry</code> runs (default is <code>dry</code>). All pipe tests now respect this mode.</li> <li>Introduced the <code>pipelex_api</code> pytest marker for tests related to the Pipelex API client, separating them from general <code>inference</code> or <code>llm</code> tests.</li> <li>Added a <code>make test-pipelex-api</code> target (shorthand: <code>make ta</code>) to exclusively run these new API client tests.</li> </ul>"},{"location":"changelog/#removed","title":"Removed","text":"<ul> <li>The <code>llm_job_func.py</code> file and the associated decorators have been removed as part of the cognitive worker refactoring.</li> </ul>"},{"location":"changelog/#v0214-2025-06-06","title":"[v0.2.14] - 2025-06-06","text":"<ul> <li>Added a feature flag for the <code>ReportingManager</code> in the config:  <pre><code>[pipelex]\n[pipelex.feature_config]\nis_reporting_enabled = true\n</code></pre></li> <li>Moved the reporting config form the <code>cogt</code>config to the Pipelex config.</li> </ul>"},{"location":"changelog/#v0213-2025-06-06","title":"[v0.2.13] - 2025-06-06","text":"<ul> <li>Added Discord badge on the Readme. Join the community! -&gt; https://go.pipelex.com/discord</li> <li>Added a client for the Pipelex API. Join the waitlist -&gt; https://www.pipelex.com/signup</li> <li>Removed the <code>run_pipe_code</code> function. Replaced by <code>execute_pipeline</code> in <code>pipelex.pipeline.execute</code>.</li> <li>Added llm deck <code>llm_for_img_to_text</code>.</li> <li>Renamed <code>InferenceReportManager</code> to <code>ReportingManager</code>: It can report more than Inference cost. Renamed <code>InferenceReportDelegate</code> to <code>ReportingProtocol</code>.</li> <li>Added an injection of dependency for <code>ReportingManager</code></li> <li>pipelex cli: fixed some bugs</li> </ul>"},{"location":"changelog/#v0212-2025-06-03","title":"[v0.2.12] - 2025-06-03","text":"<ul> <li>pipelex cli: Split <code>pipelex init</code> into 2 separate functions: <code>pipelex init-libraries</code> and <code>pipelex init-config</code></li> <li>Fixed the inheritance config manager method</li> <li>Rename Mission to Pipeline</li> <li>Enable to start a pipeline and let in run in the background, getting it's run id, but not waiting for the output</li> <li><code>Makefile</code>: avoid defaulting pytest to verbose. Setup target <code>make test-xdist</code> = Run unit tests with <code>xdist</code>, make it the default for shorthand <code>make t</code>. The old <code>make t</code> is now <code>make tp</code> (test-with-prints)</li> <li>Added <code>mistral-small-3.1</code> and <code>qwen3:8b</code></li> <li>Fix template pre-processor: don't try and substitute a dollar numerical like $10 or @25</li> <li>Refactor with less \"OpenAI\" naming for non-openai stuff that just uses the OpenAI SDK</li> </ul>"},{"location":"changelog/#v0211-2025-06-02","title":"[v0.2.11] - 2025-06-02","text":"<ul> <li>HotFix for v0.2.10 \ud83d\udc47 regarding the new pipelex/pipelex_init.toml`</li> </ul>"},{"location":"changelog/#v0210-2025-06-02","title":"[v0.2.10] - 2025-06-02","text":""},{"location":"changelog/#highlights_2","title":"Highlights","text":"<p>Python Support Expansion - We're no longer tied to Python 3.11! Now supporting Python 3.10, 3.11, 3.12, and 3.13 with full CI coverage across all versions.</p> <p>Major Model Additions - Claude 4 (Opus &amp; Sonnet), Grok-3, and GPT-4 image generation are now in the house.</p>"},{"location":"changelog/#pipeline-base-library-update","title":"Pipeline Base Library update","text":"<ul> <li>New pipe - <code>extract_page_contents_and_views_from_pdf</code> transferred from cookbook to base library (congrats on the promotion!). This pipe extracts text, linked images, AND page_view images (rendered pages) - it's very useful if you want to use Vision in follow-up pipes</li> </ul>"},{"location":"changelog/#added_8","title":"Added","text":"<ul> <li>Template preprocessor - New <code>@?</code> token prefix for optional variable insertion - if a variable doesn't exist, we gracefully skip it instead of throwing exceptions</li> <li>Claude 4 support - Both Opus and Sonnet variants, available through Anthropic SDK (direct &amp; Bedrock) plus Bedrock SDK. Includes specific max_tokens limit reduction to prevent timeout/streaming issues (temporary workaround)</li> <li>Grok-3 family support - Full support via OpenAI SDK for X.AI's latest models  </li> <li>GPT-4 image generation - New <code>gpt-image-1</code> model through OpenAI SDK, available via PipeImgGen. Currently saves local files (addressing in next release)</li> <li>Gemini update - Added latest <code>gemini-2.5-pro</code> to the lineup</li> <li>Image generation enhancements - Better quality controls, improved background handling options, auto-adapts to different models: Flux, SDXL and now gpt-image-1</li> </ul>"},{"location":"changelog/#refactored","title":"Refactored","text":"<ul> <li>Moved subpackage <code>plugin</code> to the same level as <code>cogt</code> within pipelex for better visibility</li> <li>Major cleanup in the unit tests, hierarchy significantly flattened</li> <li>Strengthened error handling throughout inference flows and template preprocessing</li> <li>Added <code>make test-quiet</code> (shorthand <code>tq</code>) to Makefile to run tests without capturing outputs (i.e. without pytest <code>-s</code> option)</li> <li>Stopped using Fixtures for <code>pipe_router</code> and <code>content_generator</code>: we're now always getting the singleton from <code>pipelex.hub</code></li> </ul>"},{"location":"changelog/#fixed_5","title":"Fixed","text":"<ul> <li>Perplexity integration - Fixed breaking changes from recent updates</li> </ul>"},{"location":"changelog/#dependencies","title":"Dependencies","text":"<ul> <li>Added pytest-xdist to run unit tests in parallel on multiple CPUs. Not yet integrated into the Makefile, so run it manually with <code>pytest -n auto</code> (without inference) or <code>pytest -n auto -m \"inference\"</code> (inference only). </li> <li>Swapped pytest-pretty for pytest-sugar - because readable test names &gt; pretty tables</li> <li>Updated instructor to v1.8.3</li> <li>All dependencies tested against Python 3.10, 3.11, 3.12, and 3.13</li> </ul>"},{"location":"changelog/#tests_3","title":"Tests","text":"<ul> <li>TestTemplatePreprocessor</li> <li>TestImggByOpenAIGpt</li> <li>TestImageGeneration</li> <li>TestPipeImgg</li> </ul>"},{"location":"changelog/#v029-2025-05-30","title":"[v0.2.9] - 2025-05-30","text":"<ul> <li>Include <code>pyproject.toml</code> inside the project build.</li> <li>Fix <code>ImggEngineFactory</code>: image generation (imgg) handle required format is <code>platform/model_name</code></li> <li>pipelex cli: Added <code>list-pipes</code> method that can list all the available pipes along with their descriptions.</li> <li>Use a minimum version for <code>uv</code> instead of a fixed version</li> <li>Implement <code>AGENTS.md</code> for Codex</li> <li>Add tests for some of the <code>tools.misc</code></li> <li>pipelex cli: Rename <code>pipelex run-setup</code> to <code>pipelex validate</code></li> </ul>"},{"location":"changelog/#v028-2025-05-28","title":"[v0.2.8] - 2025-05-28","text":"<ul> <li>Replaced <code>poetry</code> by <code>uv</code> for dependency management.</li> <li>Simplify llm provider config: All the API keys, urls, and regions now live in the <code>.env</code>.</li> <li>Added logging level <code>OFF</code>, prevents any log from hitting the console</li> </ul>"},{"location":"changelog/#v027-2025-05-26","title":"[v0.2.7] - 2025-05-26","text":"<ul> <li>Reboot repository</li> </ul>"},{"location":"changelog/#v026-2025-05-26","title":"[v0.2.6] - 2025-05-26","text":"<ul> <li>Refactor: use <code>ActivityManagerProtocol</code>, rename <code>BaseModelTypeVar</code></li> </ul>"},{"location":"changelog/#v025-2025-05-25","title":"[v0.2.5] - 2025-05-25","text":"<ul> <li>Add custom LLM integration via OpenAI sdk with custom <code>base_url</code></li> </ul>"},{"location":"changelog/#v024-2025-05-25","title":"[v0.2.4] - 2025-05-25","text":"<ul> <li>Tidy tools</li> <li>Tidy inference API plugins</li> <li>Tidy WIP feature <code>ActivityManager</code></li> </ul>"},{"location":"changelog/#v022-2025-05-22","title":"[v0.2.2] - 2025-05-22","text":"<ul> <li>Simplify the use of native concepts</li> <li>Include \"page views\" in the outputs of Ocr features</li> </ul>"},{"location":"changelog/#v021-2025-05-22","title":"[v0.2.1] - 2025-05-22","text":"<ul> <li>Added <code>OcrWorkerAbstract</code> and <code>MistralOcrWorker</code>, along with <code>PipeOcr</code> for OCR processing of images and PDFs.</li> <li>Introduced <code>MissionManager</code> for managing missions, cost reports, and activity tracking.</li> <li>Added detection and handling for pipe stack overflow, configurable with <code>pipe_stack_limit</code>.</li> <li>More possibilities for dependency injection and better class structure.</li> <li>Misc updates including simplified PR template, LLM deck overrides, removal of unused config vars, and disabling of an LLM platform id.</li> </ul>"},{"location":"changelog/#v020-2025-05-19","title":"[v0.2.0] - 2025-05-19","text":"<ul> <li>Added OCR, thanks to Mistral</li> <li>Refactoring and cleanup</li> </ul>"},{"location":"changelog/#v0114-2025-05-13","title":"[v0.1.14] - 2025-05-13","text":"<ul> <li>Initial release \ud83c\udf89</li> </ul>"},{"location":"contributing/","title":"Contributing to Pipelex","text":"<p>Thank you for your interest in contributing! Contributions are very welcome. We appreciate first time contributors and we are happy help you get started. Join our community on Discord and feel free to reach out with questions in the #code-contributions and #pipeline-contributions channels.</p> <p>Everyone interacting in Discord, codebases, mailing lists, events, or any other Pipelex activities is expected to follow the Code of Conduct. Please review it before getting started.</p> <p>Most of the issues that are open for contributions are tagged with <code>good first issue</code> or <code>help-welcome</code>. If you see an issue that isn't tagged that you're interested in, post a comment with your approach, and we'll be happy to assign it to you. If you submit a fix that isn't linked to an issue you're assigned, there's chance it won't be accepted. Don't hesitate to ping the Pipelex team on Discord to discuss your choice of issue before getting to work.</p> <p>We are open to contributions in all areas of our core Pipelex library:</p> <ul> <li>Bug fixes: Crashes, incorrect output, performance issues</li> <li>Feature: New API, CLI flag, module, test coverage</li> <li>Refactor: Rethink architecture</li> <li>Chore: Dependency updates, config tweaks, file renames</li> <li>Docs: Main docs, SWE Agent rules, tutorials, examples, READMEs</li> <li>CI/CD: GitHub Actions, packaging, release tooling</li> </ul>"},{"location":"contributing/#contribution-process","title":"Contribution process","text":"<ul> <li>Fork the Pipelex repository</li> <li>Clone the repository locally</li> <li>Install dependencies: <code>make install</code> (creates .venv and installs dependencies)</li> <li>Copy <code>.env.example</code> to <code>.env</code> and fill in required API keys (at least OpenAI)</li> <li>Run checks to make sure all is good: <code>make check</code> &amp; <code>make test</code></li> <li>Create a branch with the format user_name/category/short_slug where category is one of: <code>feature</code>, <code>fix</code>, <code>refactor</code>, <code>docs</code>, <code>cicd</code> or <code>chore</code></li> <li>Make and commit changes</li> <li>Push your local branch to your fork</li> <li>Open a PR that links to an existing Issue which does not include the <code>needs triage</code> label</li> <li>Write a PR title and description by filling the template</li> <li>CI tests will be triggered and maintainers will review the code</li> <li>Respond to feedback if required</li> <li>Merge the contribution</li> </ul>"},{"location":"contributing/#requirements","title":"Requirements","text":"<ul> <li>Python \u22653.10</li> <li>uv \u2265 0.7.2</li> </ul>"},{"location":"contributing/#development-setup","title":"Development Setup","text":"<ul> <li>Fork &amp; clone the repository</li> <li>Run <code>make install</code> to set up virtualenv and dependencies</li> <li>Copy <code>.env.example</code> to <code>.env</code> and configure API keys</li> <li>Use uv for dependency management:</li> <li>Runtime deps: <code>uv pip install &lt;package&gt;</code></li> <li>Dev deps: <code>uv pip install --extra dev &lt;package&gt;</code></li> <li>Keep dependencies alphabetically ordered in pyproject.toml</li> </ul>"},{"location":"contributing/#pull-request-process","title":"Pull Request Process","text":"<ul> <li>Fork the Pipelex repository</li> <li>Clone the repository locally</li> <li>Install dependencies: <code>make install</code> (creates .venv and installs dependencies)</li> <li>Copy <code>.env.example</code> to <code>.env</code> and fill in required API keys (at least OpenAI)</li> <li>Run checks to make sure all is good: <code>make check</code> &amp; <code>make test</code></li> <li>Create a branch for your feature/bug-fix with the format user_name/feature/some_feature or user_name/fix/some_bugfix</li> <li>Make and commit changes</li> <li>Push your local branch to your fork</li> <li>When it's ready, re-run quality tests:</li> <li>Run <code>make fix-unused-imports</code> to removed unused imports</li> <li>Run <code>make check</code> for formatting &amp; linting with Ruff, and type-checking with Pyright and Mypy</li> <li>Run <code>make test</code> for test suite</li> <li>Open a PR that links to an existing Issue including a PR title and description</li> <li>Mark as Draft until CI passes</li> <li>Maintainers will review the code</li> <li>Respond to feedback if required</li> <li>Merge the contribution</li> </ul>"},{"location":"contributing/#environment-setup","title":"Environment Setup","text":"<ul> <li>Copy <code>.env.example</code> to <code>.env</code></li> <li>Fill in required credentials (OPENAI_API_KEY, AWS_ACCESS_KEY_ID, etc.)</li> <li>Never commit <code>.env</code></li> </ul>"},{"location":"contributing/#license","title":"License","text":"<ul> <li>CLA \u2013 The first time you open a PR, the CLA-assistant bot will guide you through signing the Contributor License Agreement. The process signature uses the CLA assistant lite.</li> <li>Code of Conduct \u2013 Be kind. All interactions fall under <code>CODE_OF_CONDUCT.md</code>.</li> </ul>"},{"location":"license/","title":"License","text":"<pre><code>MIT License\n\nCopyright (c) 2025 Evotis S.A.S.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n</code></pre>"},{"location":"manifesto/","title":"The Knowledge Pipeline Manifesto","text":""},{"location":"manifesto/#this-is-our-manifesto-this-is-why-we-built-pipelex","title":"This is our manifesto, this is why we built Pipelex.","text":"<p>First published on our blog on June 3, 2025.</p>"},{"location":"manifesto/#the-knowledge-pipeline-manifesto","title":"The Knowledge Pipeline Manifesto","text":""},{"location":"manifesto/#agents-are-brilliant-but-theyre-hopeless-at-repeatability","title":"Agents are brilliant but they're hopeless at repeatability","text":"<p>AI agents are getting impressive at novel tasks: research, planning, coding from scratch. But here's what we're missing: lots of knowledge work isn't novel. It's the same patterns, repeated thousands of times.</p> <p>Ask an agent to review 10,000 expense reports. Watch it improvise a new approach for each one. Different reasoning paths, different output formats, different edge case handling. Run it twice on the same report? Different results. The intelligence is there, but the consistency isn't. And someone\u2019s paying for those improv tokens.</p> <p>Agents are explorers. But if you know the path, you don't need an expedition. You need a bullet train.</p>"},{"location":"manifesto/#enter-the-knowledge-pipeline","title":"Enter the knowledge pipeline","text":"<p>The solution should be obvious: delegate the repetitive tasks to deterministic AI workflows. But here's the deeper problem: AI workflows today are handcrafted, not engineered. We prompt, tweak, test, and pray.</p> <p>Without proper tools for capturing repeatable workflows, every company recreates the same solutions from scratch. The expense categorization that took your team weeks to perfect? The next company starts at zero. We're in the pre-SQL era of AI: brilliant capabilities trapped in proprietary silos, no way to reuse what actually works.</p> <p>We need a way to capture proven AI workflows and make them as reliable and reusable as any other software component. We call this a knowledge pipeline.</p> <p>A knowledge pipeline is built from modular components called pipes. Each pipe is a knowledge transformer with a simple contract: knowledge in, knowledge out. Unlike data pipelines that move bytes or ML pipelines that train models, knowledge pipes transform meaning.</p> <p>This isn't about dumbing down AI. Each pipe leverages full AI intelligence to handle variation in content while guaranteeing its output structure. You get deterministic structure with adaptive intelligence:\u00a0consistency without rigidity.</p>"},{"location":"manifesto/#the-architecture-of-understanding","title":"The architecture of understanding","text":""},{"location":"manifesto/#knowledge-pipes-compose-like-lego-blocks-for-repeatable-ai-workflows","title":"Knowledge pipes compose like LEGO blocks for repeatable AI workflows:","text":"<ul> <li>Connect them sequentially for step-by-step transformations</li> <li>Run them in parallel to process multiple perspectives</li> <li>Feed multiple outputs into a single pipe for synthesis</li> <li>Call sub-pipes conditionally based on categorization</li> </ul> <p>Why does this matter? Because real knowledge work isn't linear.</p> <p>A pipe analyzing contracts might need context from step 2, results from steps 5-7, and external compliance data. The architecture mirrors how knowledge actually flows: not as a conveyor belt, but as a network of understanding.</p>"},{"location":"manifesto/#the-method-becomes-the-artifact","title":"The method becomes the artifact","text":"<p>When every pipe guarantees its output structure, you can compose them fearlessly. When each pipe uses AI intelligently, the pipeline adapts without breaking. When you capture your method as actual code, you can version it, test it, and scale it like software.</p> <p>With knowledge pipelines, your process becomes something you can hold, examine, and refine. Swap out language models to find the sweet spot between cost and quality. Adjust prompts until they sing. Reconfigure the flow when you discover a shortcut. Each iteration teaches you something new because you're working with stable, measurable outcomes.</p> <p>Remember when ChatGPT launched and suddenly everyone was sharing prompts? That same collaborative instinct is waiting to be unleashed on knowledge pipelines. A pipeline for extracting customer insights gets forked for user research. A financial audit workflow becomes the skeleton for compliance reviews. The building blocks translate across industries.</p> <p>These pipeline artifacts are meant to be shared, forked, and composed. Period.</p>"},{"location":"manifesto/#the-path-forward","title":"The path forward","text":"<p>We've seen this movie before. Docker transformed deployment by giving us a simple way to package and share what used to live in scattered shell scripts and tribal knowledge. Suddenly, complex configurations became artifacts you could version, test, and run anywhere. Better yet, Docker made it possible to build on each other's work rather than starting from scratch each time.</p> <p>Today's AI workflows are ready for the same breakthrough.</p> <p>This is why we built Pipelex\u00a0as an open-source standard for repeatable AI workflows. Not just another tool, but a foundation for the community to build on.</p> <p>The manifesto is simple: When you discover a method that works, capture it as a knowledge pipeline. When you build a pipeline that roars, share it with the world!</p> <p>Join us in building the knowledge infrastructure of tomorrow. One pipe at a time.</p>"},{"location":"pages/advanced-customization/","title":"Dependency Injection","text":""},{"location":"pages/advanced-customization/#overview","title":"Overview","text":"<p>Pipelex uses dependency injection to manage service dependencies and make components more modular and testable. The system allows you to customize and extend Pipelex's functionality by injecting your own implementations of various services.</p>"},{"location":"pages/advanced-customization/#injection-methods","title":"Injection Methods","text":"<p>There are two main ways to inject custom implementations:</p>"},{"location":"pages/advanced-customization/#1-during-initialization","title":"1. During Initialization","text":"<pre><code>from pipelex import Pipelex\n\npipelex = Pipelex(\n    template_provider=MyTemplateProvider(),\n    llm_model_provider=MyLLMProvider(),\n    inference_manager=MyInferenceManager(),\n    pipeline_tracker=MyPipelineTracker(),\n    activity_manager=MyActivityManager(),\n    reporting_delegate=MyReportingDelegate()\n)\n\npipelex.setup(\n    secrets_provider=MySecretsProvider(),\n    content_generator=MyContentGenerator(),\n    pipe_router=MyPipeRouter()\n)\n</code></pre>"},{"location":"pages/advanced-customization/#2-through-the-hub","title":"2. Through the Hub","text":"<pre><code>from pipelex.hub import PipelexHub\n\nhub = PipelexHub()\nhub.set_template_provider(MyTemplateProvider())\nhub.set_llm_models_provider(MyLLMProvider())\n# ... and so on for other components\n</code></pre>"},{"location":"pages/advanced-customization/#noop-implementations","title":"NoOp Implementations","text":"<p>Some components have \"NoOp\" (No Operation) implementations that are used when the feature is disabled:</p> <ul> <li><code>ReportingNoOp</code>: Used when reporting is disabled</li> <li><code>PipelineTrackerNoOp</code>: Used when pipeline tracking is disabled</li> <li><code>ActivityManagerNoOp</code>: Used when activity tracking is disabled</li> </ul> <p>These NoOp implementations implement the same protocol but do nothing, allowing the system to function without the specific feature.</p>"},{"location":"pages/advanced-customization/#protocol-compliance","title":"Protocol Compliance","text":"<p>All custom implementations MUST:</p> <ol> <li>Implement ALL methods defined in their respective protocols</li> <li>Match the exact method signatures (parameter names and types)</li> <li>Follow the protocol's documented behavior</li> <li>Handle errors appropriately</li> <li>Clean up resources when needed</li> </ol>"},{"location":"pages/advanced-customization/#feature-flags","title":"Feature Flags","text":"<p>Some components are controlled by feature flags in the configuration:</p> <ul> <li><code>is_reporting_enabled</code>: Controls Reporting system</li> <li><code>is_pipeline_tracking_enabled</code>: Controls Pipeline Tracking</li> <li><code>is_activity_tracking_enabled</code>: Controls Activity Tracking</li> </ul> <p>When a feature is disabled, the corresponding NoOp implementation is used automatically.</p>"},{"location":"pages/advanced-customization/#available-injectable-components","title":"Available Injectable Components","text":"<p>Pipelex supports injection of the following components:</p> <ol> <li> <p>Template Provider (<code>TemplateLibrary</code>)</p> <ul> <li>Protocol: <code>TemplateLibraryProtocol</code></li> <li>Default: <code>TemplateLibrary</code></li> <li>Details</li> </ul> </li> <li> <p>LLM Model Provider (<code>LLMModelLibrary</code>)</p> <ul> <li>Protocol: <code>LLMModelLibraryProtocol</code></li> <li>Default: <code>LLMModelLibrary</code></li> <li>Details</li> </ul> </li> <li> <p>Inference Manager (<code>InferenceManager</code>)</p> <ul> <li>Protocol: <code>InferenceManagerProtocol</code></li> <li>Default: <code>InferenceManager</code></li> <li>Details</li> </ul> </li> <li> <p>Reporting Delegate (<code>ReportingManager</code>)</p> <ul> <li>Protocol: <code>ReportingProtocol</code></li> <li>Default: <code>ReportingManager</code> or <code>ReportingNoOp</code> if disabled</li> <li>Details</li> </ul> </li> <li> <p>Pipeline Tracker (<code>PipelineTracker</code>)</p> <ul> <li>Protocol: <code>PipelineTrackerProtocol</code></li> <li>Default: <code>PipelineTracker</code> or <code>PipelineTrackerNoOp</code> if disabled</li> <li>Details</li> </ul> </li> <li> <p>Activity Manager (<code>ActivityManager</code>)</p> <ul> <li>Protocol: <code>ActivityManagerProtocol</code></li> <li>Default: <code>ActivityManager</code> or <code>ActivityManagerNoOp</code> if disabled</li> <li>Details</li> </ul> </li> <li> <p>Secrets Provider (<code>EnvSecretsProvider</code>)</p> <ul> <li>Protocol: <code>SecretsProviderProtocol</code></li> <li>Default: <code>EnvSecretsProvider</code></li> <li>Details</li> </ul> </li> <li> <p>Content Generator (<code>ContentGenerator</code>)</p> <ul> <li>Protocol: <code>ContentGeneratorProtocol</code></li> <li>Default: <code>ContentGenerator</code></li> <li>Details</li> </ul> </li> <li> <p>Pipe Router (<code>PipeRouter</code>)</p> <ul> <li>Protocol: <code>PipeRouterProtocol</code></li> <li>Default: <code>PipeRouter</code></li> <li>Details</li> </ul> </li> </ol>"},{"location":"pages/advanced-customization/AI_Integration_Layer/","title":"AI Integration Layer","text":"<pre><code>graph LR\n    InferenceManager[\"InferenceManager\"]\n    LLMWorker[\"LLMWorker\"]\n    ImggWorker[\"ImggWorker\"]\n    OcrWorker[\"OcrWorker\"]\n    LLMDeck[\"LLMDeck\"]\n    LLMModelLibrary[\"LLMModelLibrary\"]\n    AI_Configuration[\"AI Configuration\"]\n    InferenceManager -- \"orchestrates\" --&gt; LLMWorker\n    InferenceManager -- \"orchestrates\" --&gt; ImggWorker\n    InferenceManager -- \"orchestrates\" --&gt; OcrWorker\n    InferenceManager -- \"is configured by\" --&gt; AI_Configuration\n    LLMWorker -- \"receives tasks from\" --&gt; InferenceManager\n    LLMWorker -- \"uses configurations from\" --&gt; LLMDeck\n    LLMWorker -- \"uses configurations from\" --&gt; LLMModelLibrary\n    ImggWorker -- \"receives tasks from\" --&gt; InferenceManager\n    ImggWorker -- \"is configured by\" --&gt; AI_Configuration\n    OcrWorker -- \"receives tasks from\" --&gt; InferenceManager\n    OcrWorker -- \"is configured by\" --&gt; AI_Configuration\n    LLMDeck -- \"provides configurations to\" --&gt; LLMWorker\n    LLMModelLibrary -- \"provides models to\" --&gt; LLMWorker\n    AI_Configuration -- \"configures\" --&gt; InferenceManager\n    AI_Configuration -- \"configures\" --&gt; LLMWorker\n    AI_Configuration -- \"configures\" --&gt; ImggWorker\n    AI_Configuration -- \"configures\" --&gt; OcrWorker</code></pre>"},{"location":"pages/advanced-customization/AI_Integration_Layer/#details","title":"Details","text":"<p>The AI Integration Layer in pipelex provides a unified interface to various AI service providers, abstracting away their specific APIs, and is utilized by the Pipe Operators for AI-related tasks. This layer is primarily encapsulated within the pipelex.cogt package.</p>"},{"location":"pages/advanced-customization/AI_Integration_Layer/#inferencemanager","title":"InferenceManager","text":"<p>The central orchestrator for all AI inference tasks (LLM, Image Generation, OCR). It receives inference requests and dispatches them to the appropriate specialized AI workers.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.cogt.inference.inference_manager</code></li> </ul>"},{"location":"pages/advanced-customization/AI_Integration_Layer/#llmworker","title":"LLMWorker","text":"<p>Defines the abstract interface for interacting with various Large Language Model (LLM) providers. Concrete implementations (e.g., Anthropic, OpenAI) handle provider-specific API calls.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.cogt.llm.llm_worker_abstract</code></li> </ul>"},{"location":"pages/advanced-customization/AI_Integration_Layer/#imggworker","title":"ImggWorker","text":"<p>Defines the abstract interface for interacting with different Image Generation (Imgg) providers. Concrete implementations handle provider-specific API calls.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.cogt.imgg.imgg_worker_abstract</code></li> </ul>"},{"location":"pages/advanced-customization/AI_Integration_Layer/#ocrworker","title":"OcrWorker","text":"<p>Defines the abstract interface for interacting with various Optical Character Recognition (OCR) providers. Concrete implementations handle provider-specific API calls.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.cogt.ocr.ocr_worker_abstract</code></li> </ul>"},{"location":"pages/advanced-customization/AI_Integration_Layer/#llmdeck","title":"LLMDeck","text":"<p>Manages and validates configurations for various LLMs, ensuring correct setup and parameters for AI interactions.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.cogt.llm.llm_models.llm_deck</code></li> </ul>"},{"location":"pages/advanced-customization/AI_Integration_Layer/#llmmodellibrary","title":"LLMModelLibrary","text":"<p>Provides access to loaded LLM model definitions and acts as a central repository for LLM models, enabling workers to retrieve necessary model information.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.cogt.llm.llm_models.llm_model_library</code></li> </ul>"},{"location":"pages/advanced-customization/AI_Integration_Layer/#ai-configuration","title":"AI Configuration","text":"<p>Encapsulates specific configuration models (<code>LLMConfig</code>, <code>ImggConfig</code>, <code>OcrConfig</code>, <code>InferenceManagerConfig</code>) used to set up and run various AI tasks across the subsystem.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.cogt.config_cogt</code></li> </ul>"},{"location":"pages/advanced-customization/AI_Integration_Layer/#faq","title":"FAQ","text":""},{"location":"pages/advanced-customization/Client_API_Layer/","title":"Client & API Layer","text":"<pre><code>graph LR\n    Client_API_Layer[\"Client &amp; API Layer\"]\n    CLI_Command_Line_Interface_[\"CLI (Command-Line Interface)\"]\n    Pipelex_Core_Engine_API_[\"Pipelex (Core Engine API)\"]\n    CLI_Command_Line_Interface_ -- \"interacts with\" --&gt; Pipelex_Core_Engine_API_\n    Pipelex_Core_Engine_API_ -- \"exposes API to\" --&gt; Client_API_Layer\n    click Client_API_Layer href \"https://github.com/Pipelex/pipelex/blob/main/.codeboarding/Client_API_Layer.md\" \"Details\"</code></pre>"},{"location":"pages/advanced-customization/Client_API_Layer/#details","title":"Details","text":"<p>The <code>Client &amp; API Layer</code> is fundamentally important as it defines how users and other systems access the workflow orchestration capabilities. Separating it into <code>CLI</code> and <code>Pipelex (Core Engine API)</code> components aligns with the \"Workflow Orchestration Engine / AI Workflow Framework\" pattern by distinguishing between direct human interaction (CLI) and programmatic integration (API). This separation promotes modularity, allowing different types of clients to interact with the core engine through appropriate interfaces, which is crucial for extensibility and maintainability in an AI workflow framework.</p>"},{"location":"pages/advanced-customization/Client_API_Layer/#client-api-layer-expand","title":"Client &amp; API Layer [Expand]","text":"<p>This layer serves as the primary interface for external users and systems to interact with the Pipelex engine. It encompasses both the command-line interface for direct user interaction and the programmatic API exposed by the core <code>Pipelex</code> engine for integration with other systems or custom scripts. It acts as the gateway for initiating, managing, and monitoring AI workflows.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.cli._cli</code></li> <li><code>pipelex.pipelex.Pipelex</code> (60:304)</li> </ul>"},{"location":"pages/advanced-customization/Client_API_Layer/#cli-command-line-interface","title":"CLI (Command-Line Interface)","text":"<p>The <code>CLI</code> component provides a user-friendly command-line interface, enabling users to directly execute Pipelex commands, validate pipeline configurations, and manage workflow executions. It is the primary entry point for manual user interaction with the Pipelex system.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.cli._cli</code></li> </ul>"},{"location":"pages/advanced-customization/Client_API_Layer/#pipelex-core-engine-api","title":"Pipelex (Core Engine API)","text":"<p>While <code>Pipelex</code> represents the core orchestration engine, its public methods and attributes form the primary programmatic API. This API allows external clients, including the <code>CLI</code> and other integrated systems, to programmatically control and manage workflows, define pipelines, and interact with the engine's functionalities.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.pipelex.Pipelex</code> (60:304)</li> </ul>"},{"location":"pages/advanced-customization/Client_API_Layer/#faq","title":"FAQ","text":""},{"location":"pages/advanced-customization/Configuration_Extensibility_Management/","title":"Configuration & Extensibility","text":"<pre><code>graph LR\n    ConfigManager[\"ConfigManager\"]\n    PipelexConfig[\"PipelexConfig\"]\n    LibraryManager[\"LibraryManager\"]\n    PluginManager[\"PluginManager\"]\n    ConfigManager -- \"populates\" --&gt; PipelexConfig\n    ConfigManager -- \"provides configuration to\" --&gt; LibraryManager\n    ConfigManager -- \"provides configuration to\" --&gt; PluginManager\n    PipelexConfig -- \"is populated by\" --&gt; ConfigManager\n    PipelexConfig -- \"provides data to\" --&gt; LibraryManager\n    PipelexConfig -- \"provides data to\" --&gt; PluginManager\n    LibraryManager -- \"depends on\" --&gt; ConfigManager\n    LibraryManager -- \"utilizes\" --&gt; PipelexConfig\n    PluginManager -- \"depends on\" --&gt; ConfigManager\n    PluginManager -- \"utilizes\" --&gt; PipelexConfig</code></pre>"},{"location":"pages/advanced-customization/Configuration_Extensibility_Management/#details","title":"Details","text":"<p>This subsystem is responsible for managing all aspects of system configuration, workflow definitions, reusable components, and external plugins, ensuring the system's adaptability and future-proofing.</p>"},{"location":"pages/advanced-customization/Configuration_Extensibility_Management/#configmanager","title":"ConfigManager","text":"<p>Serves as the primary interface for loading, merging, and providing access to all system-wide and workflow-specific configuration settings. It handles the parsing of TOML-based definitions and ensures configuration consistency across the Pipelex ecosystem.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.tools.config.manager.ConfigManager</code> (22:222)</li> </ul>"},{"location":"pages/advanced-customization/Configuration_Extensibility_Management/#pipelexconfig","title":"PipelexConfig","text":"<p>Acts as the central data structure holding the loaded and validated configuration parameters for the entire Pipelex system. It provides a structured and accessible representation of all settings, including paths to libraries and plugin directories, enabling consistent access to configuration data.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.config.PipelexConfig</code> (113:116)</li> </ul>"},{"location":"pages/advanced-customization/Configuration_Extensibility_Management/#librarymanager","title":"LibraryManager","text":"<p>Orchestrates the discovery, loading, and validation of all workflow-related components (domains, concepts, pipes) defined in TOML files and registered Python classes. It acts as the central registry for reusable workflow building blocks, ensuring their availability and proper integration into the core engine.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.libraries.library_manager.Library_Manager</code></li> </ul>"},{"location":"pages/advanced-customization/Configuration_Extensibility_Management/#pluginmanager","title":"PluginManager","text":"<p>Manages the lifecycle of external plugins, including their discovery, loading, initialization, and teardown. This component is crucial for extending Pipelex's capabilities with new LLM providers, custom operators, or other integrations without modifying the core codebase, adhering to the microkernel/core-plugin pattern.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.plugins.plugin_manager.PluginManager</code> (8:26)</li> </ul>"},{"location":"pages/advanced-customization/Configuration_Extensibility_Management/#faq","title":"FAQ","text":""},{"location":"pages/advanced-customization/Core_Orchestration_Engine/","title":"Core Orchestration Engine","text":"<pre><code>graph LR\n    Pipelex_Core[\"Pipelex Core\"]\n    Configuration_Manager[\"Configuration Manager\"]\n    Pipeline_Manager[\"Pipeline Manager\"]\n    Pipe_Router[\"Pipe Router\"]\n    Pipelex_Core -- \"initializes and coordinates\" --&gt; Configuration_Manager\n    Pipelex_Core -- \"initializes and coordinates\" --&gt; Pipeline_Manager\n    Configuration_Manager -- \"provides parsed pipeline definitions to\" --&gt; Pipelex_Core\n    Configuration_Manager -- \"provides parsed pipeline definitions to\" --&gt; Pipeline_Manager\n    Pipeline_Manager -- \"delegates individual pipe execution to\" --&gt; Pipe_Router\n    Pipeline_Manager -- \"receives pipeline definitions from\" --&gt; Configuration_Manager\n    Pipe_Router -- \"receives execution requests from\" --&gt; Pipeline_Manager\n    Pipe_Router -- \"is initialized and coordinated by\" --&gt; Pipelex_Core</code></pre>"},{"location":"pages/advanced-customization/Core_Orchestration_Engine/#details","title":"Details","text":"<p>The <code>Core Orchestration Engine</code> subsystem is the heart of Pipelex, responsible for interpreting declarative pipeline definitions and managing the execution flow of individual operations. It embodies the core pipeline architecture pattern, ensuring that workflows are parsed, managed, and executed efficiently.</p>"},{"location":"pages/advanced-customization/Core_Orchestration_Engine/#pipelex-core","title":"Pipelex Core","text":"<p>The primary entry point and top-level orchestrator of the entire Pipelex system. It is responsible for the overall system lifecycle, including initializing and coordinating the main managers (Configuration, Pipeline, and Pipe Router), acting as the central hub that initiates the orchestration process.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.pipelex.Pipelex</code> (60:304)</li> </ul>"},{"location":"pages/advanced-customization/Core_Orchestration_Engine/#configuration-manager","title":"Configuration Manager","text":"<p>Dedicated to loading, parsing, and validating declarative pipeline definitions from TOML files. It ensures that workflows are correctly structured and provides the necessary configuration data to other core components for execution.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.config</code></li> </ul>"},{"location":"pages/advanced-customization/Core_Orchestration_Engine/#pipeline-manager","title":"Pipeline Manager","text":"<p>Manages the lifecycle of defined pipelines, including their registration, retrieval, and overall execution flow. It oversees the high-level orchestration of a complete pipeline, delegating the execution of individual pipes to the Pipe Router.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.pipeline.pipeline_manager.PipelineManager</code> (13:43)</li> </ul>"},{"location":"pages/advanced-customization/Core_Orchestration_Engine/#pipe-router","title":"Pipe Router","text":"<p>The core execution engine for individual 'pipes'. It dispatches execution requests for each pipe, manages data flow between them, and invokes the specific logic of each pipe operator. This component directly orchestrates the execution of individual steps within a pipeline.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.pipe_works.pipe_router.PipeRouter</code> (15:58)</li> </ul>"},{"location":"pages/advanced-customization/Core_Orchestration_Engine/#faq","title":"FAQ","text":""},{"location":"pages/advanced-customization/Data_Working_Memory/","title":"Data & Working Memory","text":"<pre><code>graph LR\n    WorkingMemory[\"WorkingMemory\"]\n    WorkingMemoryFactory[\"WorkingMemoryFactory\"]\n    Stuff[\"Stuff\"]\n    StuffContent[\"StuffContent\"]\n    StuffFactory[\"StuffFactory\"]\n    StuffContentFactory[\"StuffContentFactory\"]\n    WorkingMemory -- \"manages\" --&gt; Stuff\n    WorkingMemoryFactory -- \"creates\" --&gt; WorkingMemory\n    WorkingMemoryFactory -- \"uses\" --&gt; StuffFactory\n    Stuff -- \"contains\" --&gt; StuffContent\n    Stuff -- \"stored in\" --&gt; WorkingMemory\n    StuffContentFactory -- \"creates\" --&gt; StuffContent\n    StuffFactory -- \"creates\" --&gt; Stuff\n    StuffFactory -- \"delegates to\" --&gt; StuffContentFactory</code></pre>"},{"location":"pages/advanced-customization/Data_Working_Memory/#details","title":"Details","text":"<p>Abstract Components Overview</p>"},{"location":"pages/advanced-customization/Data_Working_Memory/#workingmemory","title":"WorkingMemory","text":"<p>Manages the dynamic state of the pipeline by storing and providing access to <code>Stuff</code> objects. It ensures data consistency and enables pipes to share and modify data throughout the workflow execution.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.core.working_memory</code></li> </ul>"},{"location":"pages/advanced-customization/Data_Working_Memory/#workingmemoryfactory","title":"WorkingMemoryFactory","text":"<p>Initializes <code>WorkingMemory</code> instances, potentially populating them with initial <code>Stuff</code> objects. It acts as a controlled entry point for setting up the pipeline's state.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.core.working_memory_factory</code></li> </ul>"},{"location":"pages/advanced-customization/Data_Working_Memory/#stuff","title":"Stuff","text":"<p>Encapsulates a single, typed data unit. It provides a consistent interface for accessing and manipulating its content, abstracting away the underlying data type. This is the fundamental data carrier within the pipeline.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.core.stuff</code></li> </ul>"},{"location":"pages/advanced-customization/Data_Working_Memory/#stuffcontent","title":"StuffContent","text":"<p>Holds the raw data and defines type-specific behaviors (e.g., rendering to string, JSON serialization). Subclasses handle specific data formats (text, image, PDF, structured data), ensuring proper data handling based on its type.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.core.stuff_content</code></li> </ul>"},{"location":"pages/advanced-customization/Data_Working_Memory/#stufffactory","title":"StuffFactory","text":"<p>Acts as a controlled entry point for creating <code>Stuff</code> objects, abstracting the complexity of <code>StuffContent</code> instantiation. It ensures that <code>Stuff</code> objects are correctly formed with their appropriate content.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.core.stuff_factory</code></li> </ul>"},{"location":"pages/advanced-customization/Data_Working_Memory/#stuffcontentfactory","title":"StuffContentFactory","text":"<p>Determines and instantiates the correct <code>StuffContent</code> subclass based on input data or specified types. This component is crucial for dynamic type handling and ensuring data integrity.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.core.stuff_factory</code></li> </ul>"},{"location":"pages/advanced-customization/Data_Working_Memory/#faq","title":"FAQ","text":""},{"location":"pages/advanced-customization/Observability_Reporting/","title":"Observability & Reporting","text":"<pre><code>graph LR\n    Pipeline_Tracker[\"Pipeline Tracker\"]\n    Reporting_Manager[\"Reporting Manager\"]\n    Logging_Core[\"Logging Core\"]\n    Log_Dispatcher[\"Log Dispatcher\"]\n    Cost_Registry[\"Cost Registry\"]\n    Mermaid_Utilities[\"Mermaid Utilities\"]\n    Exception_Handling[\"Exception Handling\"]\n    Pipeline_Tracker -- \"utilizes\" --&gt; Mermaid_Utilities\n    Pipeline_Tracker -- \"leverages\" --&gt; Exception_Handling\n    Reporting_Manager -- \"manages\" --&gt; Cost_Registry\n    Reporting_Manager -- \"uses\" --&gt; Logging_Core\n    Reporting_Manager -- \"leverages\" --&gt; Exception_Handling\n    Logging_Core -- \"delegates to\" --&gt; Log_Dispatcher\n    Cost_Registry -- \"provides data to\" --&gt; Reporting_Manager</code></pre>"},{"location":"pages/advanced-customization/Observability_Reporting/#details","title":"Details","text":"<p>This subsystem is critical for providing insights into pipeline execution, performance, and costs, thereby aiding in debugging and monitoring of AI workflows. It adheres to the Workflow Orchestration Engine / AI Workflow Framework patterns by centralizing monitoring and reporting functionalities, which are essential for managing complex, long-running processes.</p>"},{"location":"pages/advanced-customization/Observability_Reporting/#pipeline-tracker","title":"Pipeline Tracker","text":"<p>Responsible for monitoring and recording the execution flow, state, and key metrics of individual pipelines and their constituent pipes. It provides the raw data necessary for understanding pipeline behavior and identifying bottlenecks.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.reporting.tracker.PipelineTracker</code> (1:1)</li> </ul>"},{"location":"pages/advanced-customization/Observability_Reporting/#reporting-manager","title":"Reporting Manager","text":"<p>Aggregates and processes data collected from various sources (like the Pipeline Tracker and Cost Registry) to generate comprehensive reports on pipeline performance, costs, and overall operational health. It acts as the central hub for report generation.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.reporting.manager.ReportingManager</code> (1:1)</li> </ul>"},{"location":"pages/advanced-customization/Observability_Reporting/#logging-core","title":"Logging Core","text":"<p>Provides the foundational logging infrastructure for the entire system, centralizing the collection of events, warnings, and errors from various components. It ensures a consistent logging standard across the observability subsystem.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.logging.core.LoggingCore</code> (1:1)</li> </ul>"},{"location":"pages/advanced-customization/Observability_Reporting/#log-dispatcher","title":"Log Dispatcher","text":"<p>Handles the routing and distribution of log messages received from the Logging Core to various output destinations, such as console, files, or external monitoring systems. It ensures logs are delivered efficiently to where they are needed.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.logging.dispatcher.LogDispatcher</code> (1:1)</li> </ul>"},{"location":"pages/advanced-customization/Observability_Reporting/#cost-registry","title":"Cost Registry","text":"<p>Maintains a dedicated registry for tracking and registering costs associated with pipeline execution, particularly for resource-intensive operations like LLM API calls. This component is crucial for cost analysis and optimization.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.reporting.cost_registry.CostRegistry</code> (1:1)</li> </ul>"},{"location":"pages/advanced-customization/Observability_Reporting/#mermaid-utilities","title":"Mermaid Utilities","text":"<p>Offers utility functions specifically designed to generate Mermaid syntax, enabling the creation of visual diagrams (e.g., flowcharts) that represent pipeline structures and execution flows, aiding in visual debugging and understanding.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.reporting.mermaid.MermaidUtilities</code> (1:1)</li> </ul>"},{"location":"pages/advanced-customization/Observability_Reporting/#exception-handling","title":"Exception Handling","text":"<p>Provides a centralized and consistent mechanism for catching, processing, and reporting exceptions across the system. Within the observability context, it ensures that errors are properly logged and can be integrated into reports for debugging and monitoring.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.common.exception_handling.ExceptionHandling</code> (1:1)</li> </ul>"},{"location":"pages/advanced-customization/Observability_Reporting/#faq","title":"FAQ","text":""},{"location":"pages/advanced-customization/Pipe_Operators/","title":"Pipe Operators","text":"<pre><code>graph LR\n    Pipe_Operator_Base[\"Pipe Operator Base\"]\n    Specialized_Pipe_Operators[\"Specialized Pipe Operators\"]\n    Pipe_Abstract[\"Pipe Abstract\"]\n    Core_Engine[\"Core Engine\"]\n    LLM_Adapters_Providers[\"LLM Adapters/Providers\"]\n    Input_Output_Management[\"Input/Output Management\"]\n    Pipe_Operator_Factories[\"Pipe Operator Factories\"]\n    Configuration_Layer[\"Configuration Layer\"]\n    Pipe_Operator_Base -- \"inherits from\" --&gt; Pipe_Abstract\n    Pipe_Operator_Base -- \"interacts with\" --&gt; Input_Output_Management\n    Specialized_Pipe_Operators -- \"inherits from\" --&gt; Pipe_Operator_Base\n    Specialized_Pipe_Operators -- \"utilizes\" --&gt; LLM_Adapters_Providers\n    Pipe_Abstract -- \"extended by\" --&gt; Pipe_Operator_Base\n    Core_Engine -- \"executes\" --&gt; Pipe_Operator_Base\n    Core_Engine -- \"receives results from\" --&gt; Pipe_Operator_Base\n    LLM_Adapters_Providers -- \"provides services to\" --&gt; Specialized_Pipe_Operators\n    Input_Output_Management -- \"manages data for\" --&gt; Pipe_Operator_Base\n    Pipe_Operator_Factories -- \"creates instances of\" --&gt; Specialized_Pipe_Operators\n    Configuration_Layer -- \"provides settings to\" --&gt; Pipe_Operator_Base</code></pre>"},{"location":"pages/advanced-customization/Pipe_Operators/#details","title":"Details","text":"<p>Abstract Components Overview of the Pipelex system.</p>"},{"location":"pages/advanced-customization/Pipe_Operators/#pipe-operator-base","title":"Pipe Operator Base","text":"<p>The abstract base class (pipelex.pipe_operators.pipe_operator) that defines the common interface and core execution logic for all specialized pipe operators. It ensures a standardized contract for how individual operations integrate into a pipeline.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.pipe_operators.pipe_operator</code></li> </ul>"},{"location":"pages/advanced-customization/Pipe_Operators/#specialized-pipe-operators","title":"Specialized Pipe Operators","text":"<p>Concrete implementations of the Pipe Operator Base, each designed for a specific task. This includes pipelex.pipe_operators.pipe_llm (for LLM calls), pipelex.pipe_operators.pipe_img_gen (for image generation), pipelex.pipe_operators.pipe_ocr (for OCR), pipelex.pipe_operators.pipe_func (for custom Python functions), and pipelex.pipe_operators.pipe_jinja2 (for templating).</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.pipe_operators.pipe_llm</code></li> <li><code>pipelex.pipe_operators.pipe_img_gen</code></li> <li><code>pipelex.pipe_operators.pipe_ocr</code></li> <li><code>pipelex.pipe_operators.pipe_func</code></li> <li><code>pipelex.pipe_operators.pipe_jinja2</code></li> </ul>"},{"location":"pages/advanced-customization/Pipe_Operators/#pipe-abstract","title":"Pipe Abstract","text":"<p>The most fundamental abstract base (pipelex.core.pipe_abstract.PipeAbstract) that establishes the absolute minimum interface required for any component to be considered a \"pipe\" within the Pipelex system. Pipe Operator Base extends this.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.core.pipe_abstract.PipeAbstract</code> (13:81)</li> </ul>"},{"location":"pages/advanced-customization/Pipe_Operators/#core-engine","title":"Core Engine","text":"<p>The central orchestration component responsible for parsing pipeline definitions, managing the execution flow, and invoking Pipe Operators in the correct sequence (sequential, parallel, conditional).</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.core</code></li> </ul>"},{"location":"pages/advanced-customization/Pipe_Operators/#llm-adaptersproviders","title":"LLM Adapters/Providers","text":"<p>A set of modules that abstract the complexities of interacting with various Large Language Model services (e.g., Anthropic, Google, Mistral AI). They provide a consistent API for PipeLLM to consume.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.llms</code></li> </ul>"},{"location":"pages/advanced-customization/Pipe_Operators/#inputoutput-management","title":"Input/Output Management","text":"<p>Handles the standardized flow of data into and out of individual Pipe Operators, ensuring data consistency, type validation, and proper transfer between pipeline stages.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.io</code></li> </ul>"},{"location":"pages/advanced-customization/Pipe_Operators/#pipe-operator-factories","title":"Pipe Operator Factories","text":"<p>Responsible for dynamically creating instances of Specialized Pipe Operators at runtime, typically based on declarative workflow definitions (e.g., TOML files) and associated blueprints.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.factories</code></li> </ul>"},{"location":"pages/advanced-customization/Pipe_Operators/#configuration-layer","title":"Configuration Layer","text":"<p>Manages and provides system-wide and pipeline-specific configuration settings, which influence the behavior and parameters of Pipe Operators during their instantiation and execution.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.config</code></li> </ul>"},{"location":"pages/advanced-customization/Pipe_Operators/#faq","title":"FAQ","text":""},{"location":"pages/advanced-customization/activity-manager-injection/","title":"Activity Manager Injection","text":"<p>\u26a0\ufe0f Under construction</p>"},{"location":"pages/advanced-customization/content-generator-injection/","title":"Content Generator Injection","text":"<p>\u26a0\ufe0f Under construction</p>"},{"location":"pages/advanced-customization/inference-manager-injection/","title":"Inference Manager Injection","text":"<p>\u26a0\ufe0f Under construction</p>"},{"location":"pages/advanced-customization/llm-model-provider-injection/","title":"LLM Model Provider Injection","text":"<p>\u26a0\ufe0f Under construction</p>"},{"location":"pages/advanced-customization/on_boarding/","title":"Architecture Overview","text":"<pre><code>graph LR\n    Core_Orchestration_Engine[\"Core Orchestration Engine\"]\n    Pipe_Operators[\"Pipe Operators\"]\n    AI_Integration_Layer[\"AI Integration Layer\"]\n    Configuration_Extensibility_Management[\"Configuration &amp; Extensibility Management\"]\n    Data_Working_Memory[\"Data &amp; Working Memory\"]\n    Client_API_Layer[\"Client &amp; API Layer\"]\n    Observability_Reporting[\"Observability &amp; Reporting\"]\n    Core_Orchestration_Engine -- \"orchestrates execution of\" --&gt; Pipe_Operators\n    Core_Orchestration_Engine -- \"manages data flow with\" --&gt; Data_Working_Memory\n    Core_Orchestration_Engine -- \"loads configurations from\" --&gt; Configuration_Extensibility_Management\n    Core_Orchestration_Engine -- \"sends metrics to\" --&gt; Observability_Reporting\n    Client_API_Layer -- \"interacts with\" --&gt; Core_Orchestration_Engine\n    Pipe_Operators -- \"sends AI inference requests to\" --&gt; AI_Integration_Layer\n    AI_Integration_Layer -- \"utilizes configurations/plugins from\" --&gt; Configuration_Extensibility_Management\n    AI_Integration_Layer -- \"sends metrics to\" --&gt; Observability_Reporting\n    Pipe_Operators -- \"interacts with\" --&gt; Data_Working_Memory\n    click Core_Orchestration_Engine href \"https://github.com/Pipelex/pipelex/blob/main/.codeboarding/Core_Orchestration_Engine.md\" \"Details\"\n    click Pipe_Operators href \"https://github.com/Pipelex/pipelex/blob/main/.codeboarding/Pipe_Operators.md\" \"Details\"\n    click AI_Integration_Layer href \"https://github.com/Pipelex/pipelex/blob/main/.codeboarding/AI_Integration_Layer.md\" \"Details\"\n    click Configuration_Extensibility_Management href \"https://github.com/Pipelex/pipelex/blob/main/.codeboarding/Configuration_Extensibility_Management.md\" \"Details\"\n    click Data_Working_Memory href \"https://github.com/Pipelex/pipelex/blob/main/.codeboarding/Data_Working_Memory.md\" \"Details\"\n    click Client_API_Layer href \"https://github.com/Pipelex/pipelex/blob/main/.codeboarding/Client_API_Layer.md\" \"Details\"\n    click Observability_Reporting href \"https://github.com/Pipelex/pipelex/blob/main/.codeboarding/Observability_Reporting.md\" \"Details\"</code></pre>"},{"location":"pages/advanced-customization/on_boarding/#core-orchestration-engine-expand","title":"Core Orchestration Engine [Expand]","text":"<p>Parses declarative TOML pipeline definitions, orchestrating the execution flow of individual Pipe Operators.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.pipelex.Pipelex</code> (60:304)</li> <li><code>pipelex.pipe_works.pipe_router.PipeRouter</code> (15:58)</li> <li><code>pipelex.pipeline.pipeline_manager.PipelineManager</code> (13:43)</li> </ul>"},{"location":"pages/advanced-customization/on_boarding/#pipe-operators-expand","title":"Pipe Operators [Expand]","text":"<p>Reusable, modular units encapsulating specific tasks like LLM calls, image generation, or custom functions.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.pipe_operators.pipe_operator</code></li> <li><code>pipelex.pipe_operators.pipe_llm</code></li> <li><code>pipelex.pipe_operators.pipe_img_gen</code></li> <li><code>pipelex.pipe_operators.pipe_ocr</code></li> <li><code>pipelex.pipe_operators.pipe_func</code></li> <li><code>pipelex.pipe_operators.pipe_jinja2</code></li> </ul>"},{"location":"pages/advanced-customization/on_boarding/#ai-integration-layer-expand","title":"AI Integration Layer [Expand]","text":"<p>Provides a unified interface to various AI service providers, abstracting away their specific APIs, and is utilized by the Pipe Operators for AI-related tasks.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.cogt.inference.inference_manager</code></li> <li><code>pipelex.cogt.llm</code></li> <li><code>pipelex.cogt.imgg</code></li> <li><code>pipelex.cogt.ocr</code></li> </ul>"},{"location":"pages/advanced-customization/on_boarding/#configuration-extensibility-management-expand","title":"Configuration &amp; Extensibility Management [Expand]","text":"<p>Manages all workflow definitions, reusable components, and external plugins, which ensures the system's adaptability and future-proofing.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.config.PipelexConfig</code> (113:116)</li> <li><code>pipelex.tools.config.manager</code></li> <li><code>pipelex.plugins.plugin_manager.PluginManager</code> (8:26)</li> <li><code>pipelex.libraries.library_manager.LibraryManager</code> (55:405)</li> </ul>"},{"location":"pages/advanced-customization/on_boarding/#data-working-memory-expand","title":"Data &amp; Working Memory [Expand]","text":"<p>Handles data flow and state within pipelines, providing a shared context for seamless information exchange between pipes.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.core.working_memory.WorkingMemory</code> (38:375)</li> <li><code>pipelex.core.working_memory_factory</code></li> <li><code>pipelex.core.stuff</code></li> <li><code>pipelex.core.stuff_content</code></li> </ul>"},{"location":"pages/advanced-customization/on_boarding/#client-api-layer-expand","title":"Client &amp; API Layer [Expand]","text":"<p>Facilitates external interaction with the engine.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.cli._cli</code></li> <li><code>pipelex.pipelex.Pipelex</code> (60:304)</li> </ul>"},{"location":"pages/advanced-customization/on_boarding/#observability-reporting-expand","title":"Observability &amp; Reporting [Expand]","text":"<p>Provides crucial insights into pipeline execution, performance, and costs, aiding in debugging and monitoring.</p> <p>Related Classes/Methods:</p> <ul> <li><code>pipelex.reporting.reporting_manager.ReportingManager</code> (29:121)</li> <li><code>pipelex.pipeline.track.pipeline_tracker.PipelineTracker</code> (29:357)</li> <li><code>pipelex.tools.log.log</code></li> </ul>"},{"location":"pages/advanced-customization/on_boarding/#faq","title":"FAQ","text":""},{"location":"pages/advanced-customization/pipe-router-injection/","title":"Pipe Router Injection","text":"<p>\u26a0\ufe0f Under construction</p>"},{"location":"pages/advanced-customization/pipeline-tracker-injection/","title":"Pipeline Tracker Injection","text":"<p>\u26a0\ufe0f Under construction</p>"},{"location":"pages/advanced-customization/plugin-manager-injection/","title":"Plugin Manager Injection","text":"<p>\u26a0\ufe0f Under construction</p>"},{"location":"pages/advanced-customization/reporting-delegate-injection/","title":"Reporting Delegate Injection","text":"<p>\u26a0\ufe0f Under construction</p>"},{"location":"pages/advanced-customization/secrets-provider-injection/","title":"Secrets Provider Injection","text":"<p>\u26a0\ufe0f Under construction</p>"},{"location":"pages/advanced-customization/storage-provider-ingestion/","title":"Storage Provider Injection","text":"<p>\u26a0\ufe0f Under construction</p>"},{"location":"pages/advanced-customization/template-provider-injection/","title":"Template Provider Injection","text":"<p>\u26a0\ufe0f Under construction</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/adapt-to-llm-prompting-style-openai-anthropic-mistral/","title":"Prompting Configuration","text":"<p>The <code>PromptingConfig</code> class controls how Pipelex handles prompting styles for different LLM targets.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/adapt-to-llm-prompting-style-openai-anthropic-mistral/#configuration-options","title":"Configuration Options","text":"<pre><code>class PromptingConfig(ConfigModel):\n    default_prompting_style: PromptingStyle\n    prompting_styles: Dict[str, PromptingStyle]\n</code></pre>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/adapt-to-llm-prompting-style-openai-anthropic-mistral/#fields","title":"Fields","text":"<ul> <li><code>default_prompting_style</code>: The default prompting style to use when none is specified</li> <li><code>prompting_styles</code>: Dictionary mapping LLM targets to their specific prompting styles</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/adapt-to-llm-prompting-style-openai-anthropic-mistral/#prompting-styles","title":"Prompting Styles","text":"<p>Each prompting style defines how prompts are formatted and presented to the LLM. The style can be customized per LLM target to optimize performance and ensure compatibility.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/adapt-to-llm-prompting-style-openai-anthropic-mistral/#example-configuration","title":"Example Configuration","text":"<pre><code>[pipelex.prompting_config]\ndefault_prompting_style = \"chat\"\n\n[pipelex.prompting_config.prompting_styles]\ngpt4 = \"chat\"\nclaude = \"instruction\"\nllama = \"completion\"\n</code></pre>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/adapt-to-llm-prompting-style-openai-anthropic-mistral/#usage","title":"Usage","text":"<p>The configuration provides a method to get the appropriate prompting style:</p> <pre><code>def get_prompting_style(self, prompting_target: Optional[LLMPromptingTarget] = None) -&gt; Optional[PromptingStyle]:\n    if prompting_target:\n        return self.prompting_styles.get(prompting_target, self.default_prompting_style)\n    else:\n        return None\n</code></pre> <p>This allows for:</p> <ul> <li>Target-specific prompting styles</li> <li>Fallback to default style when no specific style is defined</li> <li>Optional prompting when no target is specified</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/adapt-to-llm-prompting-style-openai-anthropic-mistral/#best-practices","title":"Best Practices","text":"<ul> <li>Define a sensible default prompting style</li> <li>Configure specific styles for LLMs with unique requirements</li> <li>Test prompting styles with each LLM target</li> <li>Document any special formatting requirements</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/ai-plugins-for-multi-llm-workflows/","title":"Plugins Configuration","text":"<p>The Plugins Configuration manages all external service integrations in Pipelex, including various LLM providers and image generation services.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/ai-plugins-for-multi-llm-workflows/#overview","title":"Overview","text":"<pre><code>[pipelex.plugins]\n# Plugin sections\n[pipelex.plugins.anthropic_config]\n[pipelex.plugins.azure_openai_config]\n[pipelex.plugins.bedrock_config]\n[pipelex.plugins.vertexai_config]\n[pipelex.plugins.mistral_config]\n[pipelex.plugins.openai_config]\n[pipelex.plugins.perplexity_config]\n[pipelex.plugins.xai_config]\n[pipelex.plugins.custom_endpoint_config]\n[pipelex.plugins.fal_config]\n</code></pre>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/ai-plugins-for-multi-llm-workflows/#common-authentication-methods","title":"Common Authentication Methods","text":"<p>Most plugins support two authentication methods:</p> <ul> <li><code>ENV</code>: Read credentials from environment variables</li> <li><code>SECRET_PROVIDER</code>: Read credentials from a secrets provider</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/ai-plugins-for-multi-llm-workflows/#plugin-specific-configurations","title":"Plugin-Specific Configurations","text":""},{"location":"pages/build-reliable-ai-workflows-with-pipelex/ai-plugins-for-multi-llm-workflows/#1-anthropic-configuration","title":"1. Anthropic Configuration","text":"<pre><code>[pipelex.plugins.anthropic_config]\n# Use 8192 for better streaming/timeout handling, or \"unlimited\" for full 32/64K tokens (Opus/Sonnet)\nclaude_4_reduced_tokens_limit = 8192\napi_key_method = \"env\"  # or \"secret_provider\"\n</code></pre> <p>Environment Variables:</p> <ul> <li><code>ANTHROPIC_API_KEY</code>: API key for Anthropic services</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/ai-plugins-for-multi-llm-workflows/#2-azure-openai-configuration","title":"2. Azure OpenAI Configuration","text":"<pre><code>[pipelex.plugins.azure_openai_config]\napi_key_method = \"env\"  # or \"secret_provider\"\n</code></pre> <p>Environment Variables:</p> <ul> <li><code>AZURE_OPENAI_API_KEY</code>: API key</li> <li><code>AZURE_OPENAI_API_ENDPOINT</code>: API endpoint URL</li> <li><code>AZURE_OPENAI_API_VERSION</code>: API version</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/ai-plugins-for-multi-llm-workflows/#3-aws-bedrock-configuration","title":"3. AWS Bedrock Configuration","text":"<pre><code>[pipelex.plugins.bedrock_config]\nclient_method = \"aioboto3\"  # or \"boto3\"\n</code></pre> <p>Environment Variables:</p> <ul> <li><code>AWS_REGION</code>: AWS region for Bedrock services</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/ai-plugins-for-multi-llm-workflows/#4-google-vertex-ai-configuration","title":"4. Google Vertex AI Configuration","text":"<pre><code>[pipelex.plugins.vertexai_config]\napi_key_method = \"env\"  # or \"secret_provider\"\n</code></pre> <p>Environment Variables:</p> <ul> <li><code>GCP_PROJECT_ID</code>: Google Cloud project ID</li> <li><code>GCP_REGION</code>: Google Cloud region</li> <li><code>GCP_CREDENTIALS_FILE_PATH</code>: Path to service account credentials file</li> </ul> <p>Dependencies:</p> <ul> <li>Requires <code>google-auth-oauthlib</code> package (<code>pip install pipelex[google]</code>)</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/ai-plugins-for-multi-llm-workflows/#5-mistral-configuration","title":"5. Mistral Configuration","text":"<pre><code>[pipelex.plugins.mistral_config]\napi_key_method = \"env\"  # or \"secret_provider\"\n</code></pre> <p>Environment Variables:</p> <ul> <li><code>MISTRAL_API_KEY</code>: API key for Mistral services</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/ai-plugins-for-multi-llm-workflows/#6-openai-configuration","title":"6. OpenAI Configuration","text":"<pre><code>[pipelex.plugins.openai_config]\nimage_output_compression = 100  # 1-100\napi_key_method = \"env\"  # or \"secret_provider\"\n</code></pre> <p>Environment Variables:</p> <ul> <li><code>OPENAI_API_KEY</code>: API key for OpenAI services</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/ai-plugins-for-multi-llm-workflows/#7-perplexity-configuration","title":"7. Perplexity Configuration","text":"<pre><code>[pipelex.plugins.perplexity_config]\napi_key_method = \"env\"  # or \"secret_provider\"\n</code></pre> <p>Environment Variables:</p> <ul> <li><code>PERPLEXITY_API_KEY</code>: API key</li> <li><code>PERPLEXITY_API_ENDPOINT</code>: API endpoint URL</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/ai-plugins-for-multi-llm-workflows/#8-xai-configuration","title":"8. XAI Configuration","text":"<pre><code>[pipelex.plugins.xai_config]\napi_key_method = \"env\"  # or \"secret_provider\"\n</code></pre> <p>Environment Variables:</p> <ul> <li><code>XAI_API_KEY</code>: API key</li> <li><code>XAI_API_ENDPOINT</code>: API endpoint URL</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/ai-plugins-for-multi-llm-workflows/#9-custom-endpoint-configuration","title":"9. Custom Endpoint Configuration","text":"<p>For custom OpenAI-compatible endpoints (e.g., Ollama, LM Studio):</p> <pre><code>[pipelex.plugins.custom_endpoint_config]\napi_key_method = \"env\"  # or \"secret_provider\"\n</code></pre> <p>Environment Variables:</p> <ul> <li><code>CUSTOM_ENDPOINT_API_KEY</code>: Optional API key</li> <li><code>CUSTOM_ENDPOINT_BASE_URL</code>: Base URL for the custom endpoint</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/ai-plugins-for-multi-llm-workflows/#10-fal-configuration","title":"10. FAL Configuration","text":"<p>Configuration for FAL image generation services:</p> <pre><code>[pipelex.plugins.fal_config]\n# Quality to steps mapping for Flux model\nflux_map_quality_to_steps = { \n    \"low\" = 14,\n    \"medium\" = 28,\n    \"high\" = 56\n}\n\n# Quality to steps mapping for SDXL Lightning model\nsdxl_lightning_map_quality_to_steps = {\n    \"low\" = 2,\n    \"medium\" = 4,\n    \"high\" = 8\n}\n</code></pre>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/ai-plugins-for-multi-llm-workflows/#error-handling","title":"Error Handling","text":"<p>Each plugin has its own error types:</p> <ul> <li><code>AnthropicCredentialsError</code></li> <li><code>AzureOpenAICredentialsError</code></li> <li><code>BedrockCredentialsError</code></li> <li><code>VertexAICredentialsError</code></li> <li><code>MistralCredentialsError</code></li> <li><code>OpenAICredentialsError</code></li> <li><code>PerplexityCredentialsError</code></li> <li><code>XaiCredentialsError</code></li> <li><code>CustomEndpointCredentialsError</code></li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/ai-plugins-for-multi-llm-workflows/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Credentials Management:</p> <ul> <li>Use environment variables for local development</li> <li>Use secrets provider for production environments</li> <li>Never commit credentials to version control</li> </ul> </li> <li> <p>Error Handling:</p> <ul> <li>Always handle credential errors appropriately</li> <li>Implement proper fallbacks when using multiple providers</li> <li>Check for required dependencies (especially for Google services)</li> </ul> </li> <li> <p>Configuration:</p> <ul> <li>Set appropriate quality levels for image generation</li> <li>Configure retry limits and timeouts</li> <li>Use appropriate client methods for async/sync operations</li> </ul> </li> </ol>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/ai-plugins-for-multi-llm-workflows/#example-complete-configuration","title":"Example Complete Configuration","text":"<pre><code>[pipelex.plugins]\n\n[pipelex.plugins.anthropic_config]\nclaude_4_reduced_tokens_limit = 8192  # Use \"unlimited\" for full 32/64K tokens\napi_key_method = \"env\"\n\n[pipelex.plugins.azure_openai_config]\napi_key_method = \"env\"\n\n[pipelex.plugins.bedrock_config]\nclient_method = \"aioboto3\"\n\n[pipelex.plugins.vertexai_config]\napi_key_method = \"env\"\n\n[pipelex.plugins.mistral_config]\napi_key_method = \"env\"\n\n[pipelex.plugins.openai_config]\nimage_output_compression = 100\napi_key_method = \"env\"\n\n[pipelex.plugins.perplexity_config]\napi_key_method = \"env\"\n\n[pipelex.plugins.xai_config]\napi_key_method = \"env\"\n\n[pipelex.plugins.custom_endpoint_config]\napi_key_method = \"env\"\n\n[pipelex.plugins.fal_config]\nflux_map_quality_to_steps = { \"low\" = 14, \"medium\" = 28, \"high\" = 56 }\nsdxl_lightning_map_quality_to_steps = { \"low\" = 2, \"medium\" = 4, \"high\" = 8 }\n</code></pre>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/configure-ai-llm-to-optimize-workflows/","title":"LLM Settings Guide","text":""},{"location":"pages/build-reliable-ai-workflows-with-pipelex/configure-ai-llm-to-optimize-workflows/#overview","title":"Overview","text":"<p>Pipelex provides a flexible way to configure and manage your LLM (Large Language Model) integrations through three main concepts:</p> <ul> <li>LLM Handles</li> <li>LLM Presets</li> <li>LLM Deck</li> </ul> <p>Those configuration are present in the <code>pipelex_libraries/llm_deck</code> directory.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/configure-ai-llm-to-optimize-workflows/#llm-handles","title":"LLM Handles","text":"<p>An LLM handle is a unique identifier that maps to a specific LLM configuration. It defines:</p> <ul> <li>The LLM name (e.g., <code>gpt-4o-mini</code>, <code>claude-4-sonnet</code>, <code>mistral-large</code>, <code>gemini-2.5-flash</code>)</li> <li>The model version</li> <li>The platform-specific settings (OpenAI, Anthropic, etc...)</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/configure-ai-llm-to-optimize-workflows/#example-handle-configurations","title":"Example Handle Configurations","text":"<pre><code>[llm_handles]\ngpt-4o-2024-11-20 = { llm_name = \"gpt-4o\", llm_version = \"2024-11-20\" }\n</code></pre> <p>There's a much simpler syntax if you want a handle to the latest version and default platform:</p> <pre><code>[llm_handles]\nbest-claude = \"claude-4-opus\"\n</code></pre> <p>\ud83d\udca1 Defining a llm_handle is alway meant to describe what model it is. Never define a llm_handle to describe what it is for or what it's good at. LLM Settings are for that.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/configure-ai-llm-to-optimize-workflows/#llm-settings-llm-presets","title":"LLM Settings &amp; LLM Presets","text":"<p>LLM Settings combine an LLM handle with specific parameters optimized for particular tasks. They help maintain consistency across similar operations and make it easier to switch between different configurations.</p> <p>An LLM Preset is simply a name for a LLM Settings that you have predefined in order to use it in various places.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/configure-ai-llm-to-optimize-workflows/#example-llm-preset-definitions","title":"Example LLM Preset definitions","text":"<pre><code>[llm_presets]\n\nllm_to_reason = { \n    llm_handle = \"gpt-4-turbo\", \n    temperature = 0.7, \n    max_tokens = \"auto\" \n}\n\nllm_to_extract = { \n    llm_handle = \"claude-4-sonnet\", \n    temperature = 0.1, \n    max_tokens = \"auto\" \n}\n</code></pre>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/configure-ai-llm-to-optimize-workflows/#using-llm-settings-in-pipelines","title":"Using LLM Settings in Pipelines","text":"<p>Here's how to use these configurations in your pipelines:</p> <pre><code>[pipe.generate_response]\nPipeLLM = \"Generate a creative response\"\ninputs = { question = \"Question\" }\noutput = \"Response\"\nllm = {\n    llm_handle = \"gpt-4-turbo\",  # Using inline LLM settings\n    temperature = 0.8,\n    max_tokens = \"auto\",\n}\nprompt = \"\"\"\nGenerate a creative response to this question:\n\n@question\n\"\"\"\n\n[pipe.extract_weather_data]\nPipeLLM = \"Extract structured weather data from text\"\ninputs = { text = \"Text\" }\noutput = \"WeatherData\"\nllm = \"llm_to_extract\"  # Using a preset\nprompt = \"\"\"\nExtract the weather data from this text:\n\n@text\n\"\"\"\n</code></pre>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/configure-ai-llm-to-optimize-workflows/#llm-deck","title":"LLM Deck","text":"<p>The LLM deck is your central configuration hub for all LLM-related settings. It's stored in the <code>pipelex_libraries/llm_deck</code> directory and consists of:</p> <ul> <li><code>base_llm_deck.toml</code>: Core LLM configurations</li> <li><code>overrides.toml</code>: Custom overrides for specific use cases</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/configure-ai-llm-to-optimize-workflows/#directory-structure","title":"Directory Structure","text":"<pre><code>pipelex_libraries/\n\u2514\u2500\u2500 llm_deck/\n    \u251c\u2500\u2500 base_llm_deck.toml\n    \u2514\u2500\u2500 overrides.toml\n</code></pre>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/configure-ai-llm-to-optimize-workflows/#best-practices","title":"Best Practices","text":"<ol> <li>Consistent Naming: Use clear, descriptive names for handles and presets</li> <li>Task-Specific Presets: Create presets optimized for specific skills and tasks</li> <li>Cost Management: Consider using different models based on task complexity and cost requirements</li> </ol>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/define_your_concepts/","title":"Defining Your Concepts","text":"<p>Concepts are the foundation of reliable knowledge pipelines. They define what flows through your pipes\u2014not just as data types, but as meaningful pieces of knowledge with clear boundaries and validation rules.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/define_your_concepts/#writing-concept-definitions","title":"Writing Concept Definitions","text":"<p>Every concept starts with a natural language definition. This definition serves two audiences: developers who build with your pipeline, and the LLMs that process your knowledge.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/define_your_concepts/#basic-concept-definition","title":"Basic Concept Definition","text":"<p>The simplest way to define a concept is with a descriptive sentence:</p> <pre><code>[concept]\nInvoice = \"A commercial document issued by a seller to a buyer\"\nEmployee = \"A person employed by an organization\"\nProductReview = \"A customer's evaluation of a product or service\"\n</code></pre> <p>Key principles for concept definitions:</p> <ol> <li> <p>Define what it is, not what it's for <pre><code># \u274c Wrong: includes usage context\nTextToSummarize = \"Text that needs to be summarized\"\n\n# \u2705 Right: defines the essence\nArticle = \"A written composition on a specific topic\"\n</code></pre></p> </li> <li> <p>Use singular forms <pre><code># \u274c Wrong: plural form\nInvoices = \"Commercial documents from sellers\"\n\n# \u2705 Right: singular form\nInvoice = \"A commercial document issued by a seller to a buyer\"\n</code></pre></p> </li> <li> <p>Avoid unnecessary adjectives <pre><code># \u274c Wrong: includes subjective qualifier\nLongArticle = \"A lengthy written composition\"\n\n# \u2705 Right: neutral definition\nArticle = \"A written composition on a specific topic\"\n</code></pre></p> </li> </ol>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/define_your_concepts/#organizing-related-concepts","title":"Organizing Related Concepts","text":"<p>Group concepts that naturally belong together in the same domain. A domain acts as a namespace for a set of related concepts and pipes, helping you organize and reuse your pipeline components. You can learn more about them in Kick off a Knowledge Pipeline Project.</p> <pre><code># pipelex_libraries/pipelines/finance.toml\ndomain = \"finance\"\ndescription = \"Financial document processing\"\n\n[concept]\nInvoice = \"A commercial document issued by a seller to a buyer\"\nReceipt = \"Proof of payment for goods or services\"\nPurchaseOrder = \"A buyer's formal request to purchase goods or services\"\nPaymentTerms = \"Conditions under which payment is to be made\"\nLineItem = \"An individual item or service listed in a financial document\"\n</code></pre>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/define_your_concepts/#adding-structure-with-python-models","title":"Adding Structure with Python Models","text":"<p>While text definitions help LLMs understand your concepts, Python models ensure structured, validated outputs. This combination gives you the best of both worlds: AI flexibility with software reliability.</p> <p>Important: If you don't create a Python class for a concept, it defaults to text-based content. Only create Python models when you need structured output with specific fields.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/define_your_concepts/#creating-your-first-structured-model","title":"Creating Your First Structured Model","text":"<p>For each concept that needs structured output, create a corresponding Python class:</p> <pre><code># pipelex_libraries/pipelines/finance.py\nfrom datetime import datetime\nfrom typing import List, Optional\nfrom pydantic import Field\nfrom pipelex.core.stuff_content import StructuredContent\n\nclass Invoice(StructuredContent):\n    invoice_number: str\n    issue_date: datetime\n    due_date: datetime\n    vendor_name: str\n    customer_name: str\n    total_amount: float = Field(ge=0, description=\"Total invoice amount\")\n    currency: str = Field(default=\"USD\", description=\"Three-letter currency code\")\n    line_items: List[str] = Field(default_factory=list)\n</code></pre> <p>The model name must match the concept name exactly: <code>Invoice</code> concept \u2192 <code>Invoice</code> class.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/define_your_concepts/#basic-validation-examples","title":"Basic Validation Examples","text":"<p>Use Pydantic's validation features to ensure data quality:</p> <pre><code>from pydantic import field_validator\nfrom pipelex.core.stuff_content import StructuredContent\n\nclass Employee(StructuredContent):\n    name: str\n    email: str\n    department: str\n    years_of_experience: int = Field(ge=0, le=50, description=\"Years of work experience\")\n\n    @field_validator(\"email\")\n    @classmethod\n    def validate_email(cls, v: str) -&gt; str:\n        if \"@\" not in v:\n            raise ValueError(\"Invalid email format\")\n        return v.lower()\n\nclass ProductReview(StructuredContent):\n    product_name: str\n    reviewer_name: str\n    rating: int = Field(ge=1, le=5, description=\"Rating from 1 to 5 stars\")\n    review_text: str\n    verified_purchase: bool = False\n</code></pre>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/define_your_concepts/#working-with-optional-fields","title":"Working with Optional Fields","text":"<p>Not all data is always available. Use Optional fields with sensible defaults:</p> <pre><code>from typing import Optional\nfrom datetime import datetime\nfrom pipelex.core.stuff_content import StructuredContent\n\nclass Meeting(StructuredContent):\n    title: str\n    scheduled_date: datetime\n    duration_minutes: int = Field(ge=15, le=480, description=\"Meeting duration\")\n    location: Optional[str] = None\n    attendees: List[str] = Field(default_factory=list)\n    notes: Optional[str] = None\n    is_recurring: bool = False\n</code></pre>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/define_your_concepts/#linking-concepts-to-models","title":"Linking Concepts to Models","text":"<p>The connection between TOML definitions and Python models happens automatically through naming:</p> <pre><code># pipelex_libraries/pipelines/hr.toml\ndomain = \"hr\"\n\n[concept]\nEmployee = \"A person employed by an organization\"\nMeeting = \"A scheduled gathering of people for discussion\"\nPerformanceReview = \"An evaluation of an employee's work performance\"\nDepartment = \"An organizational unit within a company\"  # No Python model =&gt; text-based\n</code></pre> <pre><code># pipelex_libraries/pipelines/hr.py\nfrom pipelex.core.stuff_content import StructuredContent\nfrom datetime import datetime\nfrom typing import List, Optional\n\n# Only define models for concepts that need structure\nclass Employee(StructuredContent):\n    name: str\n    email: str\n    department: str\n    hire_date: datetime\n\nclass Meeting(StructuredContent):\n    title: str\n    scheduled_date: datetime\n    duration_minutes: int\n    attendees: List[str]\n\nclass PerformanceReview(StructuredContent):\n    employee_name: str\n    review_period: str\n    rating: int = Field(ge=1, le=5)\n    strengths: List[str]\n    areas_for_improvement: List[str]\n\n# Note: Department concept has no Python model, so it's text-based\n</code></pre>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/define_your_concepts/#concept-refinement-and-inheritance","title":"Concept Refinement and Inheritance","text":"<p>Sometimes concepts build on each other. A <code>Contract</code> is a kind of <code>Document</code>. A <code>NonCompeteClause</code> is a specific part of a <code>Contract</code>. Pipelex lets you express these relationships.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/define_your_concepts/#declaring-concept-refinement","title":"Declaring Concept Refinement","text":"<p>Use the <code>refines</code> field to indicate when one concept is a more specific version of another:</p> <pre><code>[concept]\nDocument = \"A written or printed record\"\n\n[concept.Contract]\nConcept = \"A legally binding agreement between parties\"\nrefines = \"Document\"\n\n[concept.EmploymentContract]\nConcept = \"A contract between an employer and employee\"\nrefines = \"Contract\"\n\n[concept.NonCompeteClause]\nConcept = \"A contract clause restricting competitive activities\"\nrefines = \"ContractClause\"\n</code></pre>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/define_your_concepts/#why-refinement-matters","title":"Why Refinement Matters","text":"<p>Concept refinement helps in two ways:</p> <ol> <li>Semantic clarity: Makes relationships between concepts explicit</li> <li>Pipeline flexibility: Pipes accepting general concepts can work with refined ones</li> </ol> <p>For example, a pipe that processes <code>Document</code> can also process <code>Contract</code> or <code>EmploymentContract</code>:</p> <pre><code>[pipe.extract_key_points]\nPipeLLM = \"Extract main points from any document\"\ninputs = { doc = \"Document\" }  # Can accept Document, Contract, or EmploymentContract\noutput = \"KeyPoints\"\n</code></pre>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/define_your_concepts/#practical-refinement-example","title":"Practical Refinement Example","text":"<p>Here's a complete example showing concept refinement in action:</p> <pre><code># pipelex_libraries/pipelines/content.toml\ndomain = \"content\"\n\n[concept]\nText = \"Written content in natural language\"\n\n[concept.Article]\nConcept = \"A written composition on a specific topic\"\nrefines = \"Text\"\n\n[concept.NewsArticle]\nConcept = \"An article reporting current events\"\nrefines = \"Article\"\n\n[concept.OpinionPiece]\nConcept = \"An article expressing personal views\"\nrefines = \"Article\"\n\n[pipe.summarize_text]\nPipeLLM = \"Create a summary of any text\"\ninputs = { content = \"Text\" }  # Works with Text, Article, NewsArticle, etc.\noutput = \"Summary\"\n\n[pipe.extract_facts]\nPipeLLM = \"Extract factual claims from news\"\ninputs = { article = \"NewsArticle\" }  # Specifically requires news articles\noutput = \"FactualClaims\"\n</code></pre>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/define_your_concepts/#structure-inheritance-in-python","title":"Structure Inheritance in Python","text":"<p>While TOML refinement is primarily semantic, you can mirror these relationships in Python when both concepts need structure:</p> <pre><code># pipelex_libraries/pipelines/content.py\nfrom pipelex.core.stuff_content import StructuredContent\nfrom datetime import datetime\nfrom typing import Optional, List\n\n# Base Article with structure\nclass Article(StructuredContent):\n    title: str\n    content: str\n    author: str\n    word_count: int = Field(ge=1)\n\n# NewsArticle inherits and extends Article's structure\nclass NewsArticle(Article):\n    publication_date: datetime\n    news_category: str\n    sources: List[str] = Field(default_factory=list)\n    breaking_news: bool = False\n\n# OpinionPiece also inherits and extends\nclass OpinionPiece(Article):\n    opinion_type: str  # e.g., \"editorial\", \"column\", \"review\"\n    disclaimer: Optional[str] = None\n\n# Note: Text, Summary, and FactualClaims have no Python models,\n# so they remain text-based concepts\n</code></pre> <p>With well-defined concepts\u2014both in natural language and code\u2014your pipelines gain clarity, reliability, and maintainability. Next, we'll see how to build pipes that transform these concepts.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/design_and_run_pipelines/","title":"Designing and Running Pipelines","text":"<p>In Pipelex, a pipeline is not just a rigid sequence of steps; it's a dynamic and intelligent workflow built by composing individual, reusable components called pipes. This approach allows you to break down complex AI tasks into manageable, testable, and reliable units.</p> <p>This guide provides an overview of how to design your pipelines and execute them.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/design_and_run_pipelines/#the-building-blocks-pipes","title":"The Building Blocks: Pipes","text":"<p>A pipeline is composed of pipes. There are two fundamental types of pipes you will use to build your workflows:</p> <ul> <li>Pipe Operators: These are the \"workers\" of your pipeline. They perform concrete actions like calling an LLM (<code>PipeLLM</code>), extracting text from a document (<code>PipeOcr</code>), or running a Python function (<code>PipeFunc</code>). Each operator is a specialized tool designed for a specific task.</li> <li>Pipe Controllers: These are the \"managers\" of your pipeline. They don't perform tasks themselves but orchestrate the execution flow of other pipes. They define the logic of your workflow, such as running pipes in sequence (<code>PipeSequence</code>), in parallel (<code>PipeParallel</code>), or based on a condition (<code>PipeCondition</code>).</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/design_and_run_pipelines/#designing-a-pipeline-composition-in-toml","title":"Designing a Pipeline: Composition in TOML","text":"<p>The most common way to design a pipeline is by defining and composing pipes in a <code>.toml</code> configuration file. This provides a clear, declarative way to see the structure of your workflow.</p> <p>Each pipe, whether it's an operator or a controller, is defined in its own <code>[pipe.&lt;pipe_name&gt;]</code> table. The <code>&lt;pipe_name&gt;</code> becomes the unique identifier for that pipe.</p> <p>Let's look at a simple example. Imagine we want a workflow that: 1.  Takes a product description. 2.  Generates a short, catchy marketing tagline for it.</p> <p>We can achieve this with a <code>PipeLLM</code> operator.</p> <pre><code># Filename: marketing_pipeline.toml\n\ndomain = \"marketing\"\ndefinition = \"Marketing content generation domain\"\n\n# 1. Define the concepts used in our pipes\n[concept]\nProductDescription = \"A description of a product's features and benefits\"\nTagline = \"A catchy marketing tagline\"\n\n# 2. Define the pipe that does the work\n[pipe.generate_tagline]\nPipeLLM = \"Generate a catchy tagline for a product\"\ninputs = { description = \"ProductDescription\" }\noutput = \"Tagline\"\nprompt_template = \"\"\"\nProduct Description:\n@description\n\nGenerate a catchy tagline based on the above description.\nThe tagline should be memorable, concise, and highlight the key benefit.\n\"\"\"\n</code></pre> <p>This defines a single-step pipeline. The pipe <code>generate_tagline</code> takes a <code>ProductDescription</code> as input and outputs a <code>Tagline</code>.</p> <p>To create a multi-step workflow, you use a controller. The <code>PipeSequence</code> controller is the most common one. It executes a series of pipes in a specific order.</p> <pre><code># Filename: marketing_pipeline.toml\n\ndomain = \"marketing\"\ndefinition = \"Marketing content generation domain\"\n\n# 1. Define concepts\n[concept]\nProductDescription = \"A description of a product's features and benefits\"\nKeyword = \"A keyword extracted from a text\"\nTagline = \"A catchy marketing tagline\"\n\n# 2. Define operator pipes\n[pipe.extract_keywords]\nPipeLLM = \"Extract keywords from a product description\"\ninputs = { description = \"ProductDescription\" }\noutput = \"Keyword\"\nmultiple_output = true\nprompt_template = \"\"\"\nPlease extract the most relevant keywords from the following product description:\n\n@description\n\nFocus on features, benefits, and unique selling points.\n\"\"\"\n\n[pipe.generate_tagline_from_keywords]\nPipeLLM = \"Generate a tagline from keywords\"\ninputs = { keywords = \"Keyword\" }\noutput = \"Tagline\"\nprompt_template = \"\"\"\nHere are the key product keywords:\n@keywords\n\nGenerate a catchy marketing tagline based on these keywords.\nThe tagline should be memorable, concise (under 10 words), and highlight the main benefit.\n\"\"\"\n\n# 3. This controller pipe defines the two-step pipeline\n[pipe.description_to_tagline]\nPipeSequence = \"From product description to tagline\"\ninputs = { description = \"ProductDescription\" }\noutput = \"Tagline\"\nsteps = [\n    { pipe = \"extract_keywords\", result = \"extracted_keywords\" },\n    { pipe = \"generate_tagline_from_keywords\", result = \"tagline\" },\n]\n</code></pre>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/design_and_run_pipelines/#data-flow-the-working-memory","title":"Data Flow: The Working Memory","text":"<p>How does data get from <code>extract_keywords</code> to <code>generate_tagline_from_keywords</code>? This is handled by the Working Memory.</p> <p>The Working Memory is a temporary storage space that exists for the duration of a single pipeline run.</p> <ol> <li>When a pipe in a sequence executes, its output is given a name using the <code>result</code> key (e.g., <code>result = \"extracted_keywords\"</code>).</li> <li>This named result is placed into the Working Memory.</li> <li>Subsequent pipes can then reference this data by its name in their <code>inputs</code> field (e.g., <code>inputs = { keywords = \"Keyword\" }</code>).</li> </ol> <p>This mechanism allows you to chain pipes together, creating a flow of information through your pipeline.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/design_and_run_pipelines/#running-a-pipeline","title":"Running a Pipeline","text":"<p>Once your pipes are defined, you can execute them from your Python code. Pipelex provides two main functions for this: <code>start_pipeline</code> and <code>execute_pipeline</code>.</p> <p>To run the <code>description_to_tagline</code> pipeline we defined above, you would call it by its unique name:</p> <pre><code>import asyncio\nfrom pipelex.core.working_memory import WorkingMemory\nfrom pipelex.core.working_memory_factory import WorkingMemoryFactory\nfrom pipelex.pipelex import Pipelex\nfrom pipelex.pipeline.execute import execute_pipeline\n\nasync def main():\n    # First, initialize Pipelex (this loads all pipeline definitions)\n    Pipelex.make()\n\n    # Create working memory with the pipeline's input\n    working_memory = WorkingMemoryFactory.make_from_text(\n        text=\"EcoClean Pro is a revolutionary biodegradable cleaning solution that removes 99.9% of germs while being completely safe for children and pets. Made from plant-based ingredients.\",\n        concept_code=\"ProductDescription\",\n        name=\"description\"\n    )\n\n    # Execute the pipeline and wait for the result\n    pipe_output = await execute_pipeline(\n        pipe_code=\"description_to_tagline\",\n        working_memory=working_memory,\n    )\n\n    # Get the final output\n    tagline = pipe_output.main_stuff_as(content_type=str)\n    print(f\"Generated tagline: {tagline}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <ul> <li><code>execute_pipeline</code>: Runs the specified pipe and waits for it to complete, returning the final output. This is useful for simple, synchronous-style interactions.</li> <li><code>start_pipeline</code>: Immediately returns a <code>pipeline_run_id</code> and an <code>asyncio.Task</code>. This allows you to run pipelines in the background and manage them asynchronously, which is essential for complex, long-running, or parallel workflows.</li> </ul> <p>By combining declarative TOML definitions with a powerful Python execution model, Pipelex gives you a robust framework for building and running reliable AI workflows.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/kick-off-a-knowledge-pipeline-project/","title":"Kicking off a Knowledge Pipeline Project","text":""},{"location":"pages/build-reliable-ai-workflows-with-pipelex/kick-off-a-knowledge-pipeline-project/#creating-your-first-pipeline","title":"Creating Your First Pipeline","text":"<p>A pipeline in Pipelex is a collection of related concepts and pipes. Start by creating a TOML file in the <code>pipelines</code> directory:</p> <pre><code># pipelex_libraries/pipelines/tutorial.toml\n\ndomain = \"tutorial\"\ndefinition = \"My first Pipelex library\"\nsystem_prompt = \"You are a helpful assistant.\"\n\n[concept]\nQuestion = \"A question that needs to be answered\"\nAnswer = \"A response to a question\"\n\n[pipe]\n[pipe.answer_question]\nPipeLLM = \"Answer a question\"\ninputs = { question = \"tutorial.Question\" }\noutput = \"tutorial.Answer\"\nprompt_template = \"\"\"\nPlease answer the following question:\n\n@question\n\nProvide a clear and concise answer.\n\"\"\"\n</code></pre> <p>This creates a simple Q&amp;A pipeline with: - A domain called \"tutorial\" - Two concepts: Question and Answer - One pipe that transforms a Question into an Answer</p> <p>The <code>domain</code> property is the most important part of your pipeline file. It groups all your concepts and pipes into a single, easy to read bundle.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/kick-off-a-knowledge-pipeline-project/#what-are-domains","title":"What Are Domains?","text":"<p>A domain in Pipelex represents a topic or area of functionality within your pipeline. Every pipeline file must specify its domain, which helps organize and categorize your pipes and concepts.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/kick-off-a-knowledge-pipeline-project/#domain-in-practice","title":"Domain in Practice","text":"<p>When you create a pipeline file (<code>.toml</code>), you always start by declaring its domain:</p> <pre><code>domain = \"finance\"                                      # The domain name for this file\ndefinition = \"Financial document processing\"            # Optional description\nsystem_prompt = \"You are an expert financial analyst.\"  # Optional system prompt for all PipeLLM in this domain\n</code></pre> <p>A domain consists of:</p> <ol> <li> <p>Pipeline File (<code>.toml</code>)     <pre><code>domain = \"finance\"\n\n[concept]\nInvoice = \"A commercial document for a sale of products or services\"\nInvoiceSummary = \"A summary of an invoice with key details\"\n\n[pipe]\n[pipe.summarize_invoice]\nPipeLLM = \"Summarize an invoice to extract key information\"\ninputs = { invoice = \"finance.Invoice\" }\noutput = \"finance.InvoiceSummary\"\n</code></pre></p> </li> <li> <p>Python Models (<code>.py</code>)     <pre><code>from pipelex.core.stuff_content import StructuredContent\nfrom pydantic import Field\nfrom typing import List\nfrom datetime import date\n\nclass Invoice(StructuredContent):\n    invoice_number: str\n    vendor: str\n    customer: str\n    total_amount: float = Field(ge=0)\n    issue_date: date\n    line_items: List[str]\n\nclass InvoiceSummary(StructuredContent):\n    vendor: str\n    total_amount: float\n    is_overdue: bool\n</code></pre></p> </li> </ol>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/kick-off-a-knowledge-pipeline-project/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Naming</p> <ul> <li>Use clear, descriptive domain names.</li> <li>Keep names lowercase and simple.</li> <li>Use names that reflect the purpose (e.g., \"finance\", \"legal\", \"content_creation\").</li> </ul> </li> <li> <p>Organization</p> <ul> <li>One domain per topic/functionality.</li> <li>Match Python file names with domain names (<code>finance.toml</code> -&gt; <code>finance.py</code>).</li> <li>Keep related concepts within the same domain.</li> </ul> </li> <li> <p>Documentation</p> <ul> <li>Always add a description to your domain.</li> <li>Document concepts clearly.</li> <li>Include examples where helpful.</li> </ul> </li> </ol>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/kick-off-a-knowledge-pipeline-project/#using-domains","title":"Using Domains","text":"<p>When using a domain in your code, you refer to concepts with <code>domain.ConceptName</code>:</p> <pre><code>from pipelex.core.stuff_factory import StuffFactory\n\n# The concept_code combines domain and concept names\ninvoice_stuff = StuffFactory.make_stuff(\n    concept_str=\"finance.Invoice\",  # domain.ConceptName\n    name=\"invoice_123\",\n    content=invoice_data # dictionary or Invoice object\n)\n</code></pre>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/kick-off-a-knowledge-pipeline-project/#file-naming-conventions","title":"File Naming Conventions","text":"<p>Consistent naming makes your pipeline code discoverable and maintainable:</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/kick-off-a-knowledge-pipeline-project/#toml-files","title":"TOML Files","text":"<ul> <li>Use lowercase with underscores: <code>legal_contracts.toml</code>, <code>customer_service.toml</code></li> <li>Match the domain name when possible: domain \"legal\" \u2192 <code>legal.toml</code></li> <li>For multi-word domains, use underscores: domain \"customer_service\" \u2192 <code>customer_service.toml</code></li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/kick-off-a-knowledge-pipeline-project/#python-model-files","title":"Python Model Files","text":"<ul> <li>It is recommended to match the TOML filename exactly: <code>legal.toml</code> \u2192 <code>legal.py</code></li> <li>But in any case, Pipelex will load models from all python modules in the <code>pipelines</code> directory or its subdirectories.</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/kick-off-a-knowledge-pipeline-project/#project-structure","title":"Project Structure","text":"<p>Every Pipelex project follows a simple directory structure that keeps your knowledge pipelines organized and maintainable:</p> <pre><code>your-project/\n\u251c\u2500\u2500 pipelex_libraries/         # All your pipeline code lives here\n\u2502   \u251c\u2500\u2500 pipelines/             # Pipeline definitions and models\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 characters.toml    # Domain definitions\n\u2502   \u2502   \u2514\u2500\u2500 characters.py      # Python models for concepts\n\u2502   \u251c\u2500\u2500 templates/             # Reusable prompt templates\n\u2502   \u251c\u2500\u2500 llm_integrations/      # LLM provider configurations\n\u2502   \u2514\u2500\u2500 llm_deck/              # LLM model presets\n\u251c\u2500\u2500 main.py                    # Your application code\n\u2514\u2500\u2500 requirements.txt           # Python dependencies\n</code></pre> <p>The <code>pipelex_libraries/pipelines</code> directory is where Pipelex looks for your pipeline definitions. This standardized structure means you can share libraries between projects, version control them separately, and maintain clean separation between your pipeline logic and application code.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/llm-structured-generation-config/","title":"Structure Configuration","text":"<p>The <code>StructureConfig</code> class controls how Pipelex handles structural processing of content, particularly in LLM-based pipes.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/llm-structured-generation-config/#configuration-options","title":"Configuration Options","text":"<pre><code>class StructureConfig(ConfigModel):\n    is_default_text_then_structure: bool\n</code></pre>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/llm-structured-generation-config/#fields","title":"Fields","text":"<ul> <li><code>is_default_text_then_structure</code>: When true, uses a two-step LLM process where text is generated first, then structured into a JSON object</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/llm-structured-generation-config/#example-configuration","title":"Example Configuration","text":"<pre><code>[pipelex.structure_config]\nis_default_text_then_structure = true\n</code></pre>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/llm-structured-generation-config/#processing-flow","title":"Processing Flow","text":"<p>The <code>is_default_text_then_structure</code> flag determines how LLM pipes generate structured content:</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/llm-structured-generation-config/#two-step-process-when-true","title":"Two-Step Process (When <code>true</code>)","text":"<ol> <li> <p>First LLM Call: Generates preliminary text</p> <ul> <li>Uses the pipe's main prompt template</li> <li>Produces natural language text about the subject</li> </ul> </li> <li> <p>Second LLM Call: Converts text to structure</p> <ul> <li>Uses a specialized system prompt: \"You are a data modeling expert specialized in extracting structure from text\"</li> <li>Uses a template that instructs the LLM to extract structured data:    <pre><code>Your job is to extract and structure information from a text.\nHere is the text:\n{preliminary_text}\n\nNow generate the JSON in the required format.\nDo not create information that is not in the text.\n</code></pre></li> <li>Produces a JSON object matching the required concept structure</li> </ul> </li> </ol>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/llm-structured-generation-config/#single-step-process-when-false","title":"Single-Step Process (When <code>false</code>)","text":"<ul> <li>Single LLM call that directly generates the structured output</li> <li>Uses the pipe's main prompt template</li> <li>Produces structured JSON directly</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/llm-structured-generation-config/#use-cases","title":"Use Cases","text":""},{"location":"pages/build-reliable-ai-workflows-with-pipelex/llm-structured-generation-config/#when-to-use-two-step-process-true","title":"When to Use Two-Step Process (<code>true</code>)","text":"<ul> <li>When you want more natural and fluid content generation</li> <li>When the structure is complex and needs careful extraction</li> <li>When you want to ensure all generated content is properly structured</li> <li>When you need better control over the extraction process</li> <li>When you want to debug or inspect the intermediate text</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/llm-structured-generation-config/#when-to-use-single-step-process-false","title":"When to Use Single-Step Process (<code>false</code>)","text":"<ul> <li>When the structure is simple and straightforward</li> <li>When you need faster processing (avoids second LLM call)</li> <li>When the output format is well-defined and easy to generate</li> <li>When you want to reduce API costs</li> <li>When the prompt is already optimized for structured output</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/llm-structured-generation-config/#technical-details","title":"Technical Details","text":"<p>The two-step process uses:</p> <ol> <li>The pipe's configured prompts for initial text generation</li> <li>A specialized structure extraction prompt that can be customized:</li> <li>Through domain configuration (<code>domain.prompt_template_to_structure</code>)</li> <li>Through pipe configuration (<code>pipe.prompt_template_to_structure</code>)</li> <li>Falls back to base template if not specified</li> </ol>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/llm-structured-generation-config/#example-flow","title":"Example Flow","text":"<pre><code>graph TD\n    A[Input] --&gt; B{is_default_text_then_structure?}\n    B --&gt;|true| C[First LLM Call]\n    C --&gt; D[Generate Text]\n    D --&gt; E[Second LLM Call]\n    E --&gt; F[Extract Structure]\n    F --&gt; H[Final JSON Output]\n    B --&gt;|false| G[Direct Structure Generation]\n    G --&gt; H</code></pre>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/","title":"Pipe Controllers","text":"<p>Pipe controllers are the orchestrators of a Pipelex pipeline. While Pipe Operators perform the work, pipe controllers define the workflow and manage the execution logic. They allow you to run other pipes in sequence, in parallel, or conditionally.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/#core-controllers","title":"Core Controllers","text":"<p>Here are the primary pipe controllers available in Pipelex:</p> <ul> <li><code>PipeSequence</code>: The most fundamental controller. It runs a series of pipes one after another, passing the results from one step to the next.</li> <li><code>PipeParallel</code>: Executes multiple independent pipes at the same time, significantly speeding up workflows where tasks don't depend on each other.</li> <li><code>PipeBatch</code>: Performs a \"map\" operation. It takes a list of items and runs the same pipe on every single item in parallel.</li> <li><code>PipeCondition</code>: Adds branching logic (<code>if/else</code>) to your pipeline. It evaluates an expression and chooses which pipe to run next based on the result.</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/#overview","title":"Overview","text":"<p>Pipelex provides the following pipe operators:</p> <ul> <li><code>PipeSequence</code>: For chaining multiple pipes in sequence</li> <li><code>PipeParallel</code>: For running different pipes in parallel</li> <li><code>PipeBatch</code>: For running one pipe over a batch of inputs</li> <li><code>PipeCondition</code>: For conditional execution based on input validation</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/#pipesequence","title":"PipeSequence","text":"<p>Run multiple pipes in sequence.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/#key-features","title":"Key Features","text":"<ul> <li>Sequential execution</li> <li>Working memory management</li> <li>Sub-pipe handling</li> <li>Pipeline composition</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/#pipecondition","title":"PipeCondition","text":"<p>Enables conditional execution based on input validation.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/#key-features_1","title":"Key Features","text":"<ul> <li>Expression-based routing</li> <li>Default fallback paths</li> <li>Jinja2 template support</li> <li>Input validation</li> <li>Error handling</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/PipeBatch/","title":"PipeBatch","text":"<p>The <code>PipeBatch</code> controller provides a powerful \"map\" operation for your pipelines. It takes a list of items as input and runs the same pipe on each item in the list, executing them all in parallel for maximum efficiency.</p> <p>This is the ideal controller for processing collections of documents, images, or any other data records where the same logic needs to be applied to each one independently.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/PipeBatch/#how-it-works","title":"How it works","text":"<p><code>PipeBatch</code> orchestrates a parallel, per-item execution of a single \"branch pipe\".</p> <ol> <li>Input List: It identifies an input list from the working memory.</li> <li>Branching: For each item in the input list, it creates a new, isolated execution branch.</li> <li>Isolation &amp; Injection: Each branch gets a deep copy of the <code>WorkingMemory</code>. The specific item for that branch is injected into this memory with a defined name.</li> <li>Concurrent Execution: The specified <code>branch_pipe_code</code> is executed in all branches simultaneously. Each branch pipe operates only on its own item.</li> <li>Aggregation: After all branches have completed, <code>PipeBatch</code> collects the individual output from each one and aggregates them into a single new list. This list becomes the final output of the <code>PipeBatch</code> pipe.</li> </ol>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/PipeBatch/#configuration","title":"Configuration","text":"<p><code>PipeBatch</code> is configured in your pipeline's <code>.toml</code> file.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/PipeBatch/#toml-parameters","title":"TOML Parameters","text":"Parameter Type Description Required <code>PipeBatch</code> string A descriptive name for the batch operation. Yes <code>inputs</code> dictionary The input concept(s) for the batch operation, as a dictionary mapping input names to concept codes. Yes <code>output</code> string The output concept produced by the batch operation. Yes <code>branch_pipe_code</code> string The name of the single pipe to execute for each item in the input list. Yes <code>batch_params</code> table (dict) An optional table to provide more specific names for the batch operation. No"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/PipeBatch/#batch-parameters-batch_params","title":"Batch Parameters (<code>batch_params</code>)","text":"Key Type Description Required <code>input_list_stuff_name</code> string The name of the list in the <code>WorkingMemory</code> to iterate over. If not provided, it defaults to the name of the <code>PipeBatch</code>'s main <code>input</code>. No <code>input_item_stuff_name</code> string The name that an individual item from the list will have inside its execution branch. This is how the branch pipe finds its input. Yes"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/PipeBatch/#example-summarizing-a-list-of-articles","title":"Example: Summarizing a list of articles","text":"<p>Suppose you have a list of articles and you want to generate a summary for each one.</p> <pre><code># The pipe that knows how to summarize one article\n[pipe.summarize_one_article]\nPipeLLM = \"Summarize a single article\"\ninputs = { article = \"ArticleText\" }\noutput = \"ArticleSummary\"\nprompt_template = \"Please provide a one-sentence summary of the following article:\\n\\n@article_text\"\n\n# The PipeBatch definition\n[pipe.summarize_all_articles]\nPipeBatch = \"Summarize a batch of articles in parallel\"\ninputs = { articles = \"ArticleList\" }  # This is the list to iterate over\noutput = \"SummaryList\" # This will be the list of summaries\nbranch_pipe_code = \"summarize_one_article\"\n\n[pipe.summarize_all_articles.batch_params]\ninput_item_stuff_name = \"ArticleText\" # Name of an item within the branch\n</code></pre> <p>How this works: 1.  The <code>summarize_all_articles</code> pipe receives an <code>ArticleList</code>. Let's say it contains 10 articles. 2.  <code>PipeBatch</code> creates 10 parallel branches. 3.  In branch #1, it takes the first article from <code>ArticleList</code>, puts it into the branch's isolated working memory, and gives it the name <code>ArticleText</code> (as specified by <code>input_item_stuff_name</code>). 4.  The <code>summarize_one_article</code> pipe is then executed in branch #1. It looks for an input named <code>ArticleText</code>, finds the injected article, and produces a summary. 5.  Steps 3 and 4 happen simultaneously for all 10 articles in their respective branches. 6.  Once all <code>summarize_one_article</code> pipes are done, <code>PipeBatch</code> collects the 10 <code>ArticleSummary</code> outputs and bundles them into a single <code>SummaryList</code>. This list is the final result. </p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/PipeCondition/","title":"PipeCondition","text":"<p>The <code>PipeCondition</code> controller adds branching logic to your pipelines. It evaluates an expression and, based on the string result, chooses which subsequent pipe to execute from a map of possibilities.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/PipeCondition/#how-it-works","title":"How it works","text":"<p><code>PipeCondition</code> is a routing mechanism. Its execution flow is as follows:</p> <ol> <li>Evaluate an Expression: It takes an expression and renders it using Jinja2, with the full <code>WorkingMemory</code> available as context. This evaluation results in a simple string.</li> <li>Look Up in Pipe Map: The resulting string is used as a key to find a corresponding pipe name in the <code>pipe_map</code>.</li> <li>Use Default (Optional): If the key is not found in the <code>pipe_map</code>, it will use the <code>default_pipe_code</code> if one is provided. If there's no match and no default, an error is raised.</li> <li>Execute Chosen Pipe: The chosen pipe is then executed. It receives the exact same <code>WorkingMemory</code> and inputs that were passed to the <code>PipeCondition</code> operator. The output of the chosen pipe becomes the output of the <code>PipeCondition</code> itself.</li> </ol>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/PipeCondition/#configuration","title":"Configuration","text":"<p><code>PipeCondition</code> is configured in your pipeline's <code>.toml</code> file.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/PipeCondition/#toml-parameters","title":"TOML Parameters","text":"Parameter Type Description Required <code>PipeCondition</code> string A descriptive name for the condition. Yes <code>inputs</code> dictionary The input concept(s) for the condition, as a dictionary mapping input names to concept codes. Yes <code>output</code> string The output concept produced by the selected pipe. Yes <code>expression</code> string A simple Jinja2 expression. <code>{{ ... }}</code> are automatically added. Good for simple variable access like <code>\"my_var.category\"</code>. Yes (or <code>expression_template</code>) <code>expression_template</code> string A full Jinja2 template string. Use this for more complex logic, like <code>{% if my_var.value &gt; 10 %}high{% else %}low{% endif %}</code>. Yes (or <code>expression</code>) <code>pipe_map</code> table (dict) A mapping where keys are the possible string results of the expression, and values are the names of the pipes to execute. Yes <code>default_pipe_code</code> string The name of a pipe to execute if the expression result does not match any key in <code>pipe_map</code>. No <code>add_alias_from_expression_to</code> string An advanced feature. If provided, the string result of the expression evaluation is added to the working memory as an alias with this name. No"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/PipeCondition/#example-simple-routing-based-on-category","title":"Example: Simple routing based on category","text":"<p>Here's a basic example showing how PipeCondition routes based on input data:</p> <pre><code>domain = \"routing_example\"\ndefinition = \"Example of PipeCondition routing\"\n\n[concept]\nCategoryInput = \"Input with a category field\"\n\n# Define the PipeCondition first\n[pipe.route_by_category]\nPipeCondition = \"Route based on category field\"\ninputs = { input_data = \"CategoryInput\" }\noutput = \"native.Text\"\nexpression = \"input_data.category\"\n\n[pipe.route_by_category.pipe_map]\nsmall = \"process_small\"\nmedium = \"process_medium\"\nlarge = \"process_large\"\n\n# Define the pipes that PipeCondition can route to\n[pipe.process_small]\nPipeLLM = \"Handle small category\"\noutput = \"native.Text\"\nprompt_template = \"\"\"\nOutput this only: \"small\"\n\"\"\"\n\n[pipe.process_medium]\nPipeLLM = \"Handle medium category\"\noutput = \"native.Text\"\nprompt_template = \"\"\"\nOutput this only: \"medium\"\n\"\"\"\n\n[pipe.process_large]\nPipeLLM = \"Handle large category\"\noutput = \"native.Text\"\nprompt_template = \"\"\"\nOutput this only: \"large\"\n\"\"\"\n</code></pre> <p>How this works: 1. <code>PipeCondition</code> receives input data with a <code>category</code> field (e.g., <code>{category: \"small\"}</code>) 2. It evaluates the expression <code>\"input_data.category\"</code> which results in the string <code>\"small\"</code> 3. It looks up <code>\"small\"</code> in the <code>pipe_map</code> and finds the corresponding pipe: <code>\"process_small\"</code> 4. The <code>process_small</code> pipe is executed with the same working memory 5. The output from <code>process_small</code> becomes the output of the entire <code>PipeCondition</code></p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/PipeCondition/#example-routing-with-default-fallback","title":"Example: Routing with default fallback","text":"<pre><code>[pipe.route_with_fallback]\nPipeCondition = \"Route with default handling\"\ninputs = { classification = \"DocumentType\" }\noutput = \"ProcessedDocument\"\nexpression = \"classification.type\"\ndefault_pipe_code = \"process_unknown\"\n\n[pipe.route_with_fallback.pipe_map]\ninvoice = \"process_invoice\"\nreceipt = \"process_receipt\"\n\n[pipe.process_invoice]\nPipeLLM = \"Process invoice documents\"\ninputs = { classification = \"DocumentType\" }\noutput = \"ProcessedDocument\"\nprompt_template = \"\"\"\nProcess this invoice document...\n\"\"\"\n\n[pipe.process_receipt]\nPipeLLM = \"Process receipt documents\" \ninputs = { classification = \"DocumentType\" }\noutput = \"ProcessedDocument\"\nprompt_template = \"\"\"\nProcess this receipt document...\n\"\"\"\n\n[pipe.process_unknown]\nPipeLLM = \"Handle unknown document types\"\ninputs = { classification = \"DocumentType\" }\noutput = \"ProcessedDocument\"\nprompt_template = \"\"\"\nProcess this unknown document type...\n\"\"\"\n</code></pre>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/PipeCondition/#expression-types","title":"Expression Types","text":""},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/PipeCondition/#simple-expression","title":"Simple Expression","text":"<pre><code>expression = \"input_data.category\"\n</code></pre> <ul> <li>Direct access to working memory variables</li> <li>No template syntax needed (<code>{{ }}</code> are automatically added)</li> <li>Good for simple field access</li> <li>Access to Jinja2 filters and functions</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/PipeCondition/#complex-expression","title":"Complex Expression","text":"<pre><code>expression_template = \"{% if input_data.score &gt;= 70 %}high{% else %}low{% endif %}\"\n</code></pre> <ul> <li>Full Jinja2 template syntax</li> <li>Conditional logic and loops</li> <li>Complex transformations</li> <li>Multiple variable access</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/PipeCondition/#features","title":"Features","text":""},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/PipeCondition/#default-routing","title":"Default Routing","text":"<pre><code>default_pipe_code = \"process_unknown\"\n</code></pre> <ul> <li>Fallback pipe when no match is found</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/PipeCondition/#expression-aliasing","title":"Expression Aliasing","text":"<pre><code>add_alias_from_expression_to = \"category_type\"\n</code></pre> <ul> <li>Creates an alias from the expression result</li> <li>Makes the result available in working memory</li> <li>Requires the target to exist in working memory beforehand</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/PipeParallel/","title":"PipeParallel","text":"<p>The <code>PipeParallel</code> controller executes multiple pipes simultaneously. This is highly effective for running pipes concurrently in isolated branches.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/PipeParallel/#how-it-works","title":"How it works","text":"<p><code>PipeParallel</code> runs a list of sub-pipes in concurrent branches.</p> <ol> <li>Isolation: Before execution, <code>PipeParallel</code> creates a deep copy of the current <code>WorkingMemory</code> for each branch. This means every parallel pipe starts with the exact same state, but they run in complete isolation\u2014a change in one branch will not affect another.</li> <li>Concurrent Execution: All specified pipes are executed at the same time using <code>asyncio.gather</code>.</li> <li>Output Handling: After all parallel tasks have finished, their results are collected and added back to the main working memory. You can control how this happens with two parameters:<ul> <li><code>add_each_output</code>: If <code>true</code>, the individual result of each branch is added to the working memory under the name specified in its <code>result</code> key.</li> <li><code>combined_output</code>: If you provide an output concept here, the results of all branches are bundled together into a single structured object. The field names of this object correspond to the <code>result</code> names of the branches.</li> </ul> </li> </ol> <p>You must use <code>add_each_output</code>, <code>combined_output</code>, or both.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/PipeParallel/#configuration","title":"Configuration","text":"<p><code>PipeParallel</code> is configured in your pipeline's <code>.toml</code> file.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/PipeParallel/#toml-parameters","title":"TOML Parameters","text":"Parameter Type Description Required <code>PipeParallel</code> string A descriptive name for the parallel operation. Yes <code>inputs</code> dictionary The input concept(s) for the parallel operation, as a dictionary mapping input names to concept codes. Yes <code>output</code> string The output concept produced by the parallel operation. Yes <code>parallels</code> array of tables An array defining the pipes to run in parallel. Each table is a sub-pipe definition. Yes <code>add_each_output</code> boolean If <code>true</code>, adds the output of each parallel pipe to the working memory individually. Defaults to <code>false</code>. No <code>combined_output</code> string The name of a concept to use for a single, combined output object. The structure of this concept must have fields that match the <code>result</code> names from the <code>parallels</code> array. No"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/PipeParallel/#parallel-step-configuration","title":"Parallel Step Configuration","text":"<p>Each entry in the <code>parallels</code> array is a table with the following keys:</p> Key Type Description Required <code>pipe</code> string The name of the pipe to execute for this branch. Yes <code>result</code> string The name for this branch's output. Must be unique within the <code>PipeParallel</code> definition. Yes"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/PipeParallel/#example-extracting-different-details-from-a-text","title":"Example: Extracting different details from a text","text":"<p>Imagine you have a product description and you want to extract the product features and the product sentiment at the same time.</p> <pre><code>[concept.ProductAnalysis]\nstructure = \"ProductAnalysis\" # A Pydantic model with 'features' and 'sentiment' fields\n\n[pipe.extract_features]\nPipeLLM = \"Extract features from text\"\ninputs = { description = \"ProductDescription\" }\noutput = \"ProductFeatures\"\n\n[pipe.analyze_sentiment]\nPipeLLM = \"Analyze sentiment of text\"\ninputs = { description = \"ProductDescription\" }\noutput = \"ProductSentiment\"\n\n# The PipeParallel definition\n[pipe.analyze_product_in_parallel]\nPipeParallel = \"Extract features and sentiment at the same time\"\ninputs = { description = \"ProductDescription\" }\noutput = \"ProductAnalysis\" # This name is for the combined output\nadd_each_output = false\ncombined_output = \"ProductAnalysis\"\nparallels = [\n    { pipe = \"extract_features\", result = \"features\" },\n    { pipe = \"analyze_sentiment\", result = \"sentiment\" },\n]\n</code></pre> <p>How this works: 1.  The <code>analyze_product_in_parallel</code> pipe starts. It receives a <code>ProductDescription</code>. 2.  Two parallel branches are created, both with access to the <code>ProductDescription</code>. 3.  The <code>extract_features</code> pipe runs in one branch, and the <code>analyze_sentiment</code> pipe runs in the other, simultaneously. 4.  After both complete, <code>PipeParallel</code> collects the results. The output from <code>extract_features</code> is named <code>features</code>, and the output from <code>analyze_sentiment</code> is named <code>sentiment</code>. 5.  Because <code>combined_output</code> is set to <code>ProductAnalysis</code>, a new structured object of type <code>ProductAnalysis</code> is created. This object is populated with the results, like <code>{\"features\": ..., \"sentiment\": ...}</code>. 6.  This single <code>ProductAnalysis</code> object becomes the final output of the <code>analyze_product_in_parallel</code> pipe. </p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/PipeSequence/","title":"PipeSequence","text":"<p>The <code>PipeSequence</code> controller is used to execute a series of pipes one after another. It is the fundamental building block for creating linear workflows where the output of one step becomes the input for the next.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/PipeSequence/#how-it-works","title":"How it works","text":"<p>A <code>PipeSequence</code> defines a list of <code>steps</code>. Each step calls another pipe and gives a name to its output. The working memory is passed from one step to the next, accumulating results along the way.</p> <ul> <li>The <code>input</code> of the <code>PipeSequence</code> is passed to the first pipe in the sequence.</li> <li>The <code>output</code> of each intermediate step is named via the <code>result</code> key and becomes available in the working memory for all subsequent steps.</li> <li>The final <code>output</code> of the <code>PipeSequence</code> is the output produced by the very last step in the sequence.</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/PipeSequence/#configuration","title":"Configuration","text":"<p><code>PipeSequence</code> is configured in your pipeline's <code>.toml</code> file.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/PipeSequence/#toml-parameters","title":"TOML Parameters","text":"Parameter Type Description Required <code>PipeSequence</code> string A descriptive name for the sequence. Yes <code>inputs</code> dictionary The input concept(s) for the first pipe in the sequence, as a dictionary mapping input names to concept codes. No <code>output</code> string The output concept produced by the last pipe in the sequence. Yes <code>steps</code> array of tables An ordered list of the pipes to execute. Each table in the array defines a single step. Yes"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/PipeSequence/#step-configuration","title":"Step Configuration","text":"<p>Each entry in the <code>steps</code> array is a table with the following keys:</p> Key Type Description Required <code>pipe</code> string The name of the pipe to execute for this step. Yes <code>result</code> string The name to give to the output of this step in the working memory. Yes"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-controllers/PipeSequence/#example","title":"Example","text":"<p>Let's imagine a pipeline that first extracts text from an image, then summarizes that text, and finally translates the summary into French.</p> <pre><code>[pipe.extract_text_from_image]\nPipeOcr = \"...\" # (definition of the OCR pipe)\noutput = \"Text\"\n\n[pipe.summarize_text]\nPipeLLM = \"...\" # (definition of the summarization pipe)\ninputs = { text = \"Text\" }\noutput = \"Text\"\n\n[pipe.translate_to_french]\nPipeLLM = \"...\" # (definition of the translation pipe)\ninputs = { text = \"Text\" }\noutput = \"Text\"\n\n\n[pipe.image_to_french_summary]\nPipeSequence = \"Extract, summarize, and translate text from an image\"\ninputs = { image = \"source.Image\" }\noutput = \"target.FrenchText\"\nsteps = [\n    { pipe = \"extract_text_from_image\", result = \"extracted_text\" },\n    { pipe = \"summarize_text\", result = \"english_summary\" },\n    { pipe = \"translate_to_french\", result = \"french_summary\" },\n]\n</code></pre>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/","title":"Pipe Operators","text":"<p>Pipe operators are the fundamental building blocks in Pipelex, representing a single, focused task. They are the \"verbs\" of your pipeline that perform the actual work.</p> <p>Each operator specializes in a specific kind of action, from interacting with Large Language Models to executing custom Python code. You combine these operators using Pipe Controllers to create complex workflows.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/#core-operators","title":"Core Operators","text":"<p>Here are the primary pipe operators available in Pipelex:</p> <ul> <li><code>PipeLLM</code>: The core operator for all interactions with Large Language Models (LLMs), including text generation, structured data extraction, and vision tasks.</li> <li><code>PipeOcr</code>: Performs Optical Character Recognition (OCR) on images and PDF documents to extract text and embedded images.</li> <li><code>PipeImgGen</code>: Generates images from a text prompt using models like DALL-E 3 or Stable Diffusion.</li> <li><code>PipeFunc</code>: An escape hatch that allows you to execute any custom Python function, giving you maximum flexibility.</li> <li><code>PipeJinja2</code>: Renders a Jinja2 template using data from the working memory, perfect for creating formatted reports or complex prompts.</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/#overview","title":"Overview","text":"<p>Pipelex provides the following pipe operators:</p> <ul> <li><code>PipeLLM</code>: For LLM-based text generation and processing</li> <li><code>PipeOcr</code>: For optical character recognition and document processing</li> <li><code>PipeFunc</code>: For executing custom functions</li> <li><code>PipeImgGen</code>: For image generation and manipulation</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/#pipellm","title":"PipeLLM","text":"<p>Core operator for LLM-based text generation and processing.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/#key-features","title":"Key Features","text":"<ul> <li>Text generation</li> <li>Structured output generation</li> <li>Multiple output modes</li> <li>System prompt customization</li> <li>LLM configuration</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/#key-features_1","title":"Key Features","text":"<ul> <li>Sequential execution</li> <li>Working memory management</li> <li>Sub-pipe handling</li> <li>Pipeline composition</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/#pipeocr","title":"PipeOcr","text":"<p>Processes images and PDFs using Optical Character Recognition.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/#key-features_2","title":"Key Features","text":"<ul> <li>PDF processing</li> <li>Image processing</li> <li>Text extraction</li> <li>Image extraction</li> <li>Page view generation</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/#pipefunc","title":"PipeFunc","text":"<p>Executes custom functions within the pipeline.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/#key-features_3","title":"Key Features","text":"<ul> <li>Custom function execution</li> <li>Working memory integration</li> <li>Multiple output types</li> <li>Function registry integration</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/#pipeimggen","title":"PipeImgGen","text":"<p>Generates and manipulates images.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/#key-features_4","title":"Key Features","text":"<ul> <li>Image generation</li> <li>Quality control</li> <li>Multiple output formats</li> <li>Batch processing</li> <li>Parameter customization</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeFunc/","title":"PipeFunc","text":"<p>The <code>PipeFunc</code> operator provides an essential escape hatch, allowing you to execute arbitrary Python code from within a pipeline. This is useful for custom data manipulation, complex logic, or integrating with external services not supported by other operators.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeFunc/#how-it-works","title":"How it works","text":"<p><code>PipeFunc</code> operates by calling a Python function that has been registered with Pipelex's central function registry.</p> <ol> <li>Function Registration: First, you must define a standard Python function and register it with a unique name. This is done once when your application starts up.</li> <li>Function Signature: The registered function must accept a single argument: <code>working_memory: WorkingMemory</code>. This object provides access to all the data currently available in the pipeline.</li> <li>Execution: When the <code>PipeFunc</code> pipe is executed, it looks up your function by its registered name and calls it, passing in the current <code>working_memory</code>.</li> <li>Returning Data: The function can return data, which <code>PipeFunc</code> will then place back into the working memory, associated with the pipe's <code>output</code> concept.</li> </ol>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeFunc/#return-values","title":"Return values","text":"<p>Your Python function can return one of the following: -   A <code>StuffContent</code> object (e.g., <code>TextContent</code>, <code>ImageContent</code>, or a custom <code>StructuredContent</code> model). -   A <code>list</code> of <code>StuffContent</code> objects. -   A simple Python <code>str</code>, which will be automatically converted to a <code>TextContent</code>.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeFunc/#how-to-register-a-function","title":"How to Register a Function","text":"<p>To make a Python function available to <code>PipeFunc</code>, you must register it using the global <code>func_registry</code>.</p> <p>Here is an example of a function and its registration:</p> <pre><code># in a file like my_custom_functions.py\n\nfrom pipelex.core.working_memory import WorkingMemory\nfrom pipelex.core.stuff_content import TextContent\nfrom pipelex.tools.func_registry import func_registry\n\ndef concatenate_texts(working_memory: WorkingMemory) -&gt; TextContent:\n    \"\"\"\n    Retrieves two text stuffs, concatenates them, and returns a new text stuff.\n    \"\"\"\n    # Get data from working memory using the names from previous steps\n    text1 = working_memory.get_stuff_as_str(\"text_a\")\n    text2 = working_memory.get_stuff_as_str(\"text_b\")\n\n    concatenated = f\"{text1} -- {text2}\"\n\n    return TextContent(text=concatenated)\n\ndef register_my_functions():\n    \"\"\"This function should be called at application startup.\"\"\"\n    func_registry.register_function(concatenate_texts, name=\"combine_two_texts\")\n</code></pre> <p>You would then call <code>register_my_functions()</code> when your Pipelex application initializes.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeFunc/#configuration","title":"Configuration","text":"<p>Once the function is registered, you can use it in your <code>.toml</code> file.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeFunc/#toml-parameters","title":"TOML Parameters","text":"Parameter Type Description Required <code>PipeFunc</code> string A descriptive name for the pipe's function. Yes <code>function_name</code> string The unique name used to register the Python function (e.g., \"combine_two_texts\"). Yes <code>output</code> string The concept to associate with the function's return value. Yes"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeFunc/#example","title":"Example","text":"<p>This TOML snippet shows how to use the <code>combine_two_texts</code> function defined above. It assumes two previous pipes have produced outputs named <code>text_a</code> and <code>text_b</code>.</p> <pre><code>[pipe.combine_them]\nPipeFunc = \"Combine two text inputs using a custom Python function\"\nfunction_name = \"combine_two_texts\"\noutput = \"ConcatenatedText\"\n</code></pre>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeImgGen/","title":"PipeImgGen","text":"<p>The <code>PipeImgGen</code> operator is used to generate images from a text prompt using a specified image generation model.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeImgGen/#how-it-works","title":"How it works","text":"<p><code>PipeImgGen</code> takes a text prompt and a set of parameters, then calls an underlying image generation service (like DALL-E 3 or Stable Diffusion) to create one or more images.</p> <p>The prompt can be provided in two ways: 1.  As a static string directly in the pipe's TOML definition using the <code>imgg_prompt</code> parameter. 2.  As a dynamic input by connecting a concept that is or refines <code>native.Text</code>.</p> <p>The pipe can be configured to generate a single image or a list of images.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeImgGen/#configuration","title":"Configuration","text":"<p><code>PipeImgGen</code> is configured in your pipeline's <code>.toml</code> file.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeImgGen/#toml-parameters","title":"TOML Parameters","text":"Parameter Type Description Required <code>PipeImgGen</code> string A descriptive name for the image generation operation. Yes <code>inputs</code> dictionary The input concept(s) for the image generation operation, as a dictionary mapping input names to concept codes. Yes <code>output</code> string The output concept produced by the image generation operation. Yes <code>imgg_prompt</code> string A static text prompt for image generation. Use this or <code>input</code>. No <code>output_multiplicity</code> integer The number of images to generate. If omitted, a single image is generated. No <code>imgg_handle</code> string The handle for the image generation model to use (e.g., <code>\"dall-e-3\"</code>). Defaults to the model specified in the global config. No <code>aspect_ratio</code> string The desired aspect ratio of the image (e.g., <code>\"16:9\"</code>, <code>\"1:1\"</code>). No <code>quality</code> string The quality of the generated image (e.g., <code>\"standard\"</code>, <code>\"hd\"</code>). No <code>seed</code> integer or \"auto\" A seed for the random number generator to ensure reproducibility. <code>\"auto\"</code> uses a random seed. No <code>nb_steps</code> integer For diffusion models, the number of steps to run. More steps can increase detail but take longer. No <code>guidance_scale</code> float How strictly the model should adhere to the prompt. Higher values mean closer adherence. No"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeImgGen/#example-generating-a-single-image-from-a-static-prompt","title":"Example: Generating a single image from a static prompt","text":"<p>This pipe generates one image of a futuristic car without requiring any input.</p> <pre><code>[pipe.generate_car_image]\nPipeImgGen = \"Generate a futuristic car image\"\noutput = \"Image\"\nimgg_prompt = \"A sleek, futuristic sports car driving on a neon-lit highway at night.\"\nimgg_handle = \"dall-e-3\"\naspect_ratio = \"16:9\"\nquality = \"hd\"\n</code></pre>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeImgGen/#example-generating-multiple-images-from-a-dynamic-prompt","title":"Example: Generating multiple images from a dynamic prompt","text":"<p>This pipe takes a text prompt as input and generates three variations of the image.</p> <pre><code>[concept]\nImagePrompt = \"A text prompt for generating an image\"\n\n[pipe.generate_logo_variations]\nPipeImgGen = \"Generate three logo variations from a prompt\"\ninputs = { prompt = \"images.ImgGenPrompt\" }\noutput = \"Image\"\nnb_output = 3\nimgg_handle = \"stable-diffusion\"\naspect_ratio = \"1:1\"\n</code></pre> <p>To use this pipe, you would first load a text prompt (e.g., \"A minimalist logo for a coffee shop, featuring a stylized mountain and a coffee bean\") into the \"prompt\" stuff (<code>ImgGenPrompt</code> concept). After running, the output will be a list containing three generated <code>ImageContent</code> objects.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeJinja2/","title":"PipeJinja2","text":"<p>The <code>PipeJinja2</code> operator is a powerful utility for rendering Jinja2 templates. It allows you to dynamically generate text by combining data from your pipeline's working memory with a template. This is ideal for creating formatted reports, HTML content, or constructing complex, multi-part prompts for LLMs.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeJinja2/#how-it-works","title":"How it works","text":"<p><code>PipeJinja2</code> takes all the data currently in the <code>WorkingMemory</code> and uses it as the context for rendering a Jinja2 template. The resulting text is then saved back to the working memory as a new <code>Text</code> output.</p> <p>The template itself can be provided in one of two ways: 1.  By Name: Referring to a template file that has been loaded into Pipelex's template provider. This is the most common and maintainable method. 2.  Inline: Providing the template as a multi-line string directly in the <code>.toml</code> file.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeJinja2/#templating-context","title":"Templating Context","text":"<p>The Jinja2 template has access to all the \"stuffs\" currently in the working memory. You can access them by the names they were given in previous pipeline steps. For example, if a previous step produced an output named <code>user_profile</code>, you can access its attributes in the template like <code>{{ user_profile.name }}</code> or <code>{{ user_profile.email }}</code>.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeJinja2/#configuration","title":"Configuration","text":"<p><code>PipeJinja2</code> is configured in your pipeline's <code>.toml</code> file.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeJinja2/#toml-parameters","title":"TOML Parameters","text":"Parameter Type Description Required <code>PipeJinja2</code> string A descriptive name for the pipe's function. Yes <code>output</code> string The concept for the output. Defaults to <code>native.Text</code>. No <code>jinja2_name</code> string The name of a pre-loaded template file. Yes (or <code>jinja2</code>) <code>jinja2</code> string An inline Jinja2 template string. Yes (or <code>jinja2_name</code>) <code>extra_context</code> table (dict) A table of key-value pairs to add to the rendering context, making them available as variables in the template. No"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeJinja2/#example-generating-a-report-from-a-template-file","title":"Example: Generating a report from a template file","text":"<p>This example assumes you have a user profile object and a list of activities in the working memory, and a template file named <code>weekly_report.md</code> has been registered.</p> <p><code>weekly_report.md</code> template file: <pre><code># Weekly Report for {{ user.name }}\n\nHello {{ user.first_name }},\n\nHere is a summary of your activity this week:\n\n{% for activity in activities %}\n- {{ activity.timestamp }}: {{ activity.description }}\n{% else %}\n- No activity logged this week.\n{% endfor %}\n\nReport generated on: {{ report_date }}\n</code></pre></p> <p>Pipeline TOML definition: <pre><code>[pipe.generate_weekly_report]\nPipeJinja2 = \"Generate a formatted weekly report for a user\"\noutput = \"WeeklyReportText\"\njinja2_name = \"weekly_report.md\"\nextra_context = { report_date = \"2023-10-27\" }\n</code></pre></p> <p>In this scenario: - <code>PipeJinja2</code> will load the <code>weekly_report.md</code> template. - It will use the <code>user</code> and <code>activities</code> objects from the working memory. - It will add <code>report_date</code> to the context from the <code>extra_context</code> table. - The rendered markdown text will be saved as the <code>WeeklyReportText</code> concept. </p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeLLM/","title":"PipeLLM","text":"<p><code>PipeLLM</code> is the core operator in Pipelex for leveraging Large Language Models (LLMs). It can be used for a wide range of tasks, including text generation, summarization, classification, and structured data extraction.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeLLM/#how-it-works","title":"How it works","text":"<p>At its core, <code>PipeLLM</code> constructs a detailed prompt from various inputs and templates, sends it to a specified LLM, and processes the output. It can produce simple text or complex structured data (in the form of Pydantic models).</p> <p>For structured data output, <code>PipeLLM</code> employs two main strategies:</p> <ol> <li>Direct Mode: The LLM is prompted to directly generate a JSON object that conforms to the target Pydantic model's schema. This is fast but relies on the LLM's ability to generate well-formed JSON.</li> <li>Preliminary Text Mode: This is a more robust two-step process:     a. First, the LLM generates a free-form text based on the initial prompt.     b. Second, another LLM call is made with a specific prompt designed to extract and structure the information from the generated text into the target Pydantic model.</li> </ol>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeLLM/#working-with-images-vision-language-models","title":"Working with Images (Vision Language Models)","text":"<p><code>PipeLLM</code> supports Vision Language Models (VLMs) that can process both text and images. To use images in your prompts:</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeLLM/#basic-image-input","title":"Basic Image Input","text":"<p>Images must be declared in the <code>inputs</code> section of your pipe definition. The image will be automatically passed to the VLM along with your text prompt.</p> <pre><code>[pipe.describe_image]\nPipeLLM = \"Describe an image\"\ninputs = { image = \"Image\" }\noutput = \"VisualDescription\"\nprompt_template = \"\"\"\nDescribe the provided image in great detail.\n\"\"\"\n</code></pre> <p>Important: Do NOT reference image variables in your prompt template using <code>@image</code> or <code>$image</code>. Images are automatically passed to vision-enabled LLMs and should not be treated as text variables.</p> <p>Flexible Image Inputs</p> <p>You can use any concept that refines <code>Image</code> as an input, and choose descriptive variable names that fit your use case:</p> <pre><code>[pipe.analyze_wedding]\nPipeLLM = \"Analyze wedding photo\"\ninputs = { wedding_photo = \"images.Photo\" }\noutput = \"PhotoAnalysis\"\nprompt_template = \"\"\"\nAnalyze this wedding photo and describe the key moments captured.\n\"\"\"\n</code></pre>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeLLM/#images-as-sub-attributes-of-structured-content","title":"Images as Sub-attributes of Structured Content","text":"<p>When working with structured content that contains image fields (like <code>PageContent</code> which has a <code>page_view</code> field), you need to specify the full path to the image attribute in the <code>inputs</code> section:</p> <pre><code>[pipe.analyze_page_view]\nPipeLLM = \"Analyze the visual layout of a page\"\ninputs = { \"page_content.page_view\" = \"Image\" }\noutput = \"LayoutAnalysis\"\nprompt_template = \"\"\"\nAnalyze the visual layout and design elements of this page.\nFocus on typography, spacing, and overall composition.\n\"\"\"\n</code></pre> <p>In this example: - <code>page_content</code> is the input variable containing a <code>PageContent</code> object - <code>page_view</code> is the <code>ImageContent</code> field within the <code>PageContent</code> structure - The dot notation <code>page_content.page_view</code> tells Pipelex to extract the image from that specific field</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeLLM/#multiple-images","title":"Multiple Images","text":"<p>You can include multiple images in a single prompt by listing them in the inputs:</p> <pre><code>[pipe.compare_images]\nPipeLLM = \"Compare two images\"\ninputs = { \n    first_image = \"Image\",\n    second_image = \"Image\"\n}\noutput = \"ImageComparison\"\nprompt_template = \"\"\"\nCompare these two images and describe their similarities and differences.\n\"\"\"\n</code></pre>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeLLM/#combining-text-and-image-inputs","title":"Combining Text and Image Inputs","text":"<p>You can mix any stuff and image inputs in the same pipe:</p> <pre><code>[pipe.analyze_document_with_context]\nPipeLLM = \"Analyze a document page with additional context\"\ninputs = { \n    context = \"Text\",\n    document.page_view = \"Image\"\n}\noutput = \"DocumentAnalysis\"\nprompt_template = \"\"\"\nGiven this context: $context\n\nAnalyze the document page shown in the image and explain how it relates to the provided context.\n\"\"\"\n</code></pre>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeLLM/#configuration","title":"Configuration","text":"<p><code>PipeLLM</code> is configured in your pipeline's <code>.toml</code> file.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeLLM/#toml-parameters","title":"TOML Parameters","text":"Parameter Type Description Required <code>PipeLLM</code> string A descriptive name for the LLM operation. Yes <code>inputs</code> dictionary The input concept(s) for the LLM operation, as a dictionary mapping input names to concept codes. For images within structured content, use dot notation (e.g., <code>\"page.image\"</code>). Yes <code>output</code> string The output concept produced by the LLM operation. Yes <code>llm</code> string or table Specifies the LLM preset(s) to use. Can be a single preset or a table mapping different presets for different generation modes (e.g., <code>main</code>, <code>object_direct</code>). No <code>system_prompt</code> string A system-level prompt to guide the LLM's behavior (e.g., \"You are a helpful assistant\"). Can be inline text or a reference to a template file (<code>\"file:path/to/prompt.md\"</code>). No <code>prompt</code> string A simple, static user prompt. Use this when you don't need to inject any variables. No <code>prompt_template</code> string A template for the user prompt. Use <code>$</code> for inline variables (e.g., <code>$topic</code>) and <code>@</code> to insert the content of an entire input (e.g., <code>@text_to_summarize</code>). Note: Do not use <code>@</code> or <code>$</code> for image variables. No <code>images</code> list of strings Deprecated: Use the <code>inputs</code> section to declare image inputs instead. No <code>structuring_method</code> string The method for generating structured output. Can be <code>direct</code> or <code>preliminary_text</code>. Defaults to the global configuration. No <code>prompt_template_to_structure</code> string The prompt template for the second step in <code>preliminary_text</code> mode. No <code>nb_output</code> integer Specifies exactly how many outputs to generate (e.g., <code>nb_output = 3</code> for exactly 3 outputs). Use when you need a fixed number of results. Mutually exclusive with <code>multiple_output</code>. No <code>multiple_output</code> boolean Controls output generation mode. Default is <code>false</code> (single output). Set to <code>true</code> for variable-length list generation when you need an indeterminate number of outputs. Mutually exclusive with <code>nb_output</code>. No"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeLLM/#output-generation-modes","title":"Output Generation Modes","text":"<p><code>PipeLLM</code> supports three different output generation modes:</p> <ol> <li> <p>Single Output (default): Don't specify <code>nb_output</code> or <code>multiple_output</code>, or set <code>multiple_output = false</code>. The LLM generates exactly one result.</p> </li> <li> <p>Fixed Multiple Outputs: Use <code>nb_output = N</code> (where N is a positive integer) when you need exactly N outputs. For example, <code>nb_output = 3</code> will try to generate 3 results. The parameter <code>_nb_output</code> will be available in the prompt template, e.g. \"Give me the names of $_nb_output flowers\".</p> </li> <li> <p>Variable Multiple Outputs: Use <code>multiple_output = true</code> when you need a variable-length list where the LLM determines how many outputs to generate based on the content and context.</p> </li> </ol>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeLLM/#examples","title":"Examples","text":""},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeLLM/#simple-text-generation-example","title":"Simple Text Generation Example","text":"<p>This pipe takes no input and writes a poem.</p> <pre><code>[pipe.write_poem]\nPipeLLM = \"Write a short poem\"\noutput = \"Text\"\nllm = \"llm_for_creative_writing\"\nprompt = \"\"\"\nWrite a four-line poem about pipes.\n\"\"\"\n</code></pre>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeLLM/#text-to-text-example","title":"Text-to-Text Example","text":"<p>This pipe summarizes an input text, using a <code>prompt_template</code> to inject the input.</p> <pre><code>[pipe.summarize_text]\nPipeLLM = \"Summarize a text\"\ninputs = { text = \"TextToSummarize\" }\noutput = \"TextSummary\"\nprompt_template = \"\"\"\nPlease provide a concise summary of the following text:\n\n@text\n\nThe summary should be no longer than 3 sentences.\n\"\"\"\n</code></pre>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeLLM/#vision-vlm-example","title":"Vision (VLM) Example","text":"<p>This pipe takes an image of a table and uses a VLM to extract the content as an HTML table.</p> <pre><code>[pipe.extract_table_from_image]\nPipeLLM = \"Extract table data from an image\"\ninputs = { image = \"TableScreenshot\" }\noutput = \"TableData\"\nprompt_template = \"\"\"\nExtract the table data from this image and format it as a structured table.\n\"\"\"\n</code></pre>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeLLM/#structured-data-extraction-example","title":"Structured Data Extraction Example","text":"<p>This pipe extracts a list of <code>Expense</code> items from a block of text.</p> <pre><code>[concept.Expense]\nstructure = \"Expense\" # Assumes a Pydantic model 'Expense' is defined\n\n[pipe.process_expense_report]\nPipeLLM = \"Process an expense report\"\ninputs = { report = \"ExpenseReport\" }\noutput = \"ProcessedExpenseReport\"\nprompt_template = \"\"\"\nAnalyze this expense report and extract the following information:\n- Total amount\n- Date\n- Vendor\n- Category\n- Line items\n\n@report\n\"\"\"\n</code></pre> <p>In this example, <code>Pipelex</code> will instruct the LLM to return a list of objects that conform to the <code>Expense</code> structure.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeOcr/","title":"PipeOcr","text":"<p>The <code>PipeOcr</code> operator performs Optical Character Recognition (OCR) on images and PDF documents. It extracts text, embedded images, and provides full-page renderings.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeOcr/#how-it-works","title":"How it works","text":"<p><code>PipeOcr</code> takes a single input, which must be either an <code>Image</code> or a <code>Pdf</code>. It processes the document page by page and produces a list of <code>PageContent</code> objects. Each <code>PageContent</code> object encapsulates all the information extracted from a single page.</p> <p>The output is always a list, even if the input is a single image (in which case the list will contain just one item).</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeOcr/#the-pagecontent-structure","title":"The <code>PageContent</code> Structure","text":"<p>The <code>PageContent</code> object has the following structure:</p> <ul> <li><code>text_and_images</code>: Contains the main extracted content.<ul> <li><code>text</code>: The recognized text from the page as a <code>TextContent</code>.</li> <li><code>images</code>: A list of any images found embedded within the page.</li> </ul> </li> <li><code>page_view</code>: An <code>ImageContent</code> object representing a full visual rendering of the page.</li> </ul>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeOcr/#configuration","title":"Configuration","text":"<p><code>PipeOcr</code> is configured in your pipeline's <code>.toml</code> file.</p>"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeOcr/#toml-parameters","title":"TOML Parameters","text":"Parameter Type Description Required <code>PipeOcr</code> string A descriptive name for the OCR operation. Yes <code>inputs</code> Fixed The input for the PipeOcr is the key <code>ocr_input</code> and the value is either of concept <code>Image</code> or <code>Pdf</code>. Yes <code>output</code> string The output concept produced by the OCR operation. Yes <code>should_include_images</code> boolean If <code>true</code>, any images found within the document pages will be extracted and included in the output. Defaults to <code>false</code>. No <code>should_include_page_views</code> boolean If <code>true</code>, a high-fidelity image of each page will be included in the <code>page_view</code> field. Defaults to <code>false</code>. No <code>page_views_dpi</code> integer The resolution (in Dots Per Inch) for the generated page views when processing a PDF. Defaults to <code>150</code>. No <code>should_caption_images</code> boolean If <code>true</code>, the OCR service may attempt to generate captions for the images found. Note: This feature depends on the OCR provider. No"},{"location":"pages/build-reliable-ai-workflows-with-pipelex/pipe-operators/PipeOcr/#example-processing-a-pdf","title":"Example: Processing a PDF","text":"<p>This example defines a pipe that takes a PDF, extracts text and full-page images, and outputs them as a list of pages.</p> <pre><code>[concept]\nScannedDocument = \"A document that has been scanned as a PDF\"\nExtractedPages = \"A list of pages extracted from a document by OCR\"\n\n[pipe.extract_text_from_document]\nPipeOcr = \"Extract text from a scanned document\"\ninputs = { ocr_input = \"ScannedDocument\" }\noutput = \"ExtractedText\"\nshould_include_page_views = true\npage_views_dpi = 200\n</code></pre> <p>To use this pipe, you would first need to load a PDF into the <code>ScannedDocument</code> concept. After the pipe runs, the <code>ExtractedPages</code> concept will contain a list of <code>PageContent</code> objects, where each object has the extracted text and a 200 DPI image of the corresponding page.</p>"},{"location":"pages/configuration/","title":"Configuration","text":""},{"location":"pages/configuration/#overview","title":"Overview","text":"<p>Pipelex uses a TOML-based configuration system. The main configuration file <code>pipelex.toml</code> must be located at the root of your project. You can create this file by running:</p> <pre><code>pipelex init-config\n</code></pre> <p>\ud83d\udca1 Important Notes:</p> <ol> <li><code>pipelex init-config</code> creates a template configuration file with sample settings. It does not include all possible configuration options - it's meant as a starting point.</li> <li>Using <code>pipelex init-config --reset</code> will overwrite your existing <code>pipelex.toml</code> file without warning. Make sure to backup your configuration before using this flag.</li> </ol> <p>For a complete list of all possible configuration options, refer to the configuration group documentation below.</p>"},{"location":"pages/configuration/#configuration-structure","title":"Configuration Structure","text":"<p>The configuration is organized into three main sections:</p> <ol> <li><code>[pipelex]</code> - Core Pipelex settings</li> <li><code>[cogt]</code> - Cognitive tools and LLM settings</li> <li><code>[plugins]</code> - Plugin-specific configurations</li> </ol> <p>Each section contains multiple subsections for specific features and functionalities.</p>"},{"location":"pages/configuration/#configuration-override-system","title":"Configuration Override System","text":"<p>Pipelex uses a sophisticated configuration override system that loads and merges configurations in a specific order. This allows for fine-grained control over settings in different environments and scenarios.</p> <p>The exact loading sequence is:</p> <ol> <li>Base configuration from the installed Pipelex package (<code>pipelex.toml</code>)</li> <li>Your project's base configuration (<code>pipelex.toml</code> in your project root)</li> <li>Local overrides (<code>pipelex_local.toml</code>)</li> <li>Environment-specific overrides (<code>pipelex_{environment}.toml</code>)</li> <li>Example environments: dev, staging, prod -&gt; based on the environment variable <code>ENV</code> in your .env file</li> <li>Run mode overrides (<code>pipelex_{run_mode}.toml</code>)</li> <li>Example run modes: normal, unit_test</li> <li>Super user overrides (<code>pipelex_super.toml</code>) (recommended to put in .gitignore)</li> </ol> <p>Each subsequent configuration file in this sequence can override settings from the previous ones. This means: - Settings in <code>pipelex_local.toml</code> override the base configuration - Environment-specific settings override local settings - Run mode settings override environment settings - Super user settings override all previous settings</p>"},{"location":"pages/configuration/#override-file-naming","title":"Override File Naming","text":"<ul> <li>Base config: <code>pipelex.toml</code></li> <li>Local overrides: <code>pipelex_local.toml</code></li> <li>Environment overrides: <code>pipelex_dev.toml</code>, <code>pipelex_staging.toml</code>, <code>pipelex_prod.toml</code>, etc.</li> <li>Run mode overrides: <code>pipelex_normal.toml</code>, <code>pipelex_unit_test.toml</code>, etc.</li> <li>Super user overrides: <code>pipelex_super.toml</code></li> </ul> <p>NB: The run_mode unit_test is used for testing purposes.</p>"},{"location":"pages/configuration/#best-practices-for-overrides","title":"Best Practices for Overrides","text":"<ol> <li>Use the base <code>pipelex.toml</code> for default settings</li> <li>Use <code>pipelex_local.toml</code> for machine-specific settings</li> <li>Use environment files for environment-specific settings (dev, staging, prod)</li> <li>Use run mode files for normal or unit_test configurations</li> <li>Use <code>pipelex_super.toml</code> sparingly, only for temporary overrides (add to .gitignore)</li> </ol>"},{"location":"pages/configuration/#best-practices","title":"Best Practices","text":"<ol> <li>Version Control: Include your base <code>pipelex.toml</code> in version control</li> <li>Environment Overrides: Use environment-specific files for sensitive or environment-dependent settings</li> <li>Documentation: Comment any custom settings for team reference</li> <li>Validation: Run <code>pipelex validate</code> after making configuration changes</li> <li>Gitignore: Add local and sensitive override files to <code>.gitignore</code></li> </ol>"},{"location":"pages/configuration/config-advanced/feature-config/","title":"Feature Configuration","text":"<p>The <code>FeatureConfig</code> class controls which features are enabled in Pipelex.</p>"},{"location":"pages/configuration/config-advanced/feature-config/#configuration-options","title":"Configuration Options","text":"<pre><code>class FeatureConfig(ConfigModel):\n    is_pipeline_tracking_enabled: bool\n    is_activity_tracking_enabled: bool\n    is_reporting_enabled: bool\n</code></pre>"},{"location":"pages/configuration/config-advanced/feature-config/#fields","title":"Fields","text":"<ul> <li><code>is_pipeline_tracking_enabled</code>: When true, enables pipeline tracking functionality</li> <li><code>is_activity_tracking_enabled</code>: When true, enables activity tracking functionality</li> <li><code>is_reporting_enabled</code>: When true, enables the reporting system</li> </ul>"},{"location":"pages/configuration/config-advanced/feature-config/#impact-on-dependency-injection","title":"Impact on Dependency Injection","text":"<p>The feature flags directly affect which implementation is used for certain components:</p> Feature Flag When True When False <code>is_pipeline_tracking_enabled</code> <code>PipelineTracker</code> <code>PipelineTrackerNoOp</code> <code>is_activity_tracking_enabled</code> <code>ActivityManager</code> <code>ActivityManagerNoOp</code> <code>is_reporting_enabled</code> <code>ReportingManager</code> <code>ReportingNoOp</code>"},{"location":"pages/configuration/config-advanced/feature-config/#feature-details","title":"Feature Details","text":""},{"location":"pages/configuration/config-advanced/feature-config/#pipeline-tracking","title":"Pipeline Tracking","text":"<pre><code>is_pipeline_tracking_enabled = false\n</code></pre> <ul> <li>Controls whether pipeline execution tracking is enabled</li> <li>When enabled, tracks the flow and execution of pipelines using by default mermaid chart:</li> <li>View and edit charts at Mermaid Live Editor</li> <li>Useful for debugging and monitoring pipeline behavior</li> <li>Default: <code>false</code></li> </ul>"},{"location":"pages/configuration/config-advanced/feature-config/#activity-tracking","title":"Activity Tracking","text":"<pre><code>is_activity_tracking_enabled = false\n</code></pre> <ul> <li>Controls whether activity tracking is enabled</li> <li>When enabled, tracks detailed information about system activities</li> <li>Default: <code>false</code></li> </ul>"},{"location":"pages/configuration/config-advanced/feature-config/#reporting","title":"Reporting","text":"<pre><code>is_reporting_enabled = true\n</code></pre> <ul> <li>Controls whether reporting functionality is enabled</li> <li>When enabled, generates the cost report of the pipelex execution (LLM costs, OCR costs, etc...)</li> <li>Default: <code>true</code></li> </ul>"},{"location":"pages/configuration/config-advanced/feature-config/#example-configuration","title":"Example Configuration","text":"<pre><code>[pipelex.feature_config]\n# Enable pipeline tracking for debugging\nis_pipeline_tracking_enabled = true\n\n# Disable activity tracking for performance\nis_activity_tracking_enabled = false\n\n# Enable reporting for cost monitoring\nis_reporting_enabled = true\n</code></pre>"},{"location":"pages/configuration/config-pipeline-validation/dry-run-config/","title":"Dry Run Configuration","text":"<p>The <code>DryRunConfig</code> class controls how Pipelex behaves during dry runs.</p>"},{"location":"pages/configuration/config-pipeline-validation/dry-run-config/#configuration-options","title":"Configuration Options","text":"<pre><code>class DryRunConfig(ConfigModel):\n    apply_to_jinja2_rendering: bool\n    text_gen_truncate_length: int\n</code></pre>"},{"location":"pages/configuration/config-pipeline-validation/dry-run-config/#fields","title":"Fields","text":"<ul> <li><code>apply_to_jinja2_rendering</code>: When true, simulates Jinja2 template rendering during dry runs</li> <li><code>text_gen_truncate_length</code>: Maximum length of generated text during dry runs</li> </ul>"},{"location":"pages/configuration/config-pipeline-validation/dry-run-config/#example-configuration","title":"Example Configuration","text":"<pre><code>[pipelex.dry_run_config]\napply_to_jinja2_rendering = true\ntext_gen_truncate_length = 100\n</code></pre>"},{"location":"pages/configuration/config-pipeline-validation/dry-run-config/#dry-run-behavior","title":"Dry Run Behavior","text":""},{"location":"pages/configuration/config-pipeline-validation/dry-run-config/#template-rendering","title":"Template Rendering","text":"<p>When <code>apply_to_jinja2_rendering</code> is true:</p> <ul> <li>Templates are processed but not actually rendered</li> <li>Variables are validated</li> <li>Template syntax is checked</li> <li>No actual content is generated</li> </ul>"},{"location":"pages/configuration/config-pipeline-validation/dry-run-config/#text-generation","title":"Text Generation","text":"<p>The <code>text_gen_truncate_length</code> controls:</p> <ul> <li>Maximum length of simulated text output</li> <li>Helps prevent excessive resource usage during testing</li> <li>Makes dry run output more manageable</li> </ul>"},{"location":"pages/configuration/config-pipeline-validation/dry-run-config/#use-cases","title":"Use Cases","text":"<ol> <li> <p>Testing Pipeline Logic</p> <ul> <li>Validate pipeline structure</li> <li>Check template syntax</li> <li>Verify variable references</li> </ul> </li> <li> <p>Resource Estimation</p> <ul> <li>Estimate processing time</li> <li>Calculate potential costs</li> <li>Plan resource allocation</li> </ul> </li> <li> <p>Debugging</p> <ul> <li>Trace execution paths</li> <li>Identify potential issues</li> <li>Test error handling</li> </ul> </li> </ol>"},{"location":"pages/configuration/config-pipeline-validation/dry-run-config/#best-practices","title":"Best Practices","text":"<ul> <li>Use dry runs for testing before production</li> <li>Set appropriate truncation lengths</li> <li>Enable template validation when testing templates</li> <li>Review dry run logs for potential issues</li> </ul>"},{"location":"pages/configuration/config-pipeline-validation/static-validation-config/","title":"Static Validation Configuration","text":"<p>The <code>StaticValidationConfig</code> class controls how Pipelex handles validation errors during static analysis.</p>"},{"location":"pages/configuration/config-pipeline-validation/static-validation-config/#configuration-options","title":"Configuration Options","text":"<pre><code>class StaticValidationReaction(StrEnum):\n    RAISE = \"raise\"    # Raise an exception\n    LOG = \"log\"        # Log the error but continue\n    IGNORE = \"ignore\"  # Silently ignore the error\n\nclass StaticValidationConfig(ConfigModel):\n    default_reaction: StaticValidationReaction\n    reactions: Dict[StaticValidationErrorType, StaticValidationReaction]\n</code></pre>"},{"location":"pages/configuration/config-pipeline-validation/static-validation-config/#fields","title":"Fields","text":"<ul> <li><code>default_reaction</code>: Default reaction for validation errors not specifically configured</li> <li><code>reactions</code>: Dictionary mapping specific error types to their reactions</li> </ul>"},{"location":"pages/configuration/config-pipeline-validation/static-validation-config/#error-types-and-reactions","title":"Error Types and Reactions","text":"<p>Each validation error type can be configured to have one of three reactions:</p> <ul> <li><code>RAISE</code>: Stops execution and raises an exception</li> <li><code>LOG</code>: Logs the error but allows execution to continue</li> <li><code>IGNORE</code>: Silently ignores the error</li> </ul>"},{"location":"pages/configuration/config-pipeline-validation/static-validation-config/#example-configuration","title":"Example Configuration","text":"<pre><code>[pipelex.static_validation_config]\ndefault_reaction = \"raise\"\n\n[pipelex.static_validation_config.reactions]\nmissing_input_variable = \"log\"\nextraneous_input_variable = \"log\"\ninadequate_input_concept = \"log\"\n</code></pre>"},{"location":"pages/configuration/config-pipeline-validation/static-validation-config/#validation-process","title":"Validation Process","text":"<ol> <li>When a validation error is detected, the system looks up the error type in the <code>reactions</code> dictionary</li> <li>If the error type is found, the corresponding reaction is used</li> <li>If the error type is not found, the <code>default_reaction</code> is used</li> <li>The reaction determines how the error is handled</li> </ol>"},{"location":"pages/configuration/config-pipeline-validation/static-validation-config/#best-practices","title":"Best Practices","text":"<ul> <li>Use <code>RAISE</code> for critical errors that should never be ignored</li> <li>Use <code>LOG</code> for warnings that should be addressed but aren't critical</li> <li>Use <code>IGNORE</code> sparingly and only for known, harmless cases</li> <li>Configure specific reactions for known error types</li> <li>Use a reasonable <code>default_reaction</code> for unexpected error types</li> </ul>"},{"location":"pages/configuration/config-practical/logging-config/","title":"Logging Configuration","text":"<p>Configuration section: <code>[pipelex.log_config]</code></p>"},{"location":"pages/configuration/config-practical/logging-config/#overview","title":"Overview","text":"<p>The logging configuration controls how Pipelex handles log messages, their formatting, and their display. The configuration is split into general logging settings and Rich console output settings.</p>"},{"location":"pages/configuration/config-practical/logging-config/#general-settings","title":"General Settings","text":""},{"location":"pages/configuration/config-practical/logging-config/#log-levels","title":"Log Levels","text":"<pre><code>default_log_level = \"INFO\"\n</code></pre> <ul> <li>Sets the default logging level for all loggers</li> <li>Valid values: <code>\"VERBOSE\"</code>, <code>\"DEBUG\"</code>, <code>\"DEV\"</code>, <code>\"INFO\"</code>, <code>\"WARNING\"</code>, <code>\"ERROR\"</code>, <code>\"CRITICAL\"</code>, <code>\"OFF\"</code></li> </ul>"},{"location":"pages/configuration/config-practical/logging-config/#package-specific-log-levels","title":"Package-Specific Log Levels","text":"<pre><code>[pipelex.log_config.package_log_levels]\nanthropic = \"INFO\"\nasyncio = \"INFO\"\nbotocore = \"INFO\"\nopenai = \"INFO\"\npipelex = \"INFO\"\n</code></pre> <ul> <li>Override log levels for specific packages</li> <li>Use <code>-</code> instead of <code>.</code> in package names (e.g., <code>urllib3-connectionpool</code>)</li> </ul>"},{"location":"pages/configuration/config-practical/logging-config/#console-output","title":"Console Output","text":"<pre><code>is_console_logging_enabled = true\n</code></pre> <ul> <li>Enable/disable console logging</li> <li>Default: <code>true</code></li> </ul>"},{"location":"pages/configuration/config-practical/logging-config/#json-formatting","title":"JSON Formatting","text":"<pre><code>json_logs_indent = 4\npresentation_line_width = 120\n</code></pre> <ul> <li><code>json_logs_indent</code>: Indentation for JSON log output</li> <li><code>presentation_line_width</code>: Maximum line width for formatted output</li> </ul>"},{"location":"pages/configuration/config-practical/logging-config/#caller-information","title":"Caller Information","text":"<pre><code>is_caller_info_enabled = false\ncaller_info_template = \"file_line\"\n</code></pre> <p>Available templates:</p> <ul> <li><code>\"file_line\"</code>: \"file.py:123\"</li> <li><code>\"file_line_func\"</code>: \"file.py:123 function_name\"</li> <li><code>\"func\"</code>: \"function_name\"</li> <li><code>\"file_func\"</code>: \"file.py function_name\"</li> <li><code>\"func_line\"</code>: \"function_name 123\"</li> <li><code>\"func_module\"</code>: \"function_name module\"</li> <li><code>\"func_module_line\"</code>: \"function_name module 123\"</li> </ul>"},{"location":"pages/configuration/config-practical/logging-config/#problem-silencing","title":"Problem Silencing","text":"<pre><code>silenced_problem_ids = [\"azure_openai_no_stream_options\"]\n</code></pre> <ul> <li>List of problem IDs to silence</li> <li>Prevents specific warnings from being logged</li> </ul>"},{"location":"pages/configuration/config-practical/logging-config/#poor-loggers","title":"Poor Loggers","text":"<pre><code>generic_poor_logger = \"#poor-log\"\npoor_loggers = [\n    \"kajson.decoder.sandbox\",\n    \"kajson.encoder.sandbox\",\n    \"class_registry.sandbox\"\n]\n</code></pre> <ul> <li>Loggers that use simplified formatting without fancy features</li> <li>Useful for sandbox environments or when simple logging is needed</li> </ul>"},{"location":"pages/configuration/config-practical/logging-config/#rich-console-configuration","title":"Rich Console Configuration","text":"<p>Configuration section: <code>[pipelex.log_config.rich_log_config]</code></p>"},{"location":"pages/configuration/config-practical/logging-config/#display-options","title":"Display Options","text":"<pre><code>is_show_time = false\nis_show_level = true\nis_link_path_enabled = true\n</code></pre> <ul> <li><code>is_show_time</code>: Show timestamp in logs</li> <li><code>is_show_level</code>: Show log level</li> <li><code>is_link_path_enabled</code>: Make file paths clickable</li> </ul>"},{"location":"pages/configuration/config-practical/logging-config/#syntax-highlighting","title":"Syntax Highlighting","text":"<pre><code>highlighter_name = \"json\"  # or \"repr\"\nis_markup_enabled = false\n</code></pre> <ul> <li><code>highlighter_name</code>: Choose between JSON or repr highlighting</li> <li><code>is_markup_enabled</code>: Enable Rich markup syntax in log messages</li> </ul>"},{"location":"pages/configuration/config-practical/logging-config/#traceback-settings","title":"Traceback Settings","text":"<pre><code>is_rich_tracebacks = true\nis_tracebacks_word_wrap = true\nis_tracebacks_show_locals = false\ntracebacks_suppress = []\n</code></pre> <ul> <li>Control how Python tracebacks are displayed</li> <li>Enable/disable word wrapping and local variable display</li> <li>Suppress specific traceback patterns</li> </ul>"},{"location":"pages/configuration/config-practical/logging-config/#keyword-highlighting","title":"Keyword Highlighting","text":"<pre><code>keywords_to_hilight = []\n</code></pre> <ul> <li>List of keywords to highlight in log messages</li> <li>Useful for emphasizing important terms</li> </ul>"},{"location":"pages/configuration/config-practical/logging-config/#example-configuration","title":"Example Configuration","text":"<pre><code>[pipelex.log_config]\ndefault_log_level = \"INFO\"\nis_console_logging_enabled = true\njson_logs_indent = 4\npresentation_line_width = 120\nis_caller_info_enabled = true\ncaller_info_template = \"file_line_func\"\n\nsilenced_problem_ids = []\ngeneric_poor_logger = \"#poor-log\"\npoor_loggers = []\n\n[pipelex.log_config.package_log_levels]\npipelex = \"INFO\"\nopenai = \"WARNING\"\nanthropic = \"INFO\"\n\n[pipelex.log_config.rich_log_config]\nis_show_time = false\nis_show_level = true\nis_link_path_enabled = true\nhighlighter_name = \"json\"\nis_markup_enabled = false\nis_rich_tracebacks = true\nis_tracebacks_word_wrap = true\nis_tracebacks_show_locals = false\ntracebacks_suppress = []\nkeywords_to_hilight = [\"error\", \"warning\", \"failed\"]\n</code></pre>"},{"location":"pages/configuration/config-practical/logging-config/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Development Environment:</p> <ul> <li>Enable caller info for better debugging</li> <li>Use verbose logging levels</li> <li>Enable local variables in tracebacks</li> </ul> </li> <li> <p>Production Environment:</p> <ul> <li>Disable caller info for performance</li> <li>Use INFO or higher log levels</li> <li>Disable local variables in tracebacks</li> </ul> </li> <li> <p>Package Log Levels:</p> <ul> <li>Set noisy third-party packages to WARNING</li> <li>Keep pipelex at INFO for important updates</li> <li>Use VERBOSE only when debugging specific issues</li> </ul> </li> </ol>"},{"location":"pages/configuration/config-practical/pipe-run-config/","title":"Pipe Run Configuration","text":"<p>The <code>PipeRunConfig</code> class controls execution parameters for pipes in Pipelex.</p>"},{"location":"pages/configuration/config-practical/pipe-run-config/#configuration-options","title":"Configuration Options","text":"<pre><code>class PipeRunConfig(ConfigModel):\n    pipe_stack_limit: int\n</code></pre>"},{"location":"pages/configuration/config-practical/pipe-run-config/#fields","title":"Fields","text":"<ul> <li><code>pipe_stack_limit</code>: Maximum depth of nested pipe executions allowed</li> </ul>"},{"location":"pages/configuration/config-practical/pipe-run-config/#example-configuration","title":"Example Configuration","text":"<pre><code>[pipelex.pipe_run_config]\npipe_stack_limit = 100\n</code></pre>"},{"location":"pages/configuration/config-practical/pipe-run-config/#stack-limit","title":"Stack Limit","text":"<p>The <code>pipe_stack_limit</code> prevents infinite recursion in pipe execution by:</p> <ul> <li>Limiting the depth of nested pipe calls</li> <li>Throwing an exception when the limit is exceeded</li> <li>Protecting against accidental circular dependencies</li> </ul>"},{"location":"pages/configuration/config-practical/pipe-run-config/#best-practices","title":"Best Practices","text":"<ul> <li>Set a reasonable stack limit based on your pipeline complexity</li> <li>Monitor stack usage in complex pipelines</li> </ul>"},{"location":"pages/configuration/config-practical/reporting-config/","title":"Reporting Configuration","text":"<p>Configuration section: <code>[pipelex.reporting_config]</code></p>"},{"location":"pages/configuration/config-practical/reporting-config/#overview","title":"Overview","text":"<p>The reporting configuration controls how Pipelex generates and manages cost reports for various operations (LLM usage, OCR processing, etc.). This configuration allows you to customize where and how cost reports are generated.</p>"},{"location":"pages/configuration/config-practical/reporting-config/#configuration-options","title":"Configuration Options","text":""},{"location":"pages/configuration/config-practical/reporting-config/#console-logging","title":"Console Logging","text":"<pre><code>is_log_costs_to_console = false\n</code></pre> <ul> <li>Controls whether costs are logged to the console in real-time</li> <li>When enabled, displays token cost reports after each LLM operation (and other operations with costs)</li> <li>Default: <code>false</code></li> </ul>"},{"location":"pages/configuration/config-practical/reporting-config/#cost-report-file-generation","title":"Cost Report File Generation","text":"<pre><code>is_generate_cost_report_file_enabled = true\n</code></pre> <ul> <li>Controls whether cost report files are generated after the execution of the pipeline</li> <li>When enabled, creates detailed reports in the xlsx format in the directory <code>reports/</code> by default.</li> <li>Default: <code>true</code></li> </ul>"},{"location":"pages/configuration/config-practical/reporting-config/#report-file-location","title":"Report File Location","text":"<pre><code>cost_report_dir_path = \"reports\"\n</code></pre> <ul> <li>Directory where cost report files will be saved</li> <li>Path is relative to your project root</li> <li>Directory will be created if it doesn't exist.</li> <li>Default: <code>\"reports\"</code></li> </ul>"},{"location":"pages/configuration/config-practical/reporting-config/#report-file-naming","title":"Report File Naming","text":"<pre><code>cost_report_base_name = \"cost_report\"\ncost_report_extension = \"xlsx\"\n</code></pre> <ul> <li>Base name for report files</li> <li>File extension for report files (e.g., \"xlsx\" for Excel files)</li> <li>Final filename will include an incremental number (e.g., <code>cost_report_1.xlsx</code>, <code>cost_report_2.xlsx</code>)</li> <li>Default: Base name = <code>\"cost_report\"</code>, Extension = <code>\"xlsx\"</code></li> </ul>"},{"location":"pages/configuration/config-practical/reporting-config/#cost-unit-scaling","title":"Cost Unit Scaling","text":"<pre><code>cost_report_unit_scale = 1.0\n</code></pre> <ul> <li>Scaling factor applied to cost values in reports</li> <li>Use 1.0 for actual costs</li> <li>Use different values to scale costs (e.g., 1000.0 for thousands)</li> <li>The currency is in USD.</li> <li>Default: <code>1.0</code></li> </ul>"},{"location":"pages/configuration/config-practical/reporting-config/#example-configuration","title":"Example Configuration","text":"<pre><code>[pipelex.reporting_config]\n# Enable console logging for development\nis_log_costs_to_console = true\n\n# Generate report files\nis_generate_cost_report_file_enabled = true\n\n# Store reports in a custom directory\ncost_report_dir_path = \"analytics/cost_reports\"\n\n# Customize report file naming\ncost_report_base_name = \"llm_costs\"\ncost_report_extension = \"xlsx\"\n\n# Show costs in thousands\ncost_report_unit_scale = 1000.0\n</code></pre>"},{"location":"pages/configuration/config-practical/reporting-config/#best-practices","title":"Best Practices","text":"<p>\u26a0\ufe0f Under construction</p>"},{"location":"pages/configuration/config-practical/tracker-config/","title":"Tracker Configuration","text":"<p>The Tracker Configuration allows you to customize how your pipeline execution is tracked and visualized. The tracker creates a Mermaid flowchart visualization of your pipeline's execution, showing how data flows through different pipes and transformations.</p>"},{"location":"pages/configuration/config-practical/tracker-config/#overview","title":"Overview","text":"<p>The pipeline tracker visualizes:</p> <ul> <li>Stuff nodes (data objects) and their transformations</li> <li>Pipe execution steps</li> <li>Batch processing branches</li> <li>Condition nodes and choices</li> <li>Aggregation steps</li> </ul>"},{"location":"pages/configuration/config-practical/tracker-config/#configuration-options","title":"Configuration Options","text":""},{"location":"pages/configuration/config-practical/tracker-config/#basic-settings","title":"Basic Settings","text":"<ul> <li> <p><code>is_debug_mode</code> (bool): Enable or disable debug mode for tracking</p> <ul> <li>When enabled, shows additional information like:<ul> <li>Node codes and internal identifiers</li> <li>Extended comments for repeated nodes</li> <li>Pipe codes in edge captions with comments</li> </ul> </li> </ul> </li> <li> <p><code>is_include_text_preview</code> (bool): Whether to include text previews in the tracking interface</p> <ul> <li>When enabled, shows first 100 characters of text content in stuff nodes</li> <li>Only applies to text-based stuff objects</li> </ul> </li> <li> <p><code>is_include_interactivity</code> (bool): Enable or disable interactive features in the tracking interface</p> </li> </ul>"},{"location":"pages/configuration/config-practical/tracker-config/#visual-settings","title":"Visual Settings","text":"<ul> <li> <p><code>theme</code> (str | \"auto\"): The visual theme to use for the Mermaid flowchart</p> <ul> <li>Use \"auto\" for automatic theme selection based on context</li> <li>Or specify a custom theme name</li> </ul> </li> <li> <p><code>layout</code> (str | \"auto\"): The layout algorithm to use for graph visualization</p> <ul> <li>Use \"auto\" for automatic layout selection</li> <li>Or specify a custom layout algorithm</li> <li>Affects how nodes and edges are arranged in the flowchart</li> </ul> </li> <li> <p><code>wrapping_width</code> (int | \"auto\"): Text wrapping width for node labels</p> <ul> <li>Use \"auto\" for automatic width adjustment</li> <li>Or specify a fixed width in characters</li> <li>Helps control the visual width of node content</li> </ul> </li> <li> <p><code>nb_items_limit</code> (int | \"unlimited\"): Maximum number of items to display</p> <ul> <li>Use \"unlimited\" for no limit</li> <li>Or specify a maximum number of items</li> <li>Helps manage visualization of large pipelines</li> </ul> </li> </ul>"},{"location":"pages/configuration/config-practical/tracker-config/#graph-styling","title":"Graph Styling","text":"<ul> <li> <p><code>sub_graph_colors</code> (List[str]): List of colors to use for sub-graphs</p> </li> <li> <p>Colors are used to visually distinguish different pipeline layers</p> </li> <li> <p>Example: <code>[\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\"]</code></p> </li> <li> <p>Edge Styles (all str type):</p> </li> <li> <p><code>pipe_edge_style</code>: Style for regular pipe transformation edges</p> </li> <li><code>branch_edge_style</code>: Style for batch processing branch edges</li> <li><code>aggregate_edge_style</code>: Style for aggregation step edges</li> <li><code>condition_edge_style</code>: Style for condition evaluation edges</li> <li><code>choice_edge_style</code>: Style for condition choice result edges</li> </ul>"},{"location":"pages/configuration/config-practical/tracker-config/#example-configuration","title":"Example Configuration","text":"<pre><code>[tracker]\nis_debug_mode = false\nis_include_text_preview = true\nis_include_interactivity = true\ntheme = \"auto\"\nlayout = \"auto\"\nwrapping_width = \"auto\"\nnb_items_limit = \"unlimited\"\nsub_graph_colors = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\"]\npipe_edge_style = \"solid\"\nbranch_edge_style = \"dashed\"\naggregate_edge_style = \"dotted\"\ncondition_edge_style = \"dashdot\"\nchoice_edge_style = \"solid\"\n</code></pre>"},{"location":"pages/configuration/config-practical/tracker-config/#property-accessors","title":"Property Accessors","text":"<p>The TrackerConfig class provides convenient property accessors that handle the \"auto\" and \"unlimited\" special values:</p> <ul> <li><code>applied_theme</code>: Returns None for \"auto\", otherwise returns the theme name</li> <li><code>applied_layout</code>: Returns None for \"auto\", otherwise returns the layout name</li> <li><code>applied_wrapping_width</code>: Returns None for \"auto\", otherwise returns the width as an integer</li> <li><code>applied_nb_items_limit</code>: Returns None for \"unlimited\", otherwise returns the limit as an integer</li> </ul> <p>These properties make it easy to work with the configuration values in your code while maintaining the flexibility of automatic settings.</p>"},{"location":"pages/configuration/config-practical/tracker-config/#visualization-features","title":"Visualization Features","text":"<p>The tracker generates Mermaid flowcharts with the following features:</p> <ol> <li> <p>Node Types:</p> <ul> <li>Start node (special)</li> <li>Stuff nodes (data objects)</li> <li>Condition nodes (for pipeline branching)</li> </ul> </li> <li> <p>Edge Types:</p> <ul> <li>Pipe edges (regular transformations)</li> <li>Branch edges (batch processing)</li> <li>Aggregate edges (combining results)</li> <li>Condition edges (with expressions)</li> <li>Choice edges (condition results)</li> </ul> </li> <li> <p>Node Content:</p> <ul> <li>Concept type and name</li> <li>Content preview (for text)</li> <li>Debug information (when debug mode is enabled)</li> <li>Comments and descriptions</li> </ul> </li> <li> <p>Visual Organization:</p> <ul> <li>Sub-graphs for different pipeline layers</li> <li>Color coding for visual distinction</li> <li>Different edge styles for different types of connections</li> </ul> </li> </ol>"},{"location":"pages/configuration/config-technical/aws-config/","title":"AWS Configuration","text":"<p>Configuration section: <code>[pipelex.aws_config]</code></p>"},{"location":"pages/configuration/config-technical/aws-config/#overview","title":"Overview","text":"<p>The AWS configuration controls how Pipelex authenticates with AWS services. It supports two authentication methods: environment variables or a secret provider.</p>"},{"location":"pages/configuration/config-technical/aws-config/#authentication-methods","title":"Authentication Methods","text":"<pre><code>[pipelex.aws_config]\napi_key_method = \"env\"  # or \"secret_provider\"\n</code></pre>"},{"location":"pages/configuration/config-technical/aws-config/#environment-variables-method-env","title":"Environment Variables Method (<code>\"env\"</code>)","text":"<p>When using <code>api_key_method = \"env\"</code>, Pipelex expects the following environment variables: - <code>AWS_ACCESS_KEY_ID</code>: Your AWS access key ID - <code>AWS_SECRET_ACCESS_KEY</code>: Your AWS secret access key - <code>AWS_REGION</code>: Your AWS region</p> <p>Example <code>.env</code> file: <pre><code>AWS_ACCESS_KEY_ID=your_access_key_id\nAWS_SECRET_ACCESS_KEY=your_secret_access_key\nAWS_REGION=us-east-1\n</code></pre></p>"},{"location":"pages/configuration/config-technical/aws-config/#secret-provider-method-secret_provider","title":"Secret Provider Method (<code>\"secret_provider\"</code>)","text":"<p>When using <code>api_key_method = \"secret_provider\"</code>, Pipelex will: 1. Connect to your configured secret provider 2. Look for the same keys as environment variables:    - <code>AWS_ACCESS_KEY_ID</code>    - <code>AWS_SECRET_ACCESS_KEY</code>    - <code>AWS_REGION</code></p> <p>\u26a0\ufe0f Important: To use the secret provider method, you must: 1. Configure a secret provider in your project using the <code>SecretsProviderProtocol</code>: See more in the Secrets documentation. 2. Store your AWS credentials in your secret provider 3. Ensure your secret provider is properly authenticated</p>"},{"location":"pages/configuration/config-technical/aws-config/#dependency-injection","title":"Dependency Injection","text":"<p>Pipelex uses dependency injection to manage AWS clients and credentials. You can:</p> <ul> <li>Inject custom AWS client implementations</li> <li>Override default credential providers</li> <li>Mock AWS services for testing</li> </ul> <p>For detailed information about dependency injection, including examples and best practices, see the Dependency Injection documentation.</p>"},{"location":"pages/configuration/config-technical/aws-config/#best-practices","title":"Best Practices","text":"<p>\u26a0\ufe0f Under construction</p>"},{"location":"pages/configuration/config-technical/cogt-config/","title":"Cognitive Tools (Cogt) Configuration","text":"<p>The Cogt configuration manages all cognitive tools in Pipelex, including LLM (Language Models), IMGG (Image Generation), and OCR (Optical Character Recognition) capabilities.</p>"},{"location":"pages/configuration/config-technical/cogt-config/#overview","title":"Overview","text":"<pre><code>[pipelex.cogt]\n# Main Cogt configuration sections\n[pipelex.cogt.inference_manager_config]\n[pipelex.cogt.llm_config]\n[pipelex.cogt.imgg_config]\n[pipelex.cogt.ocr_config]\n</code></pre>"},{"location":"pages/configuration/config-technical/cogt-config/#inference-manager-configuration","title":"Inference Manager Configuration","text":"<p>Controls automatic setup of various cognitive tools:</p> <pre><code>[pipelex.cogt.inference_manager_config]\nis_auto_setup_preset_llm = true\nis_auto_setup_preset_imgg = true\nis_auto_setup_preset_ocr = true\n</code></pre>"},{"location":"pages/configuration/config-technical/cogt-config/#llm-configuration","title":"LLM Configuration","text":"<p>Configuration for all Language Model interactions:</p> <pre><code>[pipelex.cogt.llm_config]\ndefault_max_images = 4  # Maximum number of images in prompts\n\n# Platform preferences for different LLMs\n[pipelex.cogt.llm_config.preferred_platforms]\ngpt-4 = \"openai\"\nclaude-3-opus = \"anthropic\"\n\n# Job configuration\n[pipelex.cogt.llm_config.llm_job_config]\nis_streaming_enabled = true\nmax_retries = 3  # Between 1 and 10\n\n# Instructor settings\n[pipelex.cogt.llm_config.instructor_config]\nis_openai_structured_output_enabled = true\n</code></pre>"},{"location":"pages/configuration/config-technical/cogt-config/#llm-job-parameters","title":"LLM Job Parameters","text":"<p>When configuring LLM jobs, you can set:</p> <ul> <li><code>temperature</code> (float, 0-1): Controls randomness in outputs</li> <li><code>max_tokens</code> (optional int): Maximum tokens in response</li> <li><code>seed</code> (optional int): For reproducible outputs</li> </ul>"},{"location":"pages/configuration/config-technical/cogt-config/#image-generation-imgg-configuration","title":"Image Generation (IMGG) Configuration","text":"<p>Configuration for image generation capabilities:</p> <pre><code>[pipelex.cogt.imgg_config]\ndefault_imgg_handle = \"stable_diffusion\"\nimgg_handles = [\"stable_diffusion\", \"dall_e\"]\n\n[pipelex.cogt.imgg_config.imgg_job_config]\nis_sync_mode = true\n\n# Default parameters for image generation\n[pipelex.cogt.imgg_config.imgg_param_defaults]\naspect_ratio = \"square\"  # Options: square, landscape_4_3, landscape_3_2, landscape_16_9, landscape_21_9,\n                         # portrait_4_3, portrait_2_3, portrait_9_16, portrait_9_21\nbackground = \"auto\"     # Options: transparent, opaque, auto\nquality = \"high\"        # Options: low, medium, high\nnb_steps = 50          # Number of diffusion steps\nguidance_scale = 7.5    # Controls adherence to prompt\nis_moderated = true    # Enable content moderation\nsafety_tolerance = 3    # Safety level (1-6)\nis_raw = false         # Raw output mode\noutput_format = \"png\"  # Options: png, jpg, webp\nseed = \"auto\"          # \"auto\" or specific integer\n</code></pre>"},{"location":"pages/configuration/config-technical/cogt-config/#imgg-job-parameters","title":"IMGG Job Parameters","text":"<p>Image generation jobs support these parameters:</p> <ul> <li> <p>Dimensions:</p> <ul> <li><code>aspect_ratio</code>: Predefined ratios for image dimensions</li> <li><code>background</code>: Background handling mode</li> </ul> </li> <li> <p>Quality Control:</p> <ul> <li><code>quality</code>: Output quality level</li> <li><code>nb_steps</code>: Number of generation steps</li> <li><code>guidance_scale</code>: How closely to follow the prompt</li> </ul> </li> <li> <p>Safety:</p> <ul> <li><code>is_moderated</code>: Enable content moderation</li> <li><code>safety_tolerance</code>: Safety check strictness (1-6)</li> </ul> </li> <li> <p>Output:</p> <ul> <li><code>is_raw</code>: Raw output mode</li> <li><code>output_format</code>: Image format (PNG/JPG/WEBP)</li> <li><code>seed</code>: For reproducible generation</li> </ul> </li> </ul>"},{"location":"pages/configuration/config-technical/cogt-config/#ocr-configuration","title":"OCR Configuration","text":"<p>Configuration for Optical Character Recognition:</p> <pre><code>[pipelex.cogt.ocr_config]\nocr_handles = [\"tesseract\", \"azure_ocr\"]\npage_output_text_file_name = \"page_text.txt\"\n</code></pre>"},{"location":"pages/configuration/config-technical/cogt-config/#validation-rules","title":"Validation Rules","text":""},{"location":"pages/configuration/config-technical/cogt-config/#llm-configuration_1","title":"LLM Configuration","text":"<ul> <li>Temperature must be between 0 and 1</li> <li>Max tokens must be positive</li> <li>Max retries must be between 1 and 10</li> <li>Seeds must be non-negative</li> </ul>"},{"location":"pages/configuration/config-technical/cogt-config/#imgg-configuration","title":"IMGG Configuration","text":"<ul> <li>Guidance scale must be positive</li> <li>Safety tolerance must be between 1 and 6</li> <li>Number of steps must be positive</li> <li>Strict validation for enums (aspect ratio, background, quality, output format)</li> </ul>"},{"location":"pages/configuration/config-technical/cogt-config/#best-practices","title":"Best Practices","text":"<ol> <li> <p>LLM Settings:</p> <ul> <li>Start with lower temperatures (0.1-0.3) for consistent outputs</li> <li>Use streaming for better user experience</li> <li>Set appropriate retry limits based on your use case</li> </ul> </li> <li> <p>IMGG Settings:</p> <ul> <li>Enable moderation for production use</li> <li>Use appropriate aspect ratios for your use case</li> <li>Balance quality and performance with step count</li> </ul> </li> <li> <p>General:</p> <ul> <li>Enable auto-setup for easier initialization</li> <li>Use platform preferences to ensure consistent model selection</li> <li>Configure OCR handles based on your accuracy needs</li> </ul> </li> </ol>"},{"location":"pages/configuration/config-technical/cogt-config/#example-complete-configuration","title":"Example Complete Configuration","text":"<pre><code>[pipelex.cogt]\n[pipelex.cogt.inference_manager_config]\nis_auto_setup_preset_llm = true\nis_auto_setup_preset_imgg = true\nis_auto_setup_preset_ocr = true\n\n[pipelex.cogt.llm_config]\ndefault_max_images = 4\npreferred_platforms = { \"gpt-4\" = \"openai\", \"claude-3-opus\" = \"anthropic\" }\n\n[pipelex.cogt.llm_config.llm_job_config]\nis_streaming_enabled = true\nmax_retries = 3\n\n[pipelex.cogt.llm_config.instructor_config]\nis_openai_structured_output_enabled = true\n\n[pipelex.cogt.imgg_config]\ndefault_imgg_handle = \"stable_diffusion\"\nimgg_handles = [\"stable_diffusion\", \"dall_e\"]\n\n[pipelex.cogt.imgg_config.imgg_job_config]\nis_sync_mode = true\n\n[pipelex.cogt.imgg_config.imgg_param_defaults]\naspect_ratio = \"square\"\nbackground = \"auto\"\nquality = \"high\"\nnb_steps = 50\nguidance_scale = 7.5\nis_moderated = true\nsafety_tolerance = 3\nis_raw = false\noutput_format = \"png\"\nseed = \"auto\"\n\n[pipelex.cogt.ocr_config]\nocr_handles = [\"tesseract\", \"azure_ocr\"]\npage_output_text_file_name = \"page_text.txt\"\n</code></pre>"},{"location":"pages/configuration/config-technical/library-config/","title":"Library Configuration","text":"<p>The Library Configuration manages how Pipelex organizes, loads, and handles libraries in your project. Libraries in Pipelex include pipelines, LLM integrations, LLM decks, and templates.</p>"},{"location":"pages/configuration/config-technical/library-config/#directory-structure","title":"Directory Structure","text":"<p>The library system uses two main root directories:</p> <ul> <li>Internal library root (<code>pipelex/libraries</code>): Contains the base libraries shipped with Pipelex</li> <li>Exported library root (<code>pipelex_libraries</code>): Contains your project's libraries, including copies of base libraries</li> </ul>"},{"location":"pages/configuration/config-technical/library-config/#standard-paths","title":"Standard Paths","text":"<pre><code>pipelex_libraries/         # Exported library root\n\u251c\u2500\u2500 pipelines/             # Pipeline definitions\n\u2502   \u251c\u2500\u2500 base_library/      # Base pipelines from Pipelex\n\u2502   \u2514\u2500\u2500 your_pipelines/    # Your custom pipelines\n\u251c\u2500\u2500 llm_integrations/      # LLM integration configurations\n\u251c\u2500\u2500 llm_deck/              # LLM model configurations\n\u2514\u2500\u2500 templates/             # Template files\n</code></pre>"},{"location":"pages/configuration/config-technical/library-config/#library-loading-process","title":"Library Loading Process","text":"<ol> <li> <p>Domain Loading:</p> <ul> <li>Loads domain definitions first</li> <li>Each domain must be defined exactly once</li> <li>Supports system prompts and structure templates</li> </ul> </li> <li> <p>Concept Loading:</p> <ul> <li>Loads native concepts first</li> <li>Loads custom concepts from TOML files</li> <li>Validates concept definitions and relationships</li> </ul> </li> <li> <p>Pipe Loading:</p> <ul> <li>Loads pipe definitions after concepts</li> <li>Validates pipe configurations</li> <li>Links pipes with their respective domains</li> </ul> </li> </ol>"},{"location":"pages/configuration/config-technical/library-config/#configuration-options","title":"Configuration Options","text":""},{"location":"pages/configuration/config-technical/library-config/#path-configuration","title":"Path Configuration","text":"<p>All paths are configurable through class variables in <code>LibraryConfig</code>:</p> <pre><code>package_name = \"pipelex\"\ninternal_library_root = \"libraries\"\nexported_library_root = \"pipelex_libraries\"\nexported_pipelines_path = \"pipelex_libraries/pipelines\"\nexported_llm_integrations_path = \"pipelex_libraries/llm_integrations\"\nexported_llm_deck_path = \"pipelex_libraries/llm_deck\"\nexported_templates_path = \"pipelex_libraries/templates\"\n</code></pre>"},{"location":"pages/configuration/config-technical/library-config/#library-initialization","title":"Library Initialization","text":"<p>Use the CLI command to initialize libraries: <pre><code>pipelex init-libraries\n</code></pre></p> <p>This will:</p> <ol> <li>Create the necessary directory structure</li> <li>Copy base libraries to your project</li> <li>Set up initial configuration files</li> </ol>"},{"location":"pages/configuration/config-technical/library-config/#library-export-options","title":"Library Export Options","text":"<p>When exporting libraries to your project:</p> <ul> <li>Use <code>overwrite=True</code> to force update existing files</li> <li>Preserve custom overrides in <code>llm_deck/overrides.toml</code></li> <li>Maintain directory structure and initialization files</li> </ul>"},{"location":"pages/configuration/config-technical/library-config/#validation","title":"Validation","text":"<p>The library manager performs several validation steps:</p> <ol> <li> <p>LLM Deck Validation:</p> <ul> <li>Ensures LLM configurations are complete</li> <li>Validates model settings</li> </ul> </li> <li> <p>Concept Library Validation:</p> <ul> <li>Checks concept relationships</li> <li>Validates concept definitions</li> </ul> </li> <li> <p>Pipe Library Validation:</p> <ul> <li>Verifies pipe configurations</li> <li>Checks domain relationships</li> </ul> </li> <li> <p>Domain Library Validation:</p> <ul> <li>Ensures domain completeness</li> <li>Validates domain relationships</li> </ul> </li> </ol>"},{"location":"pages/configuration/config-technical/library-config/#error-handling","title":"Error Handling","text":"<p>The library system includes specific error types:</p> <ul> <li><code>LibraryError</code>: Base error for library issues</li> <li><code>LibraryParsingError</code>: For TOML parsing issues</li> <li><code>ConceptLibraryError</code>: For concept-related issues</li> <li><code>PipeLibraryError</code>: For pipe-related issues</li> <li><code>LLMDeckNotFoundError</code>: For missing LLM configurations</li> </ul>"},{"location":"pages/configuration/config-technical/library-config/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Organization:</p> <ul> <li>Keep related concepts and pipes in the same TOML file</li> <li>Use meaningful domain names</li> <li>Structure complex libraries using subdirectories</li> </ul> </li> <li> <p>Validation:</p> <ul> <li>Run <code>pipelex validate</code> after making changes</li> <li>Check for domain consistency</li> <li>Verify concept relationships</li> </ul> </li> <li> <p>Customization:</p> <ul> <li>Use <code>overrides.toml</code> for local LLM settings</li> <li>Keep custom pipelines separate from base library</li> <li>Document domain-specific configurations</li> </ul> </li> </ol>"},{"location":"pages/cookbook-examples/","title":"Pipelex Cookbook Examples","text":"<p>Welcome to the Pipelex Cookbook!</p> <p></p> <p>This is your go-to resource for practical examples and ready-to-use recipes to build powerful and reliable AI workflows with Pipelex. Whether you're a beginner looking to get started or an experienced user searching for advanced patterns, you'll find something useful here.</p>"},{"location":"pages/cookbook-examples/#philosophy","title":"Philosophy","text":"<p>Our examples are designed to be:</p> <ul> <li>Practical: Solving real-world problems.</li> <li>Readable: Easy to understand and adapt.</li> <li>A Starting Point: A foundation for your own custom pipelines.</li> </ul> <p>We strongly encourage you to clone our Pipelex Cookbook repository, play with the examples, and tailor them to your specific needs.</p>"},{"location":"pages/cookbook-examples/#contribute-to-the-community","title":"Contribute to the Community!","text":"<p>Have you built a cool pipeline with Pipelex? Share it with the community! We welcome contributions. Check out our contribution guidelines and help us grow this collection of examples.</p>"},{"location":"pages/cookbook-examples/#available-examples","title":"Available Examples","text":"<p>Here are some of the examples you can find in the cookbook, organized by category:</p>"},{"location":"pages/cookbook-examples/#getting-started","title":"Getting Started","text":"<ul> <li>Hello World: A simple start to your Pipelex journey.</li> </ul>"},{"location":"pages/cookbook-examples/#document-processing","title":"Document Processing","text":"<ul> <li>Simple OCR: A basic OCR pipeline to extract text from a PDF.</li> <li>Generic Document Extraction: A powerful pipeline to extract text and images from complex documents.</li> <li>Invoice Extractor: A complete workflow for processing invoices, including reporting.</li> <li>Proof of Purchase Extraction: A targeted pipeline for extracting data from receipts.</li> </ul>"},{"location":"pages/cookbook-examples/#graphical-extraction","title":"Graphical Extraction","text":"<ul> <li>Gantt Chart Extraction: Extract tasks, dates, and dependencies from a Gantt chart image.</li> <li>Table Extraction from Image: Convert a table from an image into structured HTML.</li> <li>DPE Extraction: A specialized pipeline for extracting information from French energy performance certificates.</li> </ul>"},{"location":"pages/cookbook-examples/#text-generation","title":"Text Generation","text":"<ul> <li>Screenplay Generator (wip): A creative pipeline that generates a screenplay from a simple pitch.</li> <li>Tweet Optimizer (wip): A style-transfer pipeline that optimizes a draft tweet based on a given writing style.</li> </ul> <p>Dive in and happy piping! \ud83d\ude80 </p>"},{"location":"pages/cookbook-examples/extract-dpe/","title":"Example: DPE Extraction","text":"<p>This example demonstrates how to extract information from a French \"Diagnostic de Performance \u00c9nerg\u00e9tique\" (DPE) document. This is a specialized document, and the pipeline is tailored to its specific structure.</p>"},{"location":"pages/cookbook-examples/extract-dpe/#get-the-code","title":"Get the code","text":"<p>\u27a1\ufe0f View on GitHub: examples/extract_dpe.py</p>"},{"location":"pages/cookbook-examples/extract-dpe/#the-pipeline-explained","title":"The Pipeline Explained","text":"<p>The pipeline <code>power_extractor_dpe</code> is designed to recognize and extract the key information from a DPE document. The result is a structured <code>Dpe</code> object.</p> <pre><code>async def extract_dpe(pdf_url: str) -&gt; Dpe:\n    working_memory = WorkingMemoryFactory.make_from_pdf(\n        pdf_url=pdf_url,\n        concept_str=\"PDF\",\n        name=\"pdf\",\n    )\n    pipe_output = await execute_pipeline(\n        pipe_code=\"power_extractor_dpe\",\n        working_memory=working_memory,\n    )\n    working_memory = pipe_output.working_memory\n    dpe: Dpe = working_memory.get_list_stuff_first_item_as(name=\"dpe\", item_type=Dpe)\n    return dpe\n</code></pre> <p>This example shows how Pipelex can be used for very specific document extraction tasks by creating custom pipelines and data models.</p>"},{"location":"pages/cookbook-examples/extract-dpe/#the-data-structure-dpe-model","title":"The Data Structure: <code>Dpe</code> Model","text":"<p>The pipeline extracts a <code>Dpe</code> object, which is structured to hold the specific information found in a French \"Diagnostic de Performance \u00c9nerg\u00e9tique\". It even uses a custom <code>IndexScale</code> enum for the energy efficiency classes.</p> <pre><code>class IndexScale(StrEnum):\n    A = \"A\"\n    B = \"B\"\n    C = \"C\"\n    D = \"D\"\n    E = \"E\"\n    F = \"F\"\n    G = \"G\"\n\n\nclass Dpe(StructuredContent):\n    address: Optional[str] = None\n    date_of_issue: Optional[datetime] = None\n    date_of_expiration: Optional[datetime] = None\n    energy_efficiency_class: Optional[IndexScale] = None\n    per_year_per_m2_consumption: Optional[float] = None\n    co2_emission_class: Optional[IndexScale] = None\n    per_year_per_m2_co2_emissions: Optional[float] = None\n    yearly_energy_costs: Optional[float] = None\n</code></pre>"},{"location":"pages/cookbook-examples/extract-dpe/#the-pipeline-definition-extract_dpetoml","title":"The Pipeline Definition: <code>extract_dpe.toml</code>","text":"<p>The pipeline uses a <code>PipeLLM</code> with a very specific prompt to extract the information from the document. The combination of the image and the OCR text allows the LLM to accurately capture all the details.</p> <p><pre><code>[pipe.write_markdown_from_page_content_dpe]\nPipeLLM = \"Write markdown from page content of a 'Diagnostic de Performance Energetique'\"\ninputs = { page_content = \"Page\" }\noutput = \"Dpe\" # The output is structured as a Dpe object\nllm = \"llm_for_img_to_text\"\nstructuring_method = \"preliminary_text\"\nsystem_prompt = \"\"\"You are a multimodal LLM, expert in converting images into perfect markdown.\"\"\"\nprompt_template = \"\"\"\nYou are given an image of a French 'Diagnostic de Performance Energetique'.\nYour role is to convert the image into perfect markdown.\n\nTo help you do so, you are given the text extracted from the page by an OCR model.\n@page_content.text_and_images.text.text\n\n- It is very important that you collect every element, especially if they are related to the energy performance of the building.\n- We value letters like \"A, B, C, D, E, F, G\" as they are energy performance classes.\n# ... (prompt continues)\n\"\"\"\n</code></pre> This is a great example of how to create a highly specialized extraction pipeline by combining a custom data model with a detailed, guiding prompt. </p>"},{"location":"pages/cookbook-examples/extract-gantt/","title":"Example: Gantt Chart Extraction","text":"<p>This example showcases the ability of Pipelex to extract structured information from images. In this case, it processes an image of a Gantt chart and extracts the tasks, dates, and dependencies.</p>"},{"location":"pages/cookbook-examples/extract-gantt/#get-the-code","title":"Get the code","text":"<p>\u27a1\ufe0f View on GitHub: examples/extract_gantt.py</p>"},{"location":"pages/cookbook-examples/extract-gantt/#the-pipeline-explained","title":"The Pipeline Explained","text":"<p>The pipeline takes an image as input, creates a working memory, and then executes the <code>extract_gantt_by_steps</code> pipeline to produce a structured <code>GanttChart</code> object.</p> <pre><code>async def extract_gantt(image_url: str) -&gt; GanttChart:\n    # Create Working Memory\n    working_memory = WorkingMemoryFactory.make_from_image(\n        image_url=image_url,\n        concept_str=\"gantt.GanttImage\",\n        name=\"gantt_chart_image\",\n    )\n\n    # Run the pipe\n    pipe_output = await execute_pipeline(\n        pipe_code=\"extract_gantt_by_steps\",\n        working_memory=working_memory,\n    )\n\n    # Output the result\n    return pipe_output.main_stuff_as(content_type=GanttChart)\n</code></pre> <p>This is a powerful demonstration of multi-modal capabilities, combining vision and language understanding.</p>"},{"location":"pages/cookbook-examples/extract-gantt/#the-data-structure-ganttchart-model","title":"The Data Structure: <code>GanttChart</code> Model","text":"<p>The final output is a <code>GanttChart</code> object, which contains lists of tasks and milestones. These are themselves structured objects, ensuring the data is clean and easy to work with.</p> <pre><code>class GanttTaskDetails(StructuredContent):\n    \"\"\"Do not include timezone in the dates.\"\"\"\n    name: str\n    start_date: Optional[datetime] = None\n    end_date: Optional[datetime] = None\n    # ...\n\nclass Milestone(StructuredContent):\n    name: str\n    date: Optional[datetime]\n    # ...\n\nclass GanttChart(StructuredContent):\n    tasks: Optional[List[GanttTaskDetails]]\n    milestones: Optional[List[Milestone]]\n</code></pre>"},{"location":"pages/cookbook-examples/extract-gantt/#the-pipeline-definition-gantttoml","title":"The Pipeline Definition: <code>gantt.toml</code>","text":"<p>The <code>extract_gantt_by_steps</code> pipeline is a sequence of smaller, focused pipes. This is a great example of building a complex workflow from simple, reusable components.</p> <p><pre><code>[pipe.extract_gantt_by_steps]\nPipeSequence = \"Extract all details from a gantt chart\"\ninputs = { gantt_chart_image = \"GanttChartImage\" }\noutput = \"GanttChart\"\nsteps = [\n    # First, figure out the timescale of the chart\n    { pipe = \"extract_gantt_timescale\", result = \"gantt_timescale\" },\n    # Then, get the names of all the tasks\n    { pipe = \"extract_gantt_task_names\", result = \"gantt_task_names\" },\n    # Then, for each task, extract the details\n    { pipe = \"extract_details_of_task\", batch_as = \"gantt_task_name\", result = \"details_of_all_tasks\" },\n    # Finally, assemble everything into a single GanttChart object\n    { pipe = \"gather_in_a_gantt_chart\", result = \"gantt_chart\" },\n]\n\n# This is the pipe that extracts the details for a single task\n[pipe.extract_details_of_task]\nPipeLLM = \"Extract the precise dates of the task, start_date and end_date\"\ninputs = { gantt_chart_image = \"GanttChartImage\", gantt_timescale = \"GanttTimescaleDescription\", gantt_task_name = \"GanttTaskName\" }\noutput = \"GanttTaskDetails\" # The output is structured as a GanttTaskDetails object\nstructuring_method = \"preliminary_text\"\nllm = \"llm_to_extract_diagram\"\nprompt_template = \"\"\"\nI am sharing an image of a Gantt chart.\nPlease analyse the image and for a given task name (and only this task), extract the information of the task, if relevant.\n\nBe careful, the time unit is this:\n@gantt_timescale\n\nIf the task is a milestone, then only output the start_date.\n\nHere is the name of the task you have to extract the dates for:\n@gantt_task_name\n\"\"\"\n</code></pre> This demonstrates the \"divide and conquer\" approach that Pipelex encourages. By breaking down a complex problem into smaller steps, each step can be handled by a specialized pipe, making the overall workflow more robust and easier to debug. </p>"},{"location":"pages/cookbook-examples/extract-gantt/#flowchart","title":"Flowchart","text":"<pre><code>---\nconfig:\n  layout: dagre\n  theme: base\n---\nflowchart LR\n    subgraph \"extract_gantt_by_steps\"\n    direction LR\n        ZJNLe[\"gantt_chart_image:&lt;br&gt;**Gantt image**\"]\n        Bh9Ab[\"gantt_timescale:&lt;br&gt;**Gantt timescale description**\"]\n        R2oLH[\"gantt_task_names:&lt;br&gt;**List of [Gantt task name]**\"]\n    end\n    subgraph \"extract_details_of_task\"\n    direction LR\n        R2oLH-branch-0[\"**Gantt task name** #1\"]\n        QFEdmVvYVHdL6DsCRtwqHq-branch-0[\"**Gantt task details** #1\"]\n        R2oLH-branch-1[\"**Gantt task name** #2\"]\n        QFEdmVvYVHdL6DsCRtwqHq-branch-1[\"**Gantt task details** #2\"]\n        R2oLH-branch-2[\"**Gantt task name** #3\"]\n        QFEdmVvYVHdL6DsCRtwqHq-branch-2[\"**Gantt task details** #3\"]\n        R2oLH-branch-3[\"**Gantt task name** #4\"]\n        QFEdmVvYVHdL6DsCRtwqHq-branch-3[\"**Gantt task details** #4\"]\n        R2oLH-branch-4[\"**Gantt task name** #5\"]\n        QFEdmVvYVHdL6DsCRtwqHq-branch-4[\"**Gantt task details** #5\"]\n        R2oLH-branch-5[\"**Gantt task name** #6\"]\n        QFEdmVvYVHdL6DsCRtwqHq-branch-5[\"**Gantt task details** #6\"]\n        R2oLH-branch-6[\"**Gantt task name** #7\"]\n        QFEdmVvYVHdL6DsCRtwqHq-branch-6[\"**Gantt task details** #7\"]\n        R2oLH-branch-7[\"**Gantt task name** #8\"]\n        QFEdmVvYVHdL6DsCRtwqHq-branch-7[\"**Gantt task details** #8\"]\n        R2oLH-branch-8[\"**Gantt task name** #9\"]\n        QFEdmVvYVHdL6DsCRtwqHq-branch-8[\"**Gantt task details** #9\"]\n        R2oLH-branch-9[\"**Gantt task name** #10\"]\n        QFEdmVvYVHdL6DsCRtwqHq-branch-9[\"**Gantt task details** #10\"]\n        R2oLH-branch-10[\"**Gantt task name** #11\"]\n        QFEdmVvYVHdL6DsCRtwqHq-branch-10[\"**Gantt task details** #11\"]\n        R2oLH-branch-11[\"**Gantt task name** #12\"]\n        QFEdmVvYVHdL6DsCRtwqHq-branch-11[\"**Gantt task details** #12\"]\n        nCmpx[\"details_of_all_tasks:&lt;br&gt;**List of [Gantt task details]**\"]\n        NuMVc[\"gantt_chart:&lt;br&gt;**Gantt chart**\"]\n    end\nclass extract_gantt_by_steps sub_a;\nclass extract_details_of_task sub_b;\n\n    classDef sub_a fill:#e6f5ff,color:#333,stroke:#333;\n\n    classDef sub_b fill:#fff5f7,color:#333,stroke:#333;\n\n    classDef sub_c fill:#f0fff0,color:#333,stroke:#333;\n    ZJNLe -- \"Extract gantt timescale\" ----&gt; Bh9Ab\n    ZJNLe -- \"Extract gantt task names\" ----&gt; R2oLH\n    ZJNLe -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-0\n    ZJNLe -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-1\n    ZJNLe -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-2\n    ZJNLe -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-3\n    ZJNLe -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-4\n    ZJNLe -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-5\n    ZJNLe -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-6\n    ZJNLe -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-7\n    ZJNLe -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-8\n    ZJNLe -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-9\n    ZJNLe -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-10\n    ZJNLe -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-11\n    Bh9Ab -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-0\n    Bh9Ab -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-1\n    Bh9Ab -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-2\n    Bh9Ab -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-3\n    Bh9Ab -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-4\n    Bh9Ab -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-5\n    Bh9Ab -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-6\n    Bh9Ab -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-7\n    Bh9Ab -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-8\n    Bh9Ab -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-9\n    Bh9Ab -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-10\n    Bh9Ab -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-11\n    R2oLH -...- R2oLH-branch-0\n    R2oLH -...- R2oLH-branch-1\n    R2oLH -...- R2oLH-branch-2\n    R2oLH -...- R2oLH-branch-3\n    R2oLH -...- R2oLH-branch-4\n    R2oLH -...- R2oLH-branch-5\n    R2oLH -...- R2oLH-branch-6\n    R2oLH -...- R2oLH-branch-7\n    R2oLH -...- R2oLH-branch-8\n    R2oLH -...- R2oLH-branch-9\n    R2oLH -...- R2oLH-branch-10\n    R2oLH -...- R2oLH-branch-11\n    R2oLH-branch-0 -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-0\n    QFEdmVvYVHdL6DsCRtwqHq-branch-0 -...- nCmpx\n    R2oLH-branch-1 -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-1\n    QFEdmVvYVHdL6DsCRtwqHq-branch-1 -...- nCmpx\n    R2oLH-branch-2 -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-2\n    QFEdmVvYVHdL6DsCRtwqHq-branch-2 -...- nCmpx\n    R2oLH-branch-3 -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-3\n    QFEdmVvYVHdL6DsCRtwqHq-branch-3 -...- nCmpx\n    R2oLH-branch-4 -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-4\n    QFEdmVvYVHdL6DsCRtwqHq-branch-4 -...- nCmpx\n    R2oLH-branch-5 -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-5\n    QFEdmVvYVHdL6DsCRtwqHq-branch-5 -...- nCmpx\n    R2oLH-branch-6 -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-6\n    QFEdmVvYVHdL6DsCRtwqHq-branch-6 -...- nCmpx\n    R2oLH-branch-7 -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-7\n    QFEdmVvYVHdL6DsCRtwqHq-branch-7 -...- nCmpx\n    R2oLH-branch-8 -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-8\n    QFEdmVvYVHdL6DsCRtwqHq-branch-8 -...- nCmpx\n    R2oLH-branch-9 -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-9\n    QFEdmVvYVHdL6DsCRtwqHq-branch-9 -...- nCmpx\n    R2oLH-branch-10 -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-10\n    QFEdmVvYVHdL6DsCRtwqHq-branch-10 -...- nCmpx\n    R2oLH-branch-11 -- \"Extract details of task\" ----&gt; QFEdmVvYVHdL6DsCRtwqHq-branch-11\n    QFEdmVvYVHdL6DsCRtwqHq-branch-11 -...- nCmpx\n    nCmpx -- \"Gather in a gantt chart\" ----&gt; NuMVc</code></pre>"},{"location":"pages/cookbook-examples/extract-generic/","title":"Example: Generic Document Extraction","text":"<p>This example demonstrates a powerful and generic pipeline for extracting content from complex PDF documents. It can handle documents that contain both text and images, and it merges the extracted content into a single, coherent output.</p>"},{"location":"pages/cookbook-examples/extract-generic/#get-the-code","title":"Get the code","text":"<p>\u27a1\ufe0f View on GitHub: examples/extract_generic.py</p>"},{"location":"pages/cookbook-examples/extract-generic/#the-pipeline-explained","title":"The Pipeline Explained","text":"<p>The <code>power_extractor</code> pipeline is at the heart of this example. After its execution, a custom function <code>merge_markdown_and_images</code> is used to combine the text (converted to Markdown) and the images from all pages.</p> <pre><code>async def extract_generic(pdf_url: str) -&gt; TextAndImagesContent:\n    working_memory = WorkingMemoryFactory.make_from_pdf(\n        pdf_url=pdf_url,\n        concept_str=\"PDF\",\n        name=\"pdf\",\n    )\n    pipe_output = await execute_pipeline(\n        pipe_code=\"power_extractor\",\n        working_memory=working_memory,\n    )\n    working_memory = pipe_output.working_memory\n    markdown_and_images: TextAndImagesContent = merge_markdown_and_images(working_memory)\n    return markdown_and_images\n</code></pre> <p>The <code>merge_markdown_and_images</code> function is a great example of how you can add your own Python code to a Pipelex workflow to perform custom processing.</p> <pre><code>def merge_markdown_and_images(working_memory: WorkingMemory) -&gt; TextAndImagesContent:\n    # Pages extracted from the PDF by PipeOCR\n    page_contents_list = working_memory.get_stuff_as_list(item_type=PageContent, name=\"page_contents\")\n    # Markdown text extracted from the Pages by PipeLLM\n    page_markdown_list = working_memory.get_stuff_as_list(item_type=TextContent, name=\"markdowns\")\n\n    # ... (check for length equality)\n\n    # Concatenate the markdown text\n    concatenated_markdown_text: str = \"\\\\n\".join([page_markdown.text for page_markdown in page_markdown_list.items])\n\n    # Aggregate the images from the page contents\n    image_contents: List[ImageContent] = []\n    for page_content in page_contents_list.items:\n        if page_content.text_and_images.images:\n            image_contents.extend(page_content.text_and_images.images)\n\n    return TextAndImagesContent(\n        text=TextContent(text=concatenated_markdown_text),\n        images=image_contents,\n    )\n</code></pre> <p>This example shows the flexibility of Pipelex in handling complex, multi-modal documents and allowing for custom logic. </p>"},{"location":"pages/cookbook-examples/extract-proof-of-purchase/","title":"Example: Proof of Purchase Extraction","text":"<p>This example demonstrates a pipeline designed to extract structured data from a proof of purchase, such as a receipt or an invoice.</p>"},{"location":"pages/cookbook-examples/extract-proof-of-purchase/#get-the-code","title":"Get the code","text":"<p>\u27a1\ufe0f View on GitHub: examples/extract_proof_of_purchase.py</p>"},{"location":"pages/cookbook-examples/extract-proof-of-purchase/#the-pipeline-explained","title":"The Pipeline Explained","text":"<p>The pipeline <code>power_extractor_proof_of_purchase</code> is specifically designed to handle receipts and invoices. It extracts key information and returns a structured <code>ProofOfPurchase</code> object.</p> <pre><code>async def extract_proof_of_purchase(pdf_url: str) -&gt; ProofOfPurchase:\n    working_memory = WorkingMemoryFactory.make_from_pdf(\n        pdf_url=pdf_url,\n        concept_str=\"PDF\",\n        name=\"pdf\",\n    )\n    pipe_output = await execute_pipeline(\n        pipe_code=\"power_extractor_proof_of_purchase\",\n        working_memory=working_memory,\n    )\n    working_memory = pipe_output.working_memory\n    proof_of_purchase: ProofOfPurchase = working_memory.get_list_stuff_first_item_as(name=\"proof_of_purchase\", item_type=ProofOfPurchase)\n    return proof_of_purchase\n</code></pre> <p>This is a great starting point for building more complex expense processing or accounting automation pipelines.</p>"},{"location":"pages/cookbook-examples/extract-proof-of-purchase/#the-data-structure-proofofpurchase-model","title":"The Data Structure: <code>ProofOfPurchase</code> Model","text":"<p>The pipeline is designed to extract a <code>ProofOfPurchase</code> object, which is a structured model that includes a list of <code>Products</code>.</p> <p><pre><code>class Products(StructuredContent):\n    name: Optional[str] = None\n    quantity: Optional[int] = None\n    unit_price: Optional[float] = None\n    total_price: Optional[float] = None\n\n\nclass ProofOfPurchase(StructuredContent):\n    date_of_purchase: Optional[datetime] = None\n    amount_paid: Optional[float] = None\n    currency: Optional[str] = None\n    payment_method: Optional[str] = None\n    purchase_number: Optional[str] = None\n    products: Optional[List[Products]] = None\n</code></pre> This demonstrates how you can create nested data structures to accurately model your data.</p>"},{"location":"pages/cookbook-examples/extract-proof-of-purchase/#the-pipeline-definition-extract_proof_of_purchasetoml","title":"The Pipeline Definition: <code>extract_proof_of_purchase.toml</code>","text":"<p>The pipeline uses a powerful <code>PipeLLM</code> to extract the structured data from the document. The prompt is carefully engineered to guide the LLM.</p> <p><pre><code>[pipe.write_markdown_from_page_content_proof_of_purchase]\nPipeLLM = \"Write markdown from page content\"\ninputs = { \"page_content.page_view\" = \"Page\" } # The LLM receives the image of the page\noutput = \"ProofOfPurchase\" # The LLM is forced to output a ProofOfPurchase object\nllm = \"llm_for_img_to_text\"\nstructuring_method = \"preliminary_text\"\nsystem_prompt = \"\"\"You are a multimodal LLM, expert at converting images into perfect markdown.\"\"\"\nprompt_template = \"\"\"\nYou are given an image of a proof of purchase.\nYour role is to convert the image into perfect markdown.\n\nTo help you do so, you are given the text extracted from the page by an OCR model.\n@page_content.text_and_images.text.text\n\n- Ensure you collect every title, number, and currency from the proof of purchase.\n- Pay attention to the text alignment, it might have been misaligned by the OCR.\n- The OCR extraction may be highly incomplete. It is your job to complete the text and add the missing information using the image.\n- Output only the markdown, nothing else. No need for \"```markdown\" or \"```\".\n- You can use HTML if it helps you.\n- You can use tables if it is relevant.\n\"\"\"\n</code></pre> The combination of a detailed prompt, the OCR text, and the document image allows the LLM to accurately extract the required information and structure it as a <code>ProofOfPurchase</code> object. </p>"},{"location":"pages/cookbook-examples/extract-table/","title":"Example: Table Extraction from Image","text":"<p>This example shows how to extract a table from an image and convert it into a structured HTML format. This is a common requirement when dealing with scanned documents or reports where data is presented in tabular form.</p>"},{"location":"pages/cookbook-examples/extract-table/#get-the-code","title":"Get the code","text":"<p>\u27a1\ufe0f View on GitHub: examples/extract_table.py</p>"},{"location":"pages/cookbook-examples/extract-table/#the-pipeline-explained","title":"The Pipeline Explained","text":"<p>The pipeline <code>extract_html_table_and_review</code> takes an image of a table, processes it, and returns an <code>HtmlTable</code> object.</p> <pre><code>async def extract_table(table_screenshot: str) -&gt; HtmlTable:\n    working_memory = WorkingMemoryFactory.make_from_image(\n        image_url=table_screenshot,\n        concept_str=\"tables.TableScreenshot\",\n        name=\"table_screenshot\",\n    )\n    pipe_output = await execute_pipeline(\n        pipe_code=\"extract_html_table_and_review\",\n        working_memory=working_memory,\n    )\n    html_table = pipe_output.main_stuff_as(content_type=HtmlTable)\n    return html_table\n</code></pre> <p>This is another example of Pipelex's multi-modal capabilities, turning visual information into structured data.</p>"},{"location":"pages/cookbook-examples/extract-table/#the-data-structure-htmltable-model","title":"The Data Structure: <code>HtmlTable</code> Model","text":"<p>The pipeline outputs an <code>HtmlTable</code> object. This is a great example of a \"smart\" data model. It uses a <code>pydantic.model_validator</code> to parse the generated HTML with BeautifulSoup and validate its structure, ensuring the LLM has produced valid and well-formed HTML.</p> <pre><code>class HtmlTable(StructuredContent):\n    title: str\n    inner_html_table: str\n    allowed_tags: ClassVar[set[str]] = { \"br\", \"table\", \"thead\", \"tbody\", \"tr\", \"th\", \"td\" }\n\n    @model_validator(mode=\"after\")\n    def validate_html_table(self) -&gt; Self:\n        soup = BeautifulSoup(self.inner_html_table, \"html.parser\")\n        # Check if there's exactly one table element\n        tables = soup.find_all(\"table\")\n        if len(tables) != 1:\n            raise ValueError(f\"HTML must contain exactly one table element...\")\n\n        # Validate that only allowed table-related tags are present\n        all_tags = {tag.name for tag in soup.find_all()}\n        invalid_tags = all_tags - self.allowed_tags\n        if invalid_tags:\n            raise ValueError(f\"Invalid HTML tags found: {invalid_tags}\")\n\n        # ... more validation\n        return self\n</code></pre>"},{"location":"pages/cookbook-examples/extract-table/#the-pipeline-definition-tabletoml","title":"The Pipeline Definition: <code>table.toml</code>","text":"<p>The pipeline uses a two-step \"extract and review\" pattern. The first pipe does the initial extraction, and the second pipe reviews the generated HTML against the original image to correct any errors. This is a powerful pattern for increasing the reliability of LLM outputs.</p> <p><pre><code>[pipe.extract_html_table_and_review]\nPipeSequence = \"Get an HTML table and review it\"\ninputs = { table_screenshot = \"TableScreenshot\" }\noutput = \"HtmlTable\"\nsteps = [\n    # First, do an initial extraction of the table from the image\n    { pipe = \"extract_html_table_from_image\", result = \"html_table\" },\n    # Then, ask an LLM to review the extracted table against the image and correct it\n    { pipe = \"review_html_table\", result = \"reviewed_html_table\" },\n]\n\n[pipe.review_html_table]\nPipeLLM = \"Review an HTML table\"\ninputs = { table_screenshot = \"TableScreenshot\", html_table = \"HtmlTable\" }\noutput = \"HtmlTable\"\nprompt_template = \"\"\"\nYour role is to correct an html_table to make sure that it matches the one in the provided image.\n\n@html_table\n\nPay attention to the text and formatting (color, borders, ...).\nRewrite the entire html table with your potential corrections.\nMake sure you do not forget any text.\n\"\"\"\n</code></pre> This self-correction pattern is a key technique for building robust and reliable AI workflows with Pipelex. </p>"},{"location":"pages/cookbook-examples/hello-world/","title":"Example: Hello World","text":"<p>This is the \"Hello World\" of Pipelex, a simple pipeline that demonstrates the basic concepts of Pipelex.</p> <p>It's the perfect starting point to verify your installation and get a first taste of how Pipelex works.</p>"},{"location":"pages/cookbook-examples/hello-world/#get-the-code","title":"Get the code","text":"<p>You can find the complete code for this example in the Pipelex Cookbook repository.</p> <p>\u27a1\ufe0f View on GitHub: quick_start/hello_world.py</p>"},{"location":"pages/cookbook-examples/hello-world/#the-pipeline-explained","title":"The Pipeline Explained","text":"<p>The <code>hello_world</code> function demonstrates the simplest possible Pipelex pipeline. It runs a single pipe that generates a haiku about \"Hello World\".</p> <pre><code>import asyncio\n\nfrom pipelex import pretty_print\nfrom pipelex.pipelex import Pipelex\nfrom pipelex.pipeline.execute import execute_pipeline\n\n\nasync def hello_world():\n\n    # Execute the pipeline\n    pipe_output = await execute_pipeline(\n        pipe_code=\"hello_world\",\n    )\n\n    # Print the output\n    pretty_print(pipe_output, title=\"Your first Pipelex output\")\n\n\n# start Pipelex\nPipelex.make()\n# run sample using asyncio\nasyncio.run(hello_world())\n</code></pre> <p>This example shows the minimal setup needed to run a Pipelex pipeline: initialize Pipelex, execute a pipeline by its code name, and pretty-print the results.</p>"},{"location":"pages/cookbook-examples/hello-world/#the-pipeline-definition-hello_worldtoml","title":"The Pipeline Definition: <code>hello_world.toml</code>","text":"<p>The pipeline definition is extremely simple - it's a single LLM call that generates a haiku:</p> <pre><code>domain = \"quick_start\"\ndefinition = \"Discovering Pipelex\"\n\n[pipe]\n[pipe.hello_world]\nPipeLLM = \"Write text about Hello World.\"\noutput = \"Text\"\nllm = { llm_handle = \"gpt-4o-mini\", temperature = 0.9, max_tokens = \"auto\" }\nprompt = \"\"\"\nWrite a haiku about Hello World.\n\"\"\"\n</code></pre>"},{"location":"pages/cookbook-examples/hello-world/#how-to-run","title":"How to run","text":"<ol> <li>Clone the cookbook repository:     <pre><code>git clone https://github.com/Pipelex/pipelex-cookbook.git\ncd pipelex-cookbook\n</code></pre></li> <li>Install dependencies:     <pre><code>make install\n</code></pre></li> <li>Set up your environment variables by copying <code>.env.example</code> to <code>.env</code> and adding your API keys.</li> <li>Run the example:     <pre><code>python quick_start/hello_world.py\n</code></pre></li> </ol> <p>Expected output: A haiku about \"Hello World\" displayed with pretty formatting.</p>"},{"location":"pages/cookbook-examples/invoice-extractor/","title":"Example: Invoice Extractor","text":"<p>This example provides a comprehensive pipeline for processing invoices. It takes a PDF invoice, extracts key information, and returns a structured <code>Invoice</code> object. It also demonstrates how to generate reports and track pipeline execution.</p>"},{"location":"pages/cookbook-examples/invoice-extractor/#get-the-code","title":"Get the code","text":"<p>\u27a1\ufe0f View on GitHub: examples/invoice_extractor.py</p>"},{"location":"pages/cookbook-examples/invoice-extractor/#the-pipeline-explained","title":"The Pipeline Explained","text":"<p>The <code>process_invoice</code> pipeline is a complete workflow for invoice processing.</p> <pre><code>async def process_expense_report() -&gt; ListContent[Invoice]:\n    invoice_pdf_path = \"assets/invoice_extractor/invoice_1.pdf\"\n\n    # Create Stuff objects\n    working_memory = WorkingMemoryFactory.make_from_pdf(\n        pdf_url=invoice_pdf_path,\n        name=\"invoice_pdf\",\n    )\n    pipe_output = await execute_pipeline(\n        pipe_code=\"process_invoice\",\n        working_memory=working_memory,\n    )\n\n    return pipe_output.main_stuff_as_list(item_type=Invoice)\n</code></pre> <p>This example also showcases some of the powerful observability features of Pipelex. After the pipeline runs, it generates a cost report and a flowchart of the execution.</p> <p><pre><code># Print the cost reporting\nget_report_delegate().generate_report()\n\n# Print the flowchart url of the pipeline.\nget_pipeline_tracker().output_flowchart()\n</code></pre> This is invaluable for understanding the cost and the execution flow of your pipelines.</p>"},{"location":"pages/cookbook-examples/invoice-extractor/#the-data-structure-invoice-model","title":"The Data Structure: <code>Invoice</code> Model","text":"<p>The pipeline's output is a structured <code>Invoice</code> object. This is defined using Pydantic's <code>BaseModel</code>, which allows for clear, typed, and validated data.</p> <pre><code>class Invoice(StructuredContent):\n    \"\"\"Invoice information extracted from text, supporting both formal bills and receipts\"\"\"\n\n    invoice_id: Optional[str] = Field(None, description=\"Unique identifier for the invoice\")\n    invoice_number: Optional[str] = Field(None, description=\"Invoice number as shown on the document\")\n    date: Optional[datetime] = Field(None, description=\"Date when the invoice was issued\")\n\n    amount_incl_tax: Optional[float] = Field(None, description=\"Total amount including taxes\")\n\n    vendor: Optional[str] = Field(None, description=\"Name of the vendor/seller\")\n\n    # ... other fields\n</code></pre>"},{"location":"pages/cookbook-examples/invoice-extractor/#the-pipeline-definition-invoicetoml","title":"The Pipeline Definition: <code>invoice.toml</code>","text":"<p>The entire workflow is defined in a TOML file. This declarative approach makes the pipeline easy to understand and modify. Here's a snippet from <code>invoice.toml</code>:</p> <p><pre><code># The main pipeline, a sequence of steps\n[pipe.process_invoice]\nPipeSequence = \"Process relevant information from an invoice\"\ninputs = { invoice_pdf = \"PDF\" }\noutput = \"Invoice\"\nsteps = [\n    # First, run OCR on the PDF\n    { pipe = \"extract_text_from_image\", result = \"invoice_pages\" },\n    # Then, run the invoice extraction on each page\n    { pipe = \"extract_invoice\", batch_over = \"invoice_pages\", batch_as = \"invoice_page\", result = \"invoice\" },\n]\n\n# A sub-pipeline that uses an LLM to extract the data\n[pipe.extract_invoice_data]\nPipeLLM = \"Extract invoice information from an invoice text transcript\"\ninputs = { \"invoice_page.page_view\" = \"Page\", invoice_details = \"InvoiceDetails\" }\noutput = \"Invoice\"\n# The output is constrained to the \"Invoice\" model\nllm = \"llm_to_extract_invoice\" \nprompt_template = \"\"\"\nExtract invoice information from this invoice:\n\nThe category of this invoice is: $invoice_details.category.\n\n@invoice_page.text_and_images.text.text\n\"\"\"\n</code></pre> This shows how a complex workflow, including OCR and LLM calls, can be defined in a simple, readable format. The <code>llm = \"llm_to_extract_invoice\"</code> line is particularly powerful, as it tells the LLM to structure its output according to the <code>Invoice</code> model. </p>"},{"location":"pages/cookbook-examples/invoice-extractor/#the-pipeline-flowchart","title":"The Pipeline Flowchart","text":"<pre><code>---\nconfig:\n  layout: dagre\n  theme: base\n---\nflowchart LR\n    subgraph \"extract_invoice\"\n    direction LR\n        ZynbH-branch-0[\"invoice_page:&lt;br&gt;**Page**\"]\n        RRYZF[\"invoice_details:&lt;br&gt;**Invoice details**\"]\n        RzjEzwGpkk5dXnrK3HXQJx-branch-0[\"invoice:&lt;br&gt;**Invoice**\"]\n        ZynbH[\"invoice_pages:&lt;br&gt;**List of [Page]**\"]\n        5SXqJ[\"invoice:&lt;br&gt;**List of [Invoice]**\"]\n    end\nclass extract_invoice sub_a;\n\n    classDef sub_a fill:#e6f5ff,color:#333,stroke:#333;\n\n    classDef sub_b fill:#fff5f7,color:#333,stroke:#333;\n\n    classDef sub_c fill:#f0fff0,color:#333,stroke:#333;\n    ZynbH-branch-0 -- \"Analyze invoice\" ----&gt; RRYZF\n    ZynbH-branch-0 -- \"Extract invoice data\" ----&gt; RzjEzwGpkk5dXnrK3HXQJx-branch-0\n    RRYZF -- \"Extract invoice data\" ----&gt; RzjEzwGpkk5dXnrK3HXQJx-branch-0\n    RzjEzwGpkk5dXnrK3HXQJx-branch-0 -...- 5SXqJ\n    ZynbH -...- ZynbH-branch-0</code></pre>"},{"location":"pages/cookbook-examples/simple-ocr/","title":"Example: Simple OCR","text":"<p>This example demonstrates a basic OCR (Optical Character Recognition) pipeline. It takes a PDF file as input, extracts the text from each page, and saves the content.</p> <p>This is a fundamental building block for many document processing workflows.</p>"},{"location":"pages/cookbook-examples/simple-ocr/#get-the-code","title":"Get the code","text":"<p>\u27a1\ufe0f View on GitHub: examples/simple_ocr.py</p>"},{"location":"pages/cookbook-examples/simple-ocr/#the-pipeline-explained","title":"The Pipeline Explained","text":"<p>The core of this example is a simple function that creates a \"working memory\" from a PDF and then executes a pre-defined pipeline called <code>extract_page_contents_from_pdf</code>.</p> <pre><code>async def simple_ocr(pdf_url: str):\n    working_memory = WorkingMemoryFactory.make_from_pdf(\n        pdf_url=pdf_url,\n        concept_str=\"PDF\",\n        name=\"pdf\",\n    )\n    pipe_output = await execute_pipeline(\n        pipe_code=\"extract_page_contents_from_pdf\",\n        working_memory=working_memory,\n    )\n    page_content_list: ListContent[PageContent] = pipe_output.main_stuff_as_list(item_type=PageContent)\n    return page_content_list\n</code></pre> <p>This showcases how easy it is to kick off a complex process with just a few lines of code. </p>"},{"location":"pages/cookbook-examples/write-screenplay/","title":"Example: Screenplay Generator","text":"<p>This example demonstrates how to use Pipelex for creative text generation. It takes a simple pitch and generates a full screenplay.</p>"},{"location":"pages/cookbook-examples/write-screenplay/#get-the-code","title":"Get the code","text":"<p>\u27a1\ufe0f View on GitHub: examples/wip/write_screenplay.py</p>"},{"location":"pages/cookbook-examples/write-screenplay/#the-pipeline-explained","title":"The Pipeline Explained","text":"<p>The <code>generate_screenplay</code> function takes a pitch as a string, creates a <code>Stuff</code> object with the <code>screenplay.Pitch</code> concept, and then runs the <code>generate_screenplay</code> pipeline.</p> <pre><code>async def generate_screenplay(pitch: str):\n    \"\"\"Generate a screenplay from a pitch using the pipeline.\"\"\"\n\n    # Create Stuff object for the pitch\n    pitch_stuff = StuffFactory.make_from_str(\n        str_value=pitch,\n        concept_str=\"screenplay.Pitch\",\n        name=\"pitch\",\n    )\n\n    # Create Working Memory\n    working_memory = WorkingMemoryFactory.make_from_single_stuff(pitch_stuff)\n\n    # Run the pipe\n    pipe_output = await execute_pipeline(\n        pipe_code=\"generate_screenplay\",\n        working_memory=working_memory,\n    )\n    pretty_print(pipe_output, title=\"Pipe Output\")\n</code></pre> <p>This example shows how a simple text input can be used to kick off a complex, creative workflow.</p>"},{"location":"pages/cookbook-examples/write-screenplay/#the-data-structures-screenplay-models","title":"The Data Structures: <code>Screenplay</code> Models","text":"<p>This pipeline uses a rich set of Pydantic models to represent the different components of a screenplay, from the initial <code>Pitch</code> to the final <code>FormattedScreenplay</code>. This ensures that each step of the pipeline has clear, structured inputs and outputs.</p> <pre><code>class DetailedPitch(StructuredContent):\n    \"\"\"A detailed pitch with character ideas and synopsis.\"\"\"\n    original_pitch: str\n    expanded_pitch: str\n    character_ideas: List[str]\n    synopsis: str\n\nclass Character(StructuredContent):\n    \"\"\"A character in the screenplay.\"\"\"\n    name: str\n    age: int\n    description: str\n    # ...\n\nclass Scene(StructuredContent):\n    \"\"\"A scene in the screenplay.\"\"\"\n    index: int\n    title: str\n    location: str\n    script: str\n    # ...\n\nclass Chapter(StructuredContent):\n    \"\"\"A chapter in the screenplay.\"\"\"\n    title: str\n    description: str\n    scenes: List[Scene]\n\nclass Screenplay(StructuredContent):\n    \"\"\"A complete screenplay with characters and scenes.\"\"\"\n    title: str\n    pitch: DetailedPitch\n    characters: \"CharacterList\"\n    chapters: \"ChapterList\"\n</code></pre>"},{"location":"pages/cookbook-examples/write-screenplay/#the-pipeline-definition-screenplay_writertoml","title":"The Pipeline Definition: <code>screenplay_writer.toml</code>","text":"<p>The <code>generate_screenplay</code> pipeline is a master <code>PipeSequence</code> that orchestrates a series of smaller, specialized pipes. This is a perfect example of how to build a complex, creative workflow by breaking it down into manageable steps.</p> <pre><code>[pipe.generate_screenplay]\nPipeSequence = \"Generate a complete screenplay from a pitch\"\ninputs = { pitch = \"Pitch\" }\noutput = \"FormattedScreenplay\"\nsteps = [\n    # 1. Analyze the initial pitch to expand it.\n    { pipe = \"analyze_pitch\", result = \"detailed_pitch\" },\n    # 2. Create detailed character profiles.\n    { pipe = \"create_characters\", result = \"characters\" },\n    # 3. Break the story down into chapters.\n    { pipe = \"create_chapters\", result = \"chapters\" },\n    # 4. For each chapter, create the scenes. This is a nested sequence!\n    { pipe = \"create_scenes_sequence\", batch_over = \"chapters\", batch_as = \"chapter\", result = \"chapters_with_scenes\" },\n    # 5. Format the entire screenplay.\n    { pipe = \"create_formatted_screenplay\", result = \"formatted_screenplay\" }\n]\n\n# This is the nested sequence that creates all the scenes for a single chapter.\n[pipe.create_scenes_sequence]\nPipeSequence = \"Create all scenes for a chapter sequentially\"\ninputs = { chapter = \"Chapter\", characters = \"CharacterList\", detailed_pitch = \"DetailedPitch\" }\noutput = \"Chapter\"\nsteps = [\n    # First, create the initial scene outlines for the chapter.\n    { pipe = \"create_initial_scenes\", result = \"initial_scenes\" },\n    # Then, for each scene outline, develop the full scene content.\n    { pipe = \"create_scene_sequence\", batch_over = \"initial_scenes\", batch_as = \"scene\", result = \"developed_scenes\" }\n]\n</code></pre> <p>This modular, step-by-step process, guided by the structured data models, allows Pipelex to generate a complete, well-structured screenplay from a single, simple pitch. It's a powerful demonstration of building complex, creative AI agents.</p>"},{"location":"pages/cookbook-examples/write-tweet/","title":"Example: Tweet Optimizer","text":"<p>This example demonstrates how to create a pipeline that takes a draft of a tweet and a desired writing style, and then generates an optimized tweet. This is a practical example of \"style transfer\" for text.</p>"},{"location":"pages/cookbook-examples/write-tweet/#get-the-code","title":"Get the code","text":"<p>\u27a1\ufe0f View on GitHub: examples/wip/write_tweet.py</p>"},{"location":"pages/cookbook-examples/write-tweet/#the-pipeline-explained","title":"The Pipeline Explained","text":"<p>The <code>optimize_tweet</code> function is the core of this example. It takes two strings, <code>draft_tweet_str</code> and <code>writing_style_str</code>, creates two <code>Stuff</code> objects with the concepts <code>tech_tweet.DraftTweet</code> and <code>tech_tweet.WritingStyle</code>, and then runs the <code>optimize_tweet_sequence</code> pipeline.</p> <pre><code>async def optimize_tweet(draft_tweet_str: str, writing_style_str: str) -&gt; OptimizedTweet:\n    # Create the draft tweet stuff\n    draft_tweet = StuffFactory.make_stuff(\n        concept_str=\"tech_tweet.DraftTweet\",\n        content=TextContent(text=draft_tweet_str),\n        name=\"draft_tweet\",\n    )\n    writing_style = StuffFactory.make_stuff(\n        concept_str=\"tech_tweet.WritingStyle\",\n        content=TextContent(text=writing_style_str),\n        name=\"writing_style\",\n    )\n\n    # Create working memory\n    working_memory = WorkingMemoryFactory.make_from_multiple_stuffs(\n        [\n            draft_tweet,\n            writing_style,\n        ]\n    )\n\n    # Run the sequence pipe\n    pipe_output = await execute_pipeline(\n        pipe_code=\"optimize_tweet_sequence\",\n        working_memory=working_memory,\n    )\n\n    # Get the optimized tweet\n    optimized_tweet = pipe_output.main_stuff_as(content_type=OptimizedTweet)\n    return optimized_tweet\n</code></pre> <p>This example shows how to use multiple inputs to guide the generation process and produce text that adheres to a specific style.</p>"},{"location":"pages/cookbook-examples/write-tweet/#the-data-structure-optimizedtweet-model","title":"The Data Structure: <code>OptimizedTweet</code> Model","text":"<p>The data model for this pipeline is very simple, as the final output is just a piece of text. However, the pipeline uses several concepts internally to manage the workflow, such as <code>DraftTweet</code>, <code>TweetAnalysis</code>, and <code>WritingStyle</code>.</p> <pre><code>class OptimizedTweet(TextContent):\n    \"\"\"A tweet optimized for Twitter/X engagement following best practices.\"\"\"\n    pass\n</code></pre>"},{"location":"pages/cookbook-examples/write-tweet/#the-pipeline-definition-tech_tweettoml","title":"The Pipeline Definition: <code>tech_tweet.toml</code>","text":"<p>This pipeline uses a two-step \"analyze and optimize\" sequence. The first pipe analyzes the draft tweet for common pitfalls, and the second pipe rewrites the tweet based on the analysis and a provided writing style. This is a powerful pattern for refining generated content.</p> <p><pre><code>[pipe.optimize_tweet_sequence]\nPipeSequence = \"Analyze and optimize a tech tweet in sequence\"\ninputs = { draft_tweet = \"DraftTweet\", writing_style = \"WritingStyle\" }\noutput = \"OptimizedTweet\"\nsteps = [\n    # First, analyze the draft tweet for issues like \"fluffiness\" and \"vagueness\".\n    { pipe = \"analyze_tweet\", result = \"tweet_analysis\" },\n    # Then, optimize the tweet based on the analysis and the desired writing style.\n    { pipe = \"optimize_tweet\", result = \"optimized_tweet\" },\n]\n\n# This is the pipe that analyzes the draft tweet.\n[pipe.analyze_tweet]\nPipeLLM = \"Analyze the draft tweet and identify areas for improvement\"\ninputs = { draft_tweet = \"DraftTweet\" }\noutput = \"TweetAnalysis\"\nsystem_prompt = \"\"\"\nYou are an expert in social media optimization, particularly for tech content on Twitter/X.\nYour role is to analyze tech tweets and check if they display typical startup communication pitfalls.\n\"\"\"\nprompt_template = \"\"\"\nEvaluate the tweet for these key issues:\n\n**Fluffiness** - Overuse of buzzwords without concrete meaning...\n**Cringiness** - Content that induces secondhand embarrassment...\n**Humblebragginess** - Disguising boasts as casual updates...\n**Vagueness** - Failing to clearly communicate what the product/service actually does...\n\n@draft_tweet\n\"\"\"\n</code></pre> This \"analyze and refine\" pattern is a great way to build more reliable and sophisticated text generation workflows. The first step provides a structured critique, and the second step uses that critique to improve the final output.</p> <p>Here is the flowchart generated during this run:</p> <pre><code>---\nconfig:\n  layout: dagre\n  theme: base\n---\nflowchart LR\n    subgraph \"optimize_tweet_sequence\"\n    direction LR\n        FGunn[\"draft_tweet:&lt;br&gt;**Draft tweet**\"]\n        EWhtJ[\"tweet_analysis:&lt;br&gt;**Tweet analysis**\"]\n        65Eb2[\"optimized_tweet:&lt;br&gt;**Optimized tweet**\"]\n        i34D5[\"writing_style:&lt;br&gt;**Writing style**\"]\n    end\nclass optimize_tweet_sequence sub_a;\n\n    classDef sub_a fill:#e6f5ff,color:#333,stroke:#333;\n\n    classDef sub_b fill:#fff5f7,color:#333,stroke:#333;\n\n    classDef sub_c fill:#f0fff0,color:#333,stroke:#333;\n    FGunn -- \"Analyze tweet\" ----&gt; EWhtJ\n    FGunn -- \"Optimize tweet\" ----&gt; 65Eb2\n    EWhtJ -- \"Optimize tweet\" ----&gt; 65Eb2\n    i34D5 -- \"Optimize tweet\" ----&gt; 65Eb2</code></pre>"},{"location":"pages/installation/","title":"Installation","text":""},{"location":"pages/installation/#prerequisites","title":"Prerequisites","text":"<p>Pipelex requires <code>python</code> version <code>3.10</code> or above, and access to an LLM, via an API key or a custom endpoint.</p>"},{"location":"pages/installation/#getting-started","title":"Getting Started","text":"<p>Along with our Quick Start Guide, we recommend you check out our Cookbook for practical examples.</p> <ul> <li>Create a virtual environment (recommended)</li> </ul> <pre><code>python3 -m venv .venv &amp;&amp; source .venv/bin/activate\n</code></pre> <ul> <li>Install Pipelex</li> </ul> <p>Pipelex can be installed from PyPI. We encourage the use of uv for faster installs and dependency management:</p> <pre><code>uv pip install pipelex\n</code></pre> <p>Otherwise use pip: <pre><code>pip install pipelex\n</code></pre></p> <ul> <li>Make sure you have a .env file at the root of your project that contains the following fields</li> </ul> <pre><code>OPENAI_API_KEY=sk_...\n</code></pre> <p>All the secret keys used by <code>pipelex</code> are specified in the <code>.env.example</code> file. However, by default, only the <code>OPENAI_API_KEY</code> is required.</p> <ul> <li>Make sure you run the init commands:</li> </ul> <p>In order to set the pipelex configuration files, you need to run 2 commands using the CLI (we recommend to run it at the root of your project):</p> <ul> <li><code>pipelex init-libraries</code>: This will create a <code>pipelex_libraries</code> folder, with the base llm configuration and the base pipelines.  This is the directory where you should add your pipelines. </li> </ul> <p>The structure is like this:</p> <pre><code>\u251c\u2500\u2500 pipelex_libraries           \n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 pipelines/                          # The pipelines and the structured output are stored here\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2514\u2500\u2500 base_library/                   # The base library with basic pipelines\n\u2502   \u251c\u2500\u2500 templates/                          # Those are template prompt libraries\n\u2502   \u251c\u2500\u2500 llm_deck/                           # A llm deck is a simple way to name a llm and its configuration.\n\u2502   \u2514\u2500\u2500 llm_integrations/                   # This directory regroups the configuration of the different models\n</code></pre> <p>Learn more about pipelex_libraries in our Libraries documentation</p> <ul> <li><code>pipelex init-config</code>: This cli command will create a <code>pipelex.toml</code> file at the root of the project, with basic configuration. This configuration file gathers all configuration for feature flags, logging, cost reporting, and so on... Learn more in our Configuration documentation</li> </ul> <p>\ud83d\udca1 Any troubles? Have a look at our Cookbook! and come ask for help on our Discord</p>"},{"location":"pages/pipelex-paradigm-for-repeatable-ai-workflows/","title":"The Pipelex Paradigm","text":"<p>Pipelex is an open-source Python framework for defining and running repeatable AI workflows.</p> <p>Here's what we've learned: LLMs are powerful, but asking them to do everything in one prompt is like asking a brilliant colleague to solve ten problems while juggling. The more complexity you pack into a single prompt, the more reliability drops. You've seen it: the perfect prompt that works 90% of the time until it doesn't.</p> <p>The solution is straightforward: break complex tasks into focused steps. But without proper tooling, you end up with spaghetti code and prompts scattered across your codebase.</p> <p>Pipelex introduces knowledge pipelines: a way to capture these workflow steps as composable pipes. Each pipe follows one rule: knowledge in, knowledge out. Unlike rigid templates, each pipe uses AI's full intelligence to handle variation while guaranteeing consistent output structure. You get deterministic structure with adaptive intelligence, the reliability of software with the flexibility of AI.</p>"},{"location":"pages/pipelex-paradigm-for-repeatable-ai-workflows/#working-with-knowledge-and-using-concepts-to-make-sense","title":"Working with Knowledge and Using Concepts to Make Sense","text":"<p>Knowledge refers to information you input from various data sources such as documents, PDFs, images, or information output by our pipes. There are different kinds of knowledge.</p>"},{"location":"pages/pipelex-paradigm-for-repeatable-ai-workflows/#from-data-types-to-concepts","title":"From Data Types to Concepts","text":"<p>In traditional programming, we work with data types: strings, integers, booleans (true/false), etc. But knowledge work operates at a higher level. Take for instance a \"non-compete clause from a contract\" and a \"description of a flower\": they're both text, both are stored as strings, but they represent fundamentally different concepts. You can ask an AI to extract the duration in months from a non-compete clause. You can ask an AI to render a flower description as a Monet-style painting. But if you try the reverse, it doesn't make sense.</p> <p>This is why Pipelex introduces Concepts: typing with meaning attached.</p> <p>Thanks to Pipelex's conceptual level of abstraction, knowledge pipelines can guarantee they make sense.</p>"},{"location":"pages/pipelex-paradigm-for-repeatable-ai-workflows/#how-making-sense-translates-to-reliability","title":"How Making Sense Translates to Reliability","text":"<p>Concretely, in Pipelex, a piece of knowledge is an object in the working memory. It could be anything, so we call that \"stuff\", and our Python class for it is <code>Stuff</code>.</p> <p>Stuff can be pretty basic, like plain text or an image, but it can also be structured with attributes, comprise lists, include other nested stuff, you get it... the stuff's content is actually a <code>Pydantic BaseModel</code>. Also, each Stuff knows what concept it belongs to, e.g., <code>Text</code> or <code>NonCompeteClause</code> or <code>FlowerDescription</code>.</p> <p>And with that we are fully equipped for Lego-style plug-n-play:</p> <ul> <li>Each pipe declares what inputs it uses, indicating the expected concept(s)</li> <li>Each pipe also declares what it outputs</li> </ul> <p>So when you connect two pipes, Pipelex systematically checks that they are compatible. Actually, it's even more powerful than that: imagine you have a sequence of 5 pipes, maybe pipe #4 takes two inputs, one given from the output of previous pipe #3 and the other one from the output of pipe #1. Pipelex checks that running the previous steps will have generated the required stuff and with the required concepts.</p> <p>What if you have a pipe that requires a <code>Text</code> input, to translate it to Spanish for instance, then it should also accept a <code>FlowerDescription</code>, right? Yes, the greater includes the lesser. This is expressed in Pipelex by indicating that concept <code>FlowerDescription</code> refines concept <code>Text</code>.</p> <p>One problem that developers face when working with LLMs is that LLMs always try to answer your queries, and it pushes them to hallucinate. For instance, if you're trying to extract structured purchase details from an invoice, and there's a bug in your system so instead of receiving an invoice as input, the LLM received a picture of a flower, or nothing at all, there's a good chance it will generate a 100% hallucinated mock invoice. Pipelex prevents this kind of bugs, first by making sure the pipeline makes sense a priori, but it can also check any input for compatibility with the expected concept.</p> <p>By letting you clearly assign concepts to the input and output stuff of your pipes, Pipelex makes sure that your pipeline makes sense, that it works in theory, and detects any failure of meaning at the earliest stage possible in practice.</p>"},{"location":"pages/pipelex-paradigm-for-repeatable-ai-workflows/#who-defines-the-concepts","title":"Who Defines the Concepts?","text":"<p>You define your concepts!</p> <p>Apart from a few very basic concepts (<code>Text</code>, <code>Image</code>, etc.), you can and you should define the concepts you work with. And that's a big win: the concepts you define make up the glossary of the domain you are working on. That's where you remove any ambiguity, because the same word can mean different things, and even the same concept can imply different things in various settings.</p>"},{"location":"pages/quick-start/","title":"Quick-start","text":"<p>This guide shows the basics of Pipelex for the simplest use-cases: LLM calling and structured outputs.</p> <p>You can find more powerful examples in the Cookbook Examples section of the docs or dive directly into the Cookbook repository. </p>"},{"location":"pages/quick-start/#your-first-llm-call-with-pipelex","title":"Your first LLM call with Pipelex","text":"<p>Let's start by running your very first LLM call using Pipelex. For illustration purposes, let's build a character generator. Each example relies on asynchronous execution and typed models for reliable prompts.</p>"},{"location":"pages/quick-start/#write-your-first-pipeline","title":"Write your first pipeline","text":"<p>First, create a <code>.toml</code> library file in the <code>pipelex_libraries/pipelines</code> directory to store your pipe definition. Run <code>pipelex init-libraries</code> to create this directory if it doesn't exist. For now, keep all your pipeline definitions inside that folder only.</p> <p><code>character.toml</code> <pre><code>domain = \"characters\"\n\n[pipe]\n[pipe.create_character]\nPipeLLM = \"Creates a character.\"\noutput = \"Text\"\nprompt_template = \"\"\"You are a book writer. Your task is to create a character.\nThink of it and then output the character description.\"\"\"\n</code></pre></p>"},{"location":"pages/quick-start/#run-your-first-pipelex-script","title":"Run your first Pipelex script","text":"<p>Now, create a <code>.py</code> python file to run your script. You can save it anywhere in your repository.</p> <p><code>character.py</code> <pre><code>import asyncio\nfrom pipelex.pipeline.execute import execute_pipeline\nfrom pipelex.pipelex import Pipelex\n\nasync def create_character():\n    # Run the script with execute_pipe\n    pipe_output = await execute_pipeline(\n        pipe_code=\"create_character\",\n    )\n    # Print the output\n    print(pipe_output.main_stuff_as_str)\n\n# Initialize pipelex to load your pipeline libraries\nPipelex.make()\n\n# Run using asyncio because our APIs are all async \nasyncio.run(create_character())\n</code></pre></p>"},{"location":"pages/quick-start/#get-your-first-pipelex-result","title":"Get your first Pipelex result","text":"<pre><code>python character.py\n</code></pre>"},{"location":"pages/quick-start/#how-to-use-a-specific-llm-or-llm-provider","title":"How to use a specific LLM or LLM provider","text":""},{"location":"pages/quick-start/#indicate-your-llm-selection-explicitly-using-the-llm-attribute","title":"Indicate your LLM selection explicitly using the <code>llm</code> attribute","text":"<pre><code>[pipe.create_character]\nPipeLLM = \"Create a character.\"\noutput = \"Text\"\nllm = { llm_handle = \"gpt-4o-mini\", temperature = 0.9, max_tokens = \"auto\" }\nprompt_template = \"\"\"You are a book writer. Your task is to create a character.\nThink of it and then output the character description.\"\"\"\n</code></pre>"},{"location":"pages/quick-start/#or-use-an-llm-preset-from-the-llm-deck","title":"Or use an LLM preset from the LLM deck","text":"<pre><code>[pipe.create_character]\nPipeLLM = \"Create a character.\"\noutput = \"Text\"\nllm = \"llm_for_creative_writing\"\nprompt_template = \"\"\"You are a book writer. Your task is to create a character.\nThink of it and then output the character description.\"\"\"\n\n# The llm deck above is defined in `pipelex_libraries/llm_deck/base_llm_deck.toml` as:\n# llm_for_creative_writing = { llm_handle = \"best-claude\", temperature = 0.9 }\n# it's a base preset that we provide. you can add your own presets, too.\n</code></pre> <p>\ud83d\udca1 We have a lot of LLM presets available by default. Make sure you have credentials for the underlying LLM provider (and added your API key to the <code>.env</code>) and select the one you want!</p> <p>Learn more about LLM presets, LLM handles and LLM deck in our LLM Configuration Guide</p>"},{"location":"pages/quick-start/#generate-a-structured-output","title":"Generate a structured output","text":"<p>Let's say that we no longer want plain text as output but a rigorously structured Character object.</p>"},{"location":"pages/quick-start/#define-the-model","title":"Define the model","text":"<p>Using the Pydantic BaseModel syntax, define your object structure as a Python class, in the <code>pipelex_libraries/pipelines</code> directory:</p> <p><code>pipelex_libraries/pipelines/characters.py</code> <pre><code>from pipelex.core.stuff_content import StructuredContent\n\n# Define the structure of your output here\n# This class must inherit from StructuredContent\nclass Character(StructuredContent):\n    name: str\n    age: int\n    gender: str\n    description: str\n</code></pre></p> <p>\u2139\ufe0f We'll soon make it possible to define your structure directly in the <code>.toml</code> file, without having to write any python code</p>"},{"location":"pages/quick-start/#improve-the-pipeline","title":"Improve the pipeline","text":"<p>It's time to specify that your output be a <code>Character</code> instance. Use the <code>output</code> field for that purpose.</p> <p>\ud83d\udca1 Here, the concept name matches the class name (ie. <code>Character</code>), the <code>Character</code> class will automatically be considered as the structure to output.</p> <p><code>pipelex_libraries/pipelines/characters.toml</code> <pre><code>domain = \"characters\"\n\n[concept]\nCharacter = \"A character is a fiction story\" # &lt;- Define here your output concept so that it is linked to the class name\n\n[pipe]\n[pipe.create_character]\nPipeLLM = \"Create a character. Get a structured result.\"\noutput = \"Character\"    # &lt;- This is the output concept for your pipe\nprompt_template = \"\"\"You are a book writer. Your task is to create a character.\nThink of it and then output the character description.\"\"\"\n</code></pre></p> <p>\ud83d\udca1 Defining the <code>Character</code> concept as \"A character is a fiction story\" might seem obvious but\u2026 think of it: \"character\" can also mean a letter or symbol in a text. Defining concepts is the best way to avoid any ambiguity and make sure the LLMs understand what you mean.</p>"},{"location":"pages/quick-start/#run-your-pipeline","title":"Run your pipeline","text":"<p>As you can see, the output is a <code>Character</code> instance.</p> <p></p>"},{"location":"pages/quick-start/#generate-using-information-in-a-prompt-template","title":"Generate using information in a prompt template","text":"<p>What if you want to pass some data into a prompt? You can do that using a prompt template.</p> <p>In this example, we no longer want to generate characters. We want to process existing ones, especially their description attributes.</p> <p>We want to extract structured information from the description field. Thus we have a <code>Character</code> input and a <code>CharacterMetadata</code> output.</p>"},{"location":"pages/quick-start/#define-the-output-structure","title":"Define the output structure","text":"<pre><code># pipelex_libraries/pipelines/character_model.py\nfrom pipelex.core.stuff_content import StructuredContent\n\n# input class\nclass Character(StructuredContent):\n    name: str\n    age: int\n    gender: str\n    occupation: str\n    description: str\n\n# output class\nclass CharacterMetadata(StructuredContent):\n    name: str\n    age: int\n    height: float\n</code></pre>"},{"location":"pages/quick-start/#lets-use-a-template-to-fill-prompts-with-data","title":"Let's use a template to fill prompts with data","text":"<p>\ud83d\udca1 Our template syntax is based on Jinja2 syntax. You can include a variable using the classic <code>{{ double.curly.braces }}</code>, and to make it simpler, we've added the possibility to just prefix your variable with the <code>@</code> symbol (recommended). Pipes declare their required inputs explicitly with the <code>inputs</code> table:</p> <pre><code>[concept]\nCharacter = \"A character from a book\"\nCharacterMetadata = \"Metadata regarding a character.\"\n\n[pipe]\n[pipe.extract_character_1]\nPipeLLM = \"Get character information from a description.\"\ninputs = { character = \"Character\" }  # &lt;- These are the inputs of your pipe, usable in the prompt_template\noutput = \"CharacterMetadata\"\nprompt_template = \"\"\"\nYou are given a text description of a character.\nYour task is to extract specific data from the following description.\n\n@character.description\n\"\"\"\n</code></pre> <p>\ud83d\udca1 <code>@character.description</code> is substituted by grabbing the stuff named <code>character</code>in the working memory and using its <code>description</code>attribute</p> <p>Learn more about how we use Jinja in the PipeLLM documentation.</p>"},{"location":"pages/quick-start/#this-is-how-you-do-it-from-the-code-side","title":"This is how you do it from the code side","text":"<pre><code>import asyncio\n\nfrom pipelex.core.stuff_factory import StuffFactory\nfrom pipelex.core.working_memory_factory import WorkingMemoryFactory\nfrom pipelex.pipelex import Pipelex\nfrom pipelex.pipeline.execute import execute_pipeline\n\nfrom pipelex_libraries.pipelines.screenplay import Character, CharacterMetadata\n\n\nasync def process_existing_character():\n    # Your existing data\n    character = Character(\n        name=\"Elias\",\n        age=38,\n        gender=\"man\",\n        occupation=\"explorer\",\n        description=\"\"\"Elias Varrin is a 38-year-old man, standing at approximately 1.85 meters tall, with a lean,\n        weathered frame shaped by decades of travel through remote and often unforgiving landscapes.\n        His name, though not widely known, carries weight among historians, explorers, and those who trade in whispered legends.\n        Elias has piercing storm-gray eyes that scan every environment with sharp precision, and his ash-blond hair\u2014flecked with\n        early streaks of grey\u2014is usually tucked beneath a wide-brimmed, timeworn hat.His hands are etched with fine scars and stained\n        with ink, each mark a silent record of years spent charting unrecorded lands and handling fragile relics of lost civilizations.\n        He moves with quiet purpose and speaks with a calm, thoughtful cadence that suggests he's always listening for more than just what's said.\"\"\",\n    )\n    # Wrap it into a stuff object\n    character_stuff = StuffFactory.make_stuff(\n        concept_code=\"character.Character\", # &lt;- `character` is the domain, `Character` is the concept name\n        name=\"character\",\n        content=character,\n    )\n    # Add it to the working memory\n    working_memory = WorkingMemoryFactory.make_from_single_stuff(\n        stuff=character_stuff,\n    )\n    # Run the pipe identified by its pipe_code (it's the name of the pipe)\n    pipe_output, pipeline_run_id = await execute_pipeline(\n        pipe_code=\"extract_character_1\",\n        working_memory=working_memory,\n    )\n\n    # Get the result as a porperly typed instance\n    extracted_metadata = pipe_output.main_stuff_as(content_type=CharacterMetadata) # &lt;- This is the output of your pipe, properly typed\n\n    print(extracted_metadata)\n\n\nPipelex.make()\nasyncio.run(process_existing_character())\n</code></pre>"},{"location":"pages/quick-start/#get-result","title":"Get result","text":""},{"location":"pages/tools/cli/","title":"Pipelex CLI Documentation","text":"<p>The Pipelex CLI provides a command-line interface for managing and interacting with your Pipelex projects. This document outlines all available commands and their usage.</p>"},{"location":"pages/tools/cli/#available-commands","title":"Available Commands","text":""},{"location":"pages/tools/cli/#pipelex-init-libraries","title":"<code>pipelex init-libraries</code>","text":"<p>Initialize Pipelex libraries in the current directory.</p> <pre><code>pipelex init-libraries [--overwrite/-o]\n</code></pre> <p>Options: - <code>--overwrite</code>, <code>-o</code>: If set, existing library files will be overwritten. Otherwise, only missing files will be created.</p>"},{"location":"pages/tools/cli/#pipelex-init-config","title":"<code>pipelex init-config</code>","text":"<p>Initialize Pipelex configuration in the current directory.</p> <pre><code>pipelex init-config [--reset/-r]\n</code></pre> <p>Options: - <code>--reset</code>, <code>-r</code>: If set, existing configuration file (pipelex.toml) will be overwritten. Otherwise, the command will warn if the file already exists.</p>"},{"location":"pages/tools/cli/#pipelex-validate","title":"<code>pipelex validate</code>","text":"<p>Run the setup sequence to validate your Pipelex configuration and pipelines.</p> <pre><code>pipelex validate\n</code></pre> <p>This command:</p> <ol> <li>Exports libraries</li> <li>Validates the configuration</li> <li>Ensures all pipelines are properly set up</li> </ol>"},{"location":"pages/tools/cli/#pipelex-show-config","title":"<code>pipelex show-config</code>","text":"<p>Display the current Pipelex configuration.</p> <pre><code>pipelex show-config\n</code></pre> <p>Shows the complete configuration for your project, including all settings and parameters. See more in our Configuration documentation</p>"},{"location":"pages/tools/cli/#pipelex-list-pipes","title":"<code>pipelex list-pipes</code>","text":"<p>List all available pipes in your project.</p> <pre><code>pipelex list-pipes\n</code></pre> <p>Displays a table of pipes organized by domain, showing:</p> <ul> <li>Code: The unique identifier for each pipe</li> <li>Definition: Description of the pipe's purpose</li> <li>Input: Required input parameters and their concept codes</li> <li>Output: The output concept code</li> </ul> <p>The output is formatted as tables grouped by domain, with concept codes simplified when they belong to the current domain.</p>"},{"location":"pages/tools/cli/#usage-tips","title":"Usage Tips","text":"<ol> <li>Always run <code>pipelex validate</code> after making changes to your configuration or pipelines</li> <li>Use <code>pipelex show-config</code> to debug configuration issues</li> <li> <p>When initializing a new project:</p> </li> <li> <p>Start with <code>pipelex init-config</code></p> </li> <li>Then run <code>pipelex init-libraries</code></li> <li>Finally, validate your setup with <code>pipelex validate</code></li> </ol>"},{"location":"pages/tools/logging/","title":"Pipelex Logging System","text":""},{"location":"pages/tools/logging/#overview","title":"Overview","text":"<p>Pipelex provides a sophisticated logging system that extends Python's standard logging with additional features like emoji support, rich formatting, and custom log levels.</p>"},{"location":"pages/tools/logging/#log-levels","title":"Log Levels","text":"<p>In addition to standard Python log levels, Pipelex introduces custom levels:</p> Level Value Description VERBOSE 5 Most detailed logging, below DEBUG DEBUG 10 Standard debug information DEV 15 Development-specific logging (between DEBUG and INFO) INFO 20 General informational messages WARNING 30 Warning messages ERROR 40 Error messages CRITICAL 50 Critical errors OFF 999 Disable logging"},{"location":"pages/tools/logging/#logging-features","title":"Logging Features","text":""},{"location":"pages/tools/logging/#1-rich-formatting","title":"1. Rich Formatting","text":"<ul> <li>Beautiful console output with color coding</li> <li>Syntax highlighting for JSON and other data structures</li> <li>Support for clickable file paths</li> <li>Word wrapping for better readability</li> </ul>"},{"location":"pages/tools/logging/#2-emoji-support","title":"2. Emoji Support","text":"<p>Built-in emoji indicators for different components:</p> <ul> <li>\ud83e\udde0 Pipelex core messages</li> <li>\u26aa\ufe0f OpenAI-related logs</li> <li>\ud83c\udf00 Google-related logs</li> <li>\u26a1\ufe0f Network connections</li> <li>*\ufe0f\u20e3 JSON processing</li> <li>\ud83e\uddff Sandbox operations</li> </ul>"},{"location":"pages/tools/logging/#3-caller-information","title":"3. Caller Information","text":"<p>Optional inclusion of caller information in logs:</p> <ul> <li>File name and line number</li> <li>Function name</li> <li>Module name</li> <li>Customizable format templates</li> </ul>"},{"location":"pages/tools/logging/#4-structured-data-logging","title":"4. Structured Data Logging","text":"<p>Intelligent handling of different data types:</p> <ul> <li>Pretty-printing for dictionaries and lists</li> <li>JSON formatting with customizable indentation</li> <li>Special handling for None values</li> <li>Exception traceback integration</li> </ul>"},{"location":"pages/tools/logging/#5-log-dispatch-system","title":"5. Log Dispatch System","text":"<p>Smart routing of log messages:</p> <ul> <li>Automatic detection of log origin</li> <li>Separate handlers for different logging needs</li> <li>Sandbox-aware logging behavior</li> <li>Support for poor loggers (simplified logging)</li> </ul>"},{"location":"pages/tools/logging/#using-the-logger","title":"Using the Logger","text":"<pre><code>from pipelex import log\n\n# Basic logging\nlog.info(\"Simple message\")\n\n# Logging with title\nlog.info(\"Detailed message\", title=\"Process Status\")\n\n# Logging with inline title\nlog.info(\"Quick update\", inline=\"Status\")\n\n# Logging structured data\ndata = {\"key\": \"value\", \"nested\": {\"data\": True}}\nlog.debug(data, title=\"Configuration\")\n\n# Warning with problem ID\nlog.warning(\"API rate limit approaching\", problem_id=\"rate_limit_warning\")\n\n# Error with exception traceback\nlog.error(\"Failed to process\", include_exception=True)\n\n# Development logging\nlog.dev(\"Testing new feature\")\n\n# Verbose logging\nlog.verbose(\"Detailed debug information\")\n</code></pre>"},{"location":"pages/tools/logging/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Log Level Selection:</p> <ul> <li>Use VERBOSE for detailed debugging</li> <li>Use DEBUG for general debugging</li> <li>Use DEV for development-specific logging</li> <li>Use INFO for general progress</li> <li>Use WARNING for potential issues</li> <li>Use ERROR for actual errors</li> <li>Use CRITICAL for system-critical issues</li> </ul> </li> <li> <p>Structured Data:</p> <ul> <li>Log complex data structures directly</li> <li>Use titles for context</li> <li>Include problem IDs for trackable issues</li> </ul> </li> <li> <p>Exception Handling:</p> <ul> <li>Use <code>include_exception=True</code> for error context</li> <li>Include relevant data in error logs</li> <li>Use appropriate log levels for exceptions</li> </ul> </li> </ol>"}]}